{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following kernel here shows how the excellent kernel [here](https://www.kaggle.com/scirpus/hybrid-gp-and-nn) may benefit from adding some regularisation. Overfitting was suspected because the validation scores on the neural network were considerably below the public leaderboard score. [scirpus](https://www.kaggle.com/scirpus) produces a lot of high quality kernels for Kaggle so please be sure to upvote the kernel listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as mtr\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nfl-big-data-bowl-2020/train.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/__init__.py\n",
      "/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/test.csv.encrypted\n",
      "/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/sample_submission.csv.encrypted\n",
      "/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/competition.cpython-36m-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', usecols=['GameId', 'PlayId', 'Team', 'X', 'Y', 'S', 'A', 'Dis',\n",
    "                                                                               'Orientation', 'Dir', 'NflId', 'DisplayName', 'YardLine',\n",
    "                                                                               'Quarter', 'GameClock', 'PossessionTeam', 'Down', 'Distance',\n",
    "                                                                               'FieldPosition', 'NflIdRusher', 'OffenseFormation', \n",
    "                                                                               'OffensePersonnel', 'DefendersInTheBox', 'DefensePersonnel', \n",
    "                                                                               'PlayDirection', 'TimeHandoff', 'TimeSnap', 'Yards'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = train[['GameId','PlayId','Yards']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for anchoring offense moving left from {0,0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, deploy=False):\n",
    "    def new_X(x_coordinate, play_direction):\n",
    "        if play_direction == 'left':\n",
    "            return 120.0 - x_coordinate\n",
    "        else:\n",
    "            return x_coordinate\n",
    "\n",
    "    def new_line(rush_team, field_position, yardline):\n",
    "        if rush_team == field_position:\n",
    "            # offense starting at X = 0 plus the 10 yard endzone plus the line of scrimmage\n",
    "            return 10.0 + yardline\n",
    "        else:\n",
    "            # half the field plus the yards between midfield and the line of scrimmage\n",
    "            return 60.0 + (50 - yardline)\n",
    "\n",
    "    def new_orientation(angle, play_direction):\n",
    "        if play_direction == 'left':\n",
    "            new_angle = 360.0 - angle\n",
    "            if new_angle == 360.0:\n",
    "                new_angle = 0.0\n",
    "            return new_angle\n",
    "        else:\n",
    "            return angle\n",
    "\n",
    "    def euclidean_distance(x1,y1,x2,y2):\n",
    "        x_diff = (x1-x2)**2\n",
    "        y_diff = (y1-y2)**2\n",
    "\n",
    "        return np.sqrt(x_diff + y_diff)\n",
    "\n",
    "    def back_direction(orientation):\n",
    "        if orientation > 180.0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def update_yardline(df):\n",
    "        new_yardline = df[df['NflId'] == df['NflIdRusher']]\n",
    "        new_yardline['YardLine'] = new_yardline[['PossessionTeam','FieldPosition','YardLine']].apply(lambda x: new_line(x[0],x[1],x[2]), axis=1)\n",
    "        new_yardline = new_yardline[['GameId','PlayId','YardLine']]\n",
    "\n",
    "        return new_yardline\n",
    "\n",
    "    def update_orientation(df, yardline):\n",
    "        df['X'] = df[['X','PlayDirection']].apply(lambda x: new_X(x[0],x[1]), axis=1)\n",
    "        df['Orientation'] = df[['Orientation','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n",
    "        df['Dir'] = df[['Dir','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n",
    "\n",
    "        df = df.drop('YardLine', axis=1)\n",
    "        df = pd.merge(df, yardline, on=['GameId','PlayId'], how='inner')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def back_features(df):\n",
    "        carriers = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','NflIdRusher','X','Y','Orientation','Dir','YardLine']]\n",
    "        carriers['back_from_scrimmage'] = carriers['YardLine'] - carriers['X']\n",
    "        carriers['back_oriented_down_field'] = carriers['Orientation'].apply(lambda x: back_direction(x))\n",
    "        carriers['back_moving_down_field'] = carriers['Dir'].apply(lambda x: back_direction(x))\n",
    "        carriers = carriers.rename(columns={'X':'back_X',\n",
    "                                            'Y':'back_Y'})\n",
    "        carriers = carriers[['GameId','PlayId','NflIdRusher','back_X','back_Y','back_from_scrimmage','back_oriented_down_field','back_moving_down_field']]\n",
    "\n",
    "        return carriers\n",
    "\n",
    "    def features_relative_to_back(df, carriers):\n",
    "        player_distance = df[['GameId','PlayId','NflId','X','Y']]\n",
    "        player_distance = pd.merge(player_distance, carriers, on=['GameId','PlayId'], how='inner')\n",
    "        player_distance = player_distance[player_distance['NflId'] != player_distance['NflIdRusher']]\n",
    "        player_distance['dist_to_back'] = player_distance[['X','Y','back_X','back_Y']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n",
    "\n",
    "        player_distance = player_distance.groupby(['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field'])\\\n",
    "                                         .agg({'dist_to_back':['min','max','mean','std']})\\\n",
    "                                         .reset_index()\n",
    "        player_distance.columns = ['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field',\n",
    "                                   'min_dist','max_dist','mean_dist','std_dist']\n",
    "\n",
    "        return player_distance\n",
    "\n",
    "    def defense_features(df):\n",
    "        rusher = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','Team','X','Y']]\n",
    "        rusher.columns = ['GameId','PlayId','RusherTeam','RusherX','RusherY']\n",
    "\n",
    "        defense = pd.merge(df,rusher,on=['GameId','PlayId'],how='inner')\n",
    "        defense = defense[defense['Team'] != defense['RusherTeam']][['GameId','PlayId','X','Y','RusherX','RusherY']]\n",
    "        defense['def_dist_to_back'] = defense[['X','Y','RusherX','RusherY']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n",
    "\n",
    "        defense = defense.groupby(['GameId','PlayId'])\\\n",
    "                         .agg({'def_dist_to_back':['min','max','mean','std']})\\\n",
    "                         .reset_index()\n",
    "        defense.columns = ['GameId','PlayId','def_min_dist','def_max_dist','def_mean_dist','def_std_dist']\n",
    "\n",
    "        return defense\n",
    "\n",
    "    def static_features(df):\n",
    "        static_features = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','X','Y','S','A','Dis','Orientation','Dir',\n",
    "                                                            'YardLine','Quarter','Down','Distance','DefendersInTheBox']].drop_duplicates()\n",
    "        static_features['DefendersInTheBox'] = static_features['DefendersInTheBox'].fillna(np.mean(static_features['DefendersInTheBox']))\n",
    "\n",
    "        return static_features\n",
    "\n",
    "\n",
    "    def combine_features(relative_to_back, defense, static, deploy=deploy):\n",
    "        df = pd.merge(relative_to_back,defense,on=['GameId','PlayId'],how='inner')\n",
    "        df = pd.merge(df,static,on=['GameId','PlayId'],how='inner')\n",
    "\n",
    "        if not deploy:\n",
    "            df = pd.merge(df, outcomes, on=['GameId','PlayId'], how='inner')\n",
    "\n",
    "        return df\n",
    "    \n",
    "    yardline = update_yardline(df)\n",
    "    df = update_orientation(df, yardline)\n",
    "    back_feats = back_features(df)\n",
    "    rel_back = features_relative_to_back(df, back_feats)\n",
    "    def_feats = defense_features(df)\n",
    "    static_feats = static_features(df)\n",
    "    basetable = combine_features(rel_back, def_feats, static_feats, deploy=deploy)\n",
    "    \n",
    "    return basetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 24s, sys: 1.31 s, total: 2min 25s\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%time train_basetable = create_features(train, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's split our data into train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_basetable.copy()\n",
    "yards = X.Yards\n",
    "\n",
    "y = np.zeros((yards.shape[0], 199))\n",
    "for idx, target in enumerate(list(yards)):\n",
    "    y[idx][99 + target] = 1\n",
    "\n",
    "X.drop(['GameId','PlayId','Yards'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19695, 23) (3476, 23)\n",
      "(19695, 199) (3476, 199)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape)\n",
    "print(y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's build NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below class Metric based entirely on: https://www.kaggle.com/kingychiu/keras-nn-starter-crps-early-stopping\n",
    "<br></br>\n",
    "Below early stopping entirely based on: https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/112868#latest-656533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric(Callback):\n",
    "    def __init__(self, model, callbacks, data):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.callbacks = callbacks\n",
    "        self.data = data\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_train_begin(logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_train_end(logs)\n",
    "\n",
    "    def on_epoch_end(self, batch, logs=None):\n",
    "        X_train, y_train = self.data[0][0], self.data[0][1]\n",
    "        y_pred = self.model.predict(X_train)\n",
    "        y_true = np.clip(np.cumsum(y_train, axis=1), 0, 1)\n",
    "        y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "        tr_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_train.shape[0])\n",
    "        tr_s = np.round(tr_s, 6)\n",
    "        logs['tr_CRPS'] = tr_s\n",
    "\n",
    "        X_valid, y_valid = self.data[1][0], self.data[1][1]\n",
    "\n",
    "        y_pred = self.model.predict(X_valid)\n",
    "        y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n",
    "        y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "        val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_valid.shape[0])\n",
    "        val_s = np.round(val_s, 6)\n",
    "        logs['val_CRPS'] = val_s\n",
    "        print('tr CRPS', tr_s, 'val CRPS', val_s)\n",
    "\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_epoch_end(batch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.4)) #dropout is a type of regularisation. Regularisation helps to control overfitting\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.4)) #dropout is a type of regularisation. Regularisation helps to control overfitting\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2)) #dropout is a type of regularisation. Regularisation helps to control overfitting\n",
    "model.add(Dense(199, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               12288     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 199)               51143     \n",
      "=================================================================\n",
      "Total params: 260,551\n",
      "Trainable params: 260,551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_CRPS', \n",
    "                   mode='min',\n",
    "                   restore_best_weights=True, \n",
    "                   verbose=1, \n",
    "                   patience=15)\n",
    "es.set_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = Metric(model, [es], [(X_train,y_train), (X_val,y_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "19695/19695 [==============================] - 1s 53us/step - loss: 3.9703\n",
      "tr CRPS 0.014355 val CRPS 0.01393\n",
      "Epoch 2/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 3.0468\n",
      "tr CRPS 0.014172 val CRPS 0.013747\n",
      "Epoch 3/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.9431\n",
      "tr CRPS 0.013841 val CRPS 0.0134\n",
      "Epoch 4/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.8994\n",
      "tr CRPS 0.0136 val CRPS 0.013136\n",
      "Epoch 5/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.8740\n",
      "tr CRPS 0.013486 val CRPS 0.013027\n",
      "Epoch 6/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.8443\n",
      "tr CRPS 0.013385 val CRPS 0.012932\n",
      "Epoch 7/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.8300\n",
      "tr CRPS 0.013313 val CRPS 0.01287\n",
      "Epoch 8/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.8198\n",
      "tr CRPS 0.013246 val CRPS 0.012821\n",
      "Epoch 9/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.8039\n",
      "tr CRPS 0.013217 val CRPS 0.012797\n",
      "Epoch 10/250\n",
      "19695/19695 [==============================] - 1s 35us/step - loss: 2.7907\n",
      "tr CRPS 0.013154 val CRPS 0.01276\n",
      "Epoch 11/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.7865\n",
      "tr CRPS 0.013093 val CRPS 0.012688\n",
      "Epoch 12/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.7802\n",
      "tr CRPS 0.013053 val CRPS 0.012663\n",
      "Epoch 13/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.7723\n",
      "tr CRPS 0.013061 val CRPS 0.012678\n",
      "Epoch 14/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.7657\n",
      "tr CRPS 0.01304 val CRPS 0.012682\n",
      "Epoch 15/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.7640\n",
      "tr CRPS 0.013065 val CRPS 0.012727\n",
      "Epoch 16/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.7565\n",
      "tr CRPS 0.013037 val CRPS 0.012716\n",
      "Epoch 17/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.7522\n",
      "tr CRPS 0.012979 val CRPS 0.012652\n",
      "Epoch 18/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.7428\n",
      "tr CRPS 0.012952 val CRPS 0.012641\n",
      "Epoch 19/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.7420\n",
      "tr CRPS 0.012934 val CRPS 0.012617\n",
      "Epoch 20/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.7378\n",
      "tr CRPS 0.012893 val CRPS 0.012587\n",
      "Epoch 21/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.7326\n",
      "tr CRPS 0.01283 val CRPS 0.01255\n",
      "Epoch 22/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.7300\n",
      "tr CRPS 0.012825 val CRPS 0.012531\n",
      "Epoch 23/250\n",
      "19695/19695 [==============================] - 1s 34us/step - loss: 2.7240\n",
      "tr CRPS 0.012812 val CRPS 0.012535\n",
      "Epoch 24/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.7173\n",
      "tr CRPS 0.01283 val CRPS 0.01258\n",
      "Epoch 25/250\n",
      "19695/19695 [==============================] - 1s 34us/step - loss: 2.7140\n",
      "tr CRPS 0.01279 val CRPS 0.012549\n",
      "Epoch 26/250\n",
      "19695/19695 [==============================] - 1s 35us/step - loss: 2.7116\n",
      "tr CRPS 0.01275 val CRPS 0.012512\n",
      "Epoch 27/250\n",
      "19695/19695 [==============================] - 1s 36us/step - loss: 2.7101\n",
      "tr CRPS 0.012714 val CRPS 0.012494\n",
      "Epoch 28/250\n",
      "19695/19695 [==============================] - 1s 34us/step - loss: 2.7073\n",
      "tr CRPS 0.012714 val CRPS 0.012505\n",
      "Epoch 29/250\n",
      "19695/19695 [==============================] - 1s 35us/step - loss: 2.7047\n",
      "tr CRPS 0.012731 val CRPS 0.012546\n",
      "Epoch 30/250\n",
      "19695/19695 [==============================] - 1s 35us/step - loss: 2.7006\n",
      "tr CRPS 0.012715 val CRPS 0.012516\n",
      "Epoch 31/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.6936\n",
      "tr CRPS 0.012689 val CRPS 0.012517\n",
      "Epoch 32/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.6905\n",
      "tr CRPS 0.012654 val CRPS 0.012496\n",
      "Epoch 33/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.6836\n",
      "tr CRPS 0.012665 val CRPS 0.012515\n",
      "Epoch 34/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.6823\n",
      "tr CRPS 0.012625 val CRPS 0.012506\n",
      "Epoch 35/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.6788\n",
      "tr CRPS 0.012583 val CRPS 0.012442\n",
      "Epoch 36/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.6711\n",
      "tr CRPS 0.012612 val CRPS 0.012501\n",
      "Epoch 37/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.6746\n",
      "tr CRPS 0.01254 val CRPS 0.012422\n",
      "Epoch 38/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.6697\n",
      "tr CRPS 0.012548 val CRPS 0.012445\n",
      "Epoch 39/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.6682\n",
      "tr CRPS 0.012537 val CRPS 0.012453\n",
      "Epoch 40/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.6631\n",
      "tr CRPS 0.012506 val CRPS 0.012431\n",
      "Epoch 41/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.6567\n",
      "tr CRPS 0.012473 val CRPS 0.012416\n",
      "Epoch 42/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.6555\n",
      "tr CRPS 0.012487 val CRPS 0.012435\n",
      "Epoch 43/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.6554\n",
      "tr CRPS 0.012483 val CRPS 0.012451\n",
      "Epoch 44/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.6518\n",
      "tr CRPS 0.012444 val CRPS 0.012427\n",
      "Epoch 45/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.6487\n",
      "tr CRPS 0.012424 val CRPS 0.012402\n",
      "Epoch 46/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.6448\n",
      "tr CRPS 0.01245 val CRPS 0.012481\n",
      "Epoch 47/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.6397\n",
      "tr CRPS 0.012399 val CRPS 0.012438\n",
      "Epoch 48/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.6380\n",
      "tr CRPS 0.012392 val CRPS 0.012412\n",
      "Epoch 49/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.6356\n",
      "tr CRPS 0.012405 val CRPS 0.012452\n",
      "Epoch 50/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.6332\n",
      "tr CRPS 0.01238 val CRPS 0.012438\n",
      "Epoch 51/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.6351\n",
      "tr CRPS 0.012382 val CRPS 0.012444\n",
      "Epoch 52/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.6268\n",
      "tr CRPS 0.012354 val CRPS 0.012435\n",
      "Epoch 53/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.6183\n",
      "tr CRPS 0.01231 val CRPS 0.01237\n",
      "Epoch 54/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.6246\n",
      "tr CRPS 0.012301 val CRPS 0.012386\n",
      "Epoch 55/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.6179\n",
      "tr CRPS 0.012267 val CRPS 0.012378\n",
      "Epoch 56/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.6195\n",
      "tr CRPS 0.012279 val CRPS 0.012401\n",
      "Epoch 57/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.6149\n",
      "tr CRPS 0.01225 val CRPS 0.01239\n",
      "Epoch 58/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.6100\n",
      "tr CRPS 0.01223 val CRPS 0.012364\n",
      "Epoch 59/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.6051\n",
      "tr CRPS 0.012196 val CRPS 0.012361\n",
      "Epoch 60/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.6015\n",
      "tr CRPS 0.012222 val CRPS 0.012389\n",
      "Epoch 61/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.6051\n",
      "tr CRPS 0.012208 val CRPS 0.012374\n",
      "Epoch 62/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.5965\n",
      "tr CRPS 0.012155 val CRPS 0.01235\n",
      "Epoch 63/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.5977\n",
      "tr CRPS 0.012158 val CRPS 0.01236\n",
      "Epoch 64/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.5882\n",
      "tr CRPS 0.012139 val CRPS 0.012373\n",
      "Epoch 65/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.5917\n",
      "tr CRPS 0.012126 val CRPS 0.012381\n",
      "Epoch 66/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.5907\n",
      "tr CRPS 0.01215 val CRPS 0.012432\n",
      "Epoch 67/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.5813\n",
      "tr CRPS 0.012089 val CRPS 0.012355\n",
      "Epoch 68/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.5777\n",
      "tr CRPS 0.012073 val CRPS 0.012362\n",
      "Epoch 69/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.5769\n",
      "tr CRPS 0.012077 val CRPS 0.012391\n",
      "Epoch 70/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.5773\n",
      "tr CRPS 0.012073 val CRPS 0.012392\n",
      "Epoch 71/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.5758\n",
      "tr CRPS 0.012036 val CRPS 0.012372\n",
      "Epoch 72/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.5750\n",
      "tr CRPS 0.012019 val CRPS 0.012373\n",
      "Epoch 73/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.5713\n",
      "tr CRPS 0.011997 val CRPS 0.012325\n",
      "Epoch 74/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.5662\n",
      "tr CRPS 0.011984 val CRPS 0.01232\n",
      "Epoch 75/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.5666\n",
      "tr CRPS 0.011988 val CRPS 0.012342\n",
      "Epoch 76/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.5633\n",
      "tr CRPS 0.011969 val CRPS 0.012362\n",
      "Epoch 77/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.5610\n",
      "tr CRPS 0.011953 val CRPS 0.012358\n",
      "Epoch 78/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.5560\n",
      "tr CRPS 0.011946 val CRPS 0.012357\n",
      "Epoch 79/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.5563\n",
      "tr CRPS 0.011951 val CRPS 0.012396\n",
      "Epoch 80/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.5519\n",
      "tr CRPS 0.011933 val CRPS 0.012377\n",
      "Epoch 81/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.5497\n",
      "tr CRPS 0.01192 val CRPS 0.012398\n",
      "Epoch 82/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.5462\n",
      "tr CRPS 0.011917 val CRPS 0.012406\n",
      "Epoch 83/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.5432\n",
      "tr CRPS 0.01195 val CRPS 0.012474\n",
      "Epoch 84/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.5420\n",
      "tr CRPS 0.011863 val CRPS 0.012373\n",
      "Epoch 85/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.5374\n",
      "tr CRPS 0.011833 val CRPS 0.012359\n",
      "Epoch 86/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.5381\n",
      "tr CRPS 0.011811 val CRPS 0.012385\n",
      "Epoch 87/250\n",
      "19695/19695 [==============================] - 1s 32us/step - loss: 2.5276\n",
      "tr CRPS 0.011811 val CRPS 0.012379\n",
      "Epoch 88/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.5311\n",
      "tr CRPS 0.011778 val CRPS 0.012392\n",
      "Epoch 89/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 2.5330\n",
      "tr CRPS 0.011802 val CRPS 0.0124\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00089: early stopping\n",
      "CPU times: user 5min 11s, sys: 32.7 s, total: 5min 44s\n",
      "Wall time: 2min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f3124c5fd68>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train, callbacks=[metric], epochs=250, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GP:\n",
    "    def __init__(self):\n",
    "        self.classes = 20\n",
    "        self.class_names = [ 'class_0',\n",
    "                             'class_1',\n",
    "                             'class_2',\n",
    "                             'class_3',\n",
    "                             'class_4',\n",
    "                             'class_5',\n",
    "                             'class_6',\n",
    "                             'class_7',\n",
    "                             'class_8',\n",
    "                             'class_9',\n",
    "                             'class_10',\n",
    "                             'class_11',\n",
    "                             'class_12',\n",
    "                             'class_13',\n",
    "                            'class_14',\n",
    "                            'class_15',\n",
    "                            'class_16',\n",
    "                            'class_17',\n",
    "                            'class_18',\n",
    "                            'class_19',\n",
    "                           ]\n",
    "\n",
    "\n",
    "    def GrabPredictions(self, data):\n",
    "        oof_preds = np.zeros((len(data), len(self.class_names)))\n",
    "        oof_preds[:,0] = self.GP_class_0(data)\n",
    "        oof_preds[:,1] = self.GP_class_1(data)\n",
    "        oof_preds[:,2] = self.GP_class_2(data)\n",
    "        oof_preds[:,3] = self.GP_class_3(data)\n",
    "        oof_preds[:,4] = self.GP_class_4(data)\n",
    "        oof_preds[:,5] = self.GP_class_5(data)\n",
    "        oof_preds[:,6] = self.GP_class_6(data)\n",
    "        oof_preds[:,7] = self.GP_class_7(data)\n",
    "        oof_preds[:,8] = self.GP_class_8(data)\n",
    "        oof_preds[:,9] = self.GP_class_9(data)\n",
    "        oof_preds[:,10] = self.GP_class_10(data)\n",
    "        oof_preds[:,11] = self.GP_class_11(data)\n",
    "        oof_preds[:,12] = self.GP_class_12(data)\n",
    "        oof_preds[:,13] = self.GP_class_13(data)\n",
    "        oof_preds[:,14] = self.GP_class_14(data)\n",
    "        oof_preds[:,15] = self.GP_class_15(data)\n",
    "        oof_preds[:,16] = self.GP_class_16(data)\n",
    "        oof_preds[:,17] = self.GP_class_17(data)\n",
    "        oof_preds[:,18] = self.GP_class_18(data)\n",
    "        oof_preds[:,19] = self.GP_class_19(data)\n",
    "        oof_df = pd.DataFrame(np.exp(oof_preds), columns=self.class_names)\n",
    "        oof_df =oof_df.div(oof_df.sum(axis=1), axis=0)\n",
    "        \n",
    "        return oof_df.values\n",
    "\n",
    "\n",
    "    def GP_class_0(self,data):\n",
    "        return(0.250000*np.tanh(((((((data[:,0]) - (((data[:,0]) + (data[:,0]))))) + (data[:,0]))) + (((((data[:,0]) * 2.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh(((((((((((((data[:,2]) - (data[:,7]))) * 2.0)) + (data[:,7]))) * 2.0)) + (data[:,0]))) + (((((data[:,2]) + (data[:,0]))) - (data[:,7]))))) +\n",
    "                0.250000*np.tanh(((((((((((((((((((data[:,3]) - (data[:,7]))) - (((data[:,0]) / 2.0)))) + (data[:,0]))) - (data[:,7]))) + (data[:,2]))) + (((data[:,7]) + (data[:,2]))))) + (data[:,7]))) - (data[:,7]))) + (data[:,0]))) +\n",
    "                0.250000*np.tanh(((((((((data[:,0]) - (data[:,7]))) - (data[:,14]))) + (((data[:,17]) - (data[:,14]))))) + (((((((data[:,0]) - ((1.0)))) - (data[:,0]))) + (data[:,20]))))) +\n",
    "                0.250000*np.tanh(((((data[:,18]) + (((((((data[:,0]) - (data[:,7]))) + (data[:,2]))) + (data[:,0]))))) - (((data[:,7]) + (data[:,2]))))) +\n",
    "                0.250000*np.tanh((((((((data[:,8]) + ((((((((data[:,13]) + (data[:,3]))) + (data[:,0]))/2.0)) + ((((((((data[:,0]) + (((((data[:,0]) - (data[:,0]))) / 2.0)))) + (data[:,17]))/2.0)) + (data[:,11]))))))/2.0)) + (data[:,0]))) - (data[:,13]))) +\n",
    "                0.250000*np.tanh(((((data[:,0]) * 2.0)) + (((((((((data[:,2]) + (data[:,2]))) * 2.0)) - (((data[:,14]) - (((np.tanh((data[:,2]))) * 2.0)))))) - (data[:,7]))))) +\n",
    "                0.250000*np.tanh(((((((((((((data[:,17]) - (((data[:,17]) * (((((data[:,17]) * (data[:,17]))) * 2.0)))))) + (((((((data[:,17]) * 2.0)) * 2.0)) * 2.0)))/2.0)) / 2.0)) + (((data[:,17]) - ((7.76236486434936523)))))/2.0)) + (((((((data[:,17]) * (data[:,17]))) * 2.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh(((((((((((data[:,17]) + (data[:,17]))/2.0)) + ((((data[:,17]) + ((((data[:,17]) + (data[:,17]))/2.0)))/2.0)))/2.0)) * (data[:,17]))) - (data[:,13]))) +\n",
    "                0.250000*np.tanh((((((data[:,19]) + (((((((((data[:,19]) * 2.0)) + (data[:,19]))) - ((1.07645297050476074)))) + (((data[:,22]) + (data[:,22]))))))/2.0)) + (((data[:,22]) + (data[:,4]))))))\n",
    "    \n",
    "    def GP_class_1(self,data):\n",
    "        return(0.250000*np.tanh(((((((((((((data[:,3]) + (((np.tanh((data[:,2]))) - (data[:,14]))))) - ((10.0)))) - ((4.88989353179931641)))) - ((13.92175483703613281)))) / 2.0)) - (data[:,6]))) +\n",
    "                0.250000*np.tanh(data[:,3]) +\n",
    "                0.250000*np.tanh(((data[:,2]) + (((((np.tanh((((data[:,14]) * 2.0)))) - (((((((data[:,7]) * 2.0)) - (((((data[:,0]) - (data[:,14]))) - (data[:,7]))))) - (data[:,0]))))) + (data[:,0]))))) +\n",
    "                0.250000*np.tanh(((((((data[:,0]) - ((-1.0*((data[:,14])))))) + ((((((((((data[:,0]) - (data[:,7]))) - ((((data[:,14]) + (data[:,14]))/2.0)))) + (((data[:,2]) - (((data[:,0]) * (data[:,14]))))))/2.0)) - (data[:,14]))))) - (data[:,7]))) +\n",
    "                0.250000*np.tanh(((((data[:,0]) / 2.0)) + (data[:,0]))) +\n",
    "                0.250000*np.tanh(((((data[:,19]) - (data[:,19]))) / 2.0)) +\n",
    "                0.250000*np.tanh(((((np.tanh((((np.tanh((data[:,5]))) - ((((1.69341480731964111)) + ((((((np.tanh((data[:,14]))) - (data[:,14]))) + (data[:,14]))/2.0)))))))) - (data[:,2]))) - (((data[:,14]) * 2.0)))) +\n",
    "                0.250000*np.tanh((((((data[:,22]) + (((data[:,0]) + ((((((((data[:,22]) / 2.0)) + ((-1.0*((data[:,13])))))/2.0)) + (data[:,19]))))))/2.0)) - (data[:,13]))) +\n",
    "                0.250000*np.tanh(((((((data[:,17]) / 2.0)) * (data[:,17]))) * (((data[:,17]) + (((data[:,17]) * (((((((((data[:,17]) + (data[:,17]))) * (data[:,17]))) * (data[:,17]))) + (((np.tanh((data[:,17]))) / 2.0)))))))))) +\n",
    "                0.250000*np.tanh((((((data[:,14]) * (((data[:,13]) + (data[:,3]))))) + (((data[:,14]) * (((data[:,14]) - ((-1.0*((data[:,3])))))))))/2.0)))\n",
    "    \n",
    "    def GP_class_2(self,data):\n",
    "        return(0.250000*np.tanh(((data[:,0]) + (np.tanh((((((((((data[:,2]) + (((data[:,2]) / 2.0)))/2.0)) + (data[:,0]))/2.0)) * (data[:,7]))))))) +\n",
    "                0.250000*np.tanh((((data[:,22]) + (data[:,22]))/2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,14]) + ((-1.0*((((((4.73206138610839844)) + (((((((((((np.tanh((data[:,7]))) + (data[:,1]))/2.0)) - (np.tanh((((((data[:,0]) - (data[:,20]))) - (data[:,14]))))))) * ((7.0)))) + (data[:,14]))/2.0)))/2.0))))))/2.0)) - (data[:,14]))) +\n",
    "                0.250000*np.tanh(((((data[:,1]) + ((4.15603733062744141)))) / 2.0)) +\n",
    "                0.250000*np.tanh(((((((((((((data[:,0]) - (data[:,7]))) - (data[:,7]))) + ((((data[:,0]) + (data[:,0]))/2.0)))) * 2.0)) + (data[:,0]))) * 2.0)) +\n",
    "                0.250000*np.tanh(((((data[:,11]) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(((((((((((((((((((((((data[:,2]) / 2.0)) + (((data[:,2]) / 2.0)))/2.0)) / 2.0)) / 2.0)) / 2.0)) + ((((-1.0*((((data[:,0]) / 2.0))))) * (((data[:,0]) / 2.0)))))/2.0)) + (data[:,0]))/2.0)) + (np.tanh((data[:,0]))))/2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(((((data[:,0]) + (((data[:,0]) + (((((((data[:,14]) * (data[:,14]))) + (data[:,14]))) - (data[:,0]))))))) - (data[:,14]))) +\n",
    "                0.250000*np.tanh((((((np.tanh((np.tanh(((0.0)))))) * (data[:,15]))) + (data[:,20]))/2.0)) +\n",
    "                0.250000*np.tanh(((data[:,14]) * ((((data[:,13]) + ((((data[:,13]) + ((((data[:,14]) + ((((((data[:,14]) + ((((data[:,14]) + (((data[:,13]) - ((((-1.0*(((((data[:,14]) + (data[:,14]))/2.0))))) * 2.0)))))/2.0)))) + (data[:,14]))/2.0)))/2.0)))/2.0)))/2.0)))))\n",
    "    \n",
    "    def GP_class_3(self,data):\n",
    "        return(0.250000*np.tanh(((((((((8.0)) + (((((((5.33416414260864258)) + ((9.0)))/2.0)) + ((((8.0)) * 2.0)))))) * 2.0)) + ((5.33416414260864258)))/2.0)) +\n",
    "                0.250000*np.tanh((((9.48088836669921875)) + (((((10.56953334808349609)) + ((((4.48959350585937500)) + (np.tanh(((((3.0)) + ((9.0)))))))))/2.0)))) +\n",
    "                0.250000*np.tanh((((((((((data[:,22]) / 2.0)) + (data[:,22]))/2.0)) * 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((10.44883441925048828)) +\n",
    "                0.250000*np.tanh(((((data[:,0]) + (((data[:,0]) + ((-1.0*((data[:,9])))))))) + (((((data[:,0]) - (data[:,7]))) - (data[:,9]))))) +\n",
    "                0.250000*np.tanh(((np.tanh((data[:,6]))) - (data[:,21]))) +\n",
    "                0.250000*np.tanh(((data[:,0]) - (((((data[:,14]) + (((((data[:,14]) + (((data[:,14]) + (((data[:,14]) - (data[:,0]))))))) - (((((data[:,0]) - (data[:,14]))) + (data[:,14]))))))) - (((((data[:,14]) * (data[:,14]))) + (data[:,18]))))))) +\n",
    "                0.250000*np.tanh(((data[:,14]) * ((((data[:,13]) + (data[:,14]))/2.0)))) +\n",
    "                0.250000*np.tanh((((((data[:,8]) * (((data[:,8]) / 2.0)))) + ((((((data[:,9]) * (data[:,8]))) + (data[:,8]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh((((data[:,2]) + (((((((data[:,2]) + (data[:,20]))/2.0)) + ((((((((data[:,2]) + (data[:,8]))/2.0)) / 2.0)) - (data[:,8]))))/2.0)))/2.0)))\n",
    "    \n",
    "    def GP_class_4(self,data):\n",
    "        return(0.250000*np.tanh((((12.98819637298583984)) / 2.0)) +\n",
    "                0.250000*np.tanh(((((4.75780344009399414)) + (((((((8.66014671325683594)) + ((4.18107128143310547)))/2.0)) * ((8.97841739654541016)))))/2.0)) +\n",
    "                0.250000*np.tanh((((9.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(((((((((((10.0)) + (np.tanh((((((6.0)) + ((((13.80149555206298828)) + ((7.0)))))/2.0)))))) + ((10.0)))) + (((((((data[:,0]) + ((8.0)))) / 2.0)) / 2.0)))/2.0)) + ((((-1.0*((((data[:,2]) * (data[:,9])))))) * 2.0)))) +\n",
    "                0.250000*np.tanh(((((data[:,0]) + (((((((data[:,22]) + (data[:,22]))/2.0)) + (data[:,22]))/2.0)))) + ((((((data[:,22]) + ((((((data[:,22]) * 2.0)) + (data[:,22]))/2.0)))) + (data[:,18]))/2.0)))) +\n",
    "                0.250000*np.tanh(((((((((((((np.tanh((data[:,18]))) + ((((data[:,1]) + (data[:,18]))/2.0)))/2.0)) * (data[:,18]))) * (data[:,18]))) + (((data[:,18]) * (data[:,18]))))/2.0)) - (((((((np.tanh((data[:,18]))) + (((data[:,18]) * (data[:,18]))))/2.0)) + (data[:,17]))/2.0)))) +\n",
    "                0.250000*np.tanh(((np.tanh(((((((np.tanh((data[:,6]))) - (((np.tanh((data[:,6]))) - (data[:,6]))))) + (np.tanh((data[:,6]))))/2.0)))) - ((((data[:,10]) + ((((data[:,2]) + (((np.tanh((data[:,6]))) - (((np.tanh((np.tanh((data[:,6]))))) - (data[:,10]))))))/2.0)))/2.0)))) +\n",
    "                0.250000*np.tanh((((((((((((data[:,10]) + (data[:,4]))) + (((data[:,10]) + (((data[:,0]) * (data[:,10]))))))/2.0)) + (((data[:,4]) * (((data[:,10]) + (data[:,4]))))))/2.0)) + (data[:,7]))/2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,11]) + (((((data[:,18]) / 2.0)) * (((data[:,11]) * (data[:,18]))))))/2.0)) * (((data[:,18]) * (((((((((data[:,18]) * (((((((data[:,11]) / 2.0)) / 2.0)) * (data[:,18]))))) / 2.0)) / 2.0)) * ((-1.0*((data[:,21])))))))))) +\n",
    "                0.250000*np.tanh((((-1.0*((((((((((((data[:,2]) - (data[:,2]))) * (np.tanh((data[:,2]))))) + (np.tanh((((data[:,14]) * 2.0)))))/2.0)) + (data[:,2]))/2.0))))) - (data[:,2]))))\n",
    "    \n",
    "    def GP_class_5(self,data):\n",
    "        return(0.250000*np.tanh(((((((((((3.46574378013610840)) + ((((np.tanh(((3.46574378013610840)))) + ((8.46705245971679688)))/2.0)))/2.0)) * 2.0)) + ((((3.46574378013610840)) + ((4.0)))))) + ((((4.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((10.55856513977050781)) / 2.0)) +\n",
    "                0.250000*np.tanh((((3.76695251464843750)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((6.0)) / 2.0)) + ((((8.57984828948974609)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((((((((((3.42168045043945312)) + (data[:,7]))) + (np.tanh((data[:,7]))))) + (np.tanh((np.tanh((np.tanh(((3.42168045043945312)))))))))/2.0)) + (data[:,7]))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((((data[:,6]) - (data[:,9]))) + (data[:,7]))/2.0)) * 2.0)) + ((((((data[:,7]) + (data[:,9]))/2.0)) - (data[:,9]))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((((data[:,22]) + (data[:,22]))) + (data[:,11]))/2.0)) + (data[:,22]))/2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((((0.76044219732284546)) / 2.0)) + ((0.76044219732284546)))/2.0)) + (np.tanh((np.tanh((((((((0.76043862104415894)) / 2.0)) + ((1.0)))/2.0)))))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((data[:,12]) + (np.tanh((data[:,9]))))/2.0)) + (((((((((((data[:,12]) + (((((0.0)) + (np.tanh((((((((data[:,7]) + (data[:,6]))/2.0)) + (data[:,7]))/2.0)))))/2.0)))/2.0)) / 2.0)) / 2.0)) + (data[:,7]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((data[:,20]) / 2.0)) / 2.0)) * (((np.tanh((data[:,20]))) * (((data[:,20]) / 2.0)))))) * ((((((data[:,20]) / 2.0)) + (((data[:,20]) / 2.0)))/2.0)))))\n",
    "    \n",
    "    def GP_class_6(self,data):\n",
    "        return(0.250000*np.tanh(((((((11.68076229095458984)) + (((((11.68075847625732422)) + ((((11.47270107269287109)) + (((((11.47269725799560547)) + ((11.68076229095458984)))/2.0)))))/2.0)))/2.0)) + ((((4.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((8.0)) + ((((10.0)) + ((6.59042119979858398)))))) +\n",
    "                0.250000*np.tanh(((((((((((13.33760547637939453)) + (((((3.86388397216796875)) + (((((((8.18321037292480469)) + (data[:,4]))) + (((((((5.95386552810668945)) + ((12.93883609771728516)))) + (((((10.73907089233398438)) + ((4.0)))/2.0)))/2.0)))/2.0)))/2.0)))/2.0)) + (np.tanh(((3.0)))))) - ((2.0)))) + (((((10.61559963226318359)) + (data[:,1]))/2.0)))) +\n",
    "                0.250000*np.tanh(((np.tanh(((((((((((7.13513946533203125)) + ((12.48778533935546875)))/2.0)) + (((((((7.13513565063476562)) - ((8.12031841278076172)))) + (((((((((7.13513565063476562)) + ((((10.69830417633056641)) + ((10.69830799102783203)))))) + ((10.69830799102783203)))) + ((7.83078956604003906)))/2.0)))/2.0)))/2.0)) * 2.0)))) + ((3.0)))) +\n",
    "                0.250000*np.tanh(((((((((((data[:,7]) - (data[:,0]))) * 2.0)) - (data[:,7]))) + (data[:,7]))) + (data[:,0]))) +\n",
    "                0.250000*np.tanh(((((data[:,7]) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((((((((((1.0)) + (((((((data[:,2]) + (((((((1.0)) * (data[:,2]))) + (data[:,14]))/2.0)))/2.0)) + ((1.0)))/2.0)))) + ((((1.0)) - (((data[:,2]) * (data[:,14]))))))/2.0)) - (data[:,2]))) * 2.0)) + (data[:,14]))/2.0)) + (data[:,14]))) +\n",
    "                0.250000*np.tanh(((np.tanh((np.tanh(((((((data[:,19]) * ((0.0)))) + ((0.0)))/2.0)))))) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((0.0)) / 2.0)) / 2.0)) * (((((((((data[:,15]) / 2.0)) * ((0.0)))) / 2.0)) * ((((-1.0*(((0.0))))) / 2.0)))))) +\n",
    "                0.250000*np.tanh(((((data[:,15]) * (((((((((((((np.tanh(((((0.09032609313726425)) / 2.0)))) / 2.0)) / 2.0)) / 2.0)) / 2.0)) / 2.0)) / 2.0)))) / 2.0)))\n",
    "    \n",
    "    def GP_class_7(self,data):\n",
    "        return(0.250000*np.tanh((10.27210903167724609)) +\n",
    "                0.250000*np.tanh((((((((((10.0)) + (((((((((8.26972770690917969)) + ((11.06334972381591797)))/2.0)) * 2.0)) / 2.0)))) + ((((((5.0)) + ((((5.0)) + ((7.92727756500244141)))))) * 2.0)))) * ((7.92728137969970703)))) + ((10.0)))) +\n",
    "                0.250000*np.tanh((8.42519950866699219)) +\n",
    "                0.250000*np.tanh(((((((data[:,14]) + (data[:,14]))) + ((((((1.59392631053924561)) + (data[:,14]))) + (data[:,14]))))) + (np.tanh((((((data[:,14]) + (((((((3.0)) + (((data[:,14]) * 2.0)))/2.0)) + ((1.59391915798187256)))))) + ((1.59392631053924561)))))))) +\n",
    "                0.250000*np.tanh((((data[:,7]) + (((data[:,0]) + (((((((data[:,7]) + (data[:,4]))/2.0)) + (((data[:,7]) * 2.0)))/2.0)))))/2.0)) +\n",
    "                0.250000*np.tanh((((((((((((((data[:,9]) - (((data[:,0]) - (data[:,0]))))) - (((data[:,0]) / 2.0)))) / 2.0)) - (((data[:,21]) - (data[:,7]))))) + (data[:,21]))/2.0)) - (data[:,0]))) +\n",
    "                0.250000*np.tanh((((((((((2.0)) + ((((((data[:,21]) + ((((data[:,13]) + (((((((((((data[:,13]) * 2.0)) + (data[:,21]))/2.0)) + (data[:,13]))/2.0)) * 2.0)))/2.0)))/2.0)) - (np.tanh(((((0.0)) - (data[:,21]))))))))) + ((1.0)))/2.0)) + (data[:,13]))/2.0)) +\n",
    "                0.250000*np.tanh(((((data[:,14]) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((((((((((-1.0*(((((((data[:,21]) / 2.0)) + (data[:,8]))/2.0))))) / 2.0)) / 2.0)) / 2.0)) + (data[:,9]))/2.0)) / 2.0)) + ((((((((((((data[:,7]) / 2.0)) / 2.0)) / 2.0)) / 2.0)) + (data[:,7]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((((np.tanh(((1.0)))) / 2.0)) / 2.0)) / 2.0)))\n",
    "    \n",
    "    def GP_class_8(self,data):\n",
    "        return(0.250000*np.tanh(((((((data[:,0]) + (((((6.71804094314575195)) + (data[:,15]))/2.0)))) + ((((((11.56385326385498047)) * 2.0)) * ((((10.48986148834228516)) + ((11.56385326385498047)))))))) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((((data[:,14]) / 2.0)) + ((2.83755254745483398)))/2.0)) + ((((((data[:,12]) + (data[:,14]))/2.0)) + (data[:,14]))))) + ((((data[:,9]) + (((data[:,12]) + (data[:,14]))))/2.0)))) +\n",
    "                0.250000*np.tanh(((((((((data[:,6]) + (((((((3.50821948051452637)) + ((((data[:,21]) + ((11.92932796478271484)))/2.0)))) + ((1.0)))/2.0)))) + (data[:,10]))/2.0)) + (data[:,21]))/2.0)) +\n",
    "                0.250000*np.tanh(((data[:,14]) + (np.tanh((np.tanh(((-1.0*((((data[:,22]) - (data[:,13])))))))))))) +\n",
    "                0.250000*np.tanh(((((1.0)) + ((((data[:,7]) + (data[:,7]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((data[:,21]) / 2.0)) / 2.0)) * (((((((np.tanh((((np.tanh((data[:,13]))) / 2.0)))) / 2.0)) + (((((((np.tanh(((((data[:,21]) + (data[:,21]))/2.0)))) / 2.0)) - (data[:,12]))) / 2.0)))) / 2.0)))) - (data[:,12]))) +\n",
    "                0.250000*np.tanh((((data[:,7]) + (np.tanh(((((data[:,12]) + (((data[:,7]) * ((((data[:,13]) + (data[:,13]))/2.0)))))/2.0)))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((data[:,13]) / 2.0)) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((((np.tanh((data[:,9]))) + (data[:,13]))/2.0)) + ((((((((data[:,21]) / 2.0)) * 2.0)) + ((((3.94983267784118652)) / 2.0)))/2.0)))/2.0)) + ((((np.tanh(((3.94983267784118652)))) + (data[:,9]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((((((((data[:,14]) * (((((((((data[:,19]) / 2.0)) * (np.tanh((((data[:,2]) / 2.0)))))) / 2.0)) / 2.0)))) / 2.0)) / 2.0)) / 2.0)) / 2.0)) / 2.0)) * (((((data[:,11]) / 2.0)) / 2.0)))))\n",
    "    \n",
    "    def GP_class_9(self,data):\n",
    "        return(0.250000*np.tanh(((((((data[:,14]) * 2.0)) / 2.0)) + (((((data[:,14]) + (np.tanh((((data[:,14]) * 2.0)))))) + (data[:,14]))))) +\n",
    "                0.250000*np.tanh(((data[:,9]) - (((((-1.0*((data[:,11])))) + (data[:,9]))/2.0)))) +\n",
    "                0.250000*np.tanh(((data[:,21]) * 2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,14]) + (data[:,14]))/2.0)) + ((((data[:,13]) + ((((np.tanh((((data[:,9]) + ((6.0)))))) + (data[:,9]))/2.0)))/2.0)))) +\n",
    "                0.250000*np.tanh(np.tanh(((1.0)))) +\n",
    "                0.250000*np.tanh(((np.tanh((np.tanh(((((np.tanh((((data[:,20]) * (((((((np.tanh((((data[:,20]) / 2.0)))) + (data[:,12]))/2.0)) + ((((data[:,15]) + ((((data[:,17]) + (data[:,9]))/2.0)))/2.0)))/2.0)))))) + (data[:,9]))/2.0)))))) / 2.0)) +\n",
    "                0.250000*np.tanh(((((data[:,2]) - (data[:,11]))) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((data[:,13]) / 2.0)) + (((data[:,7]) + (data[:,7]))))/2.0)) - (((((data[:,22]) + (((((data[:,14]) * (((((data[:,7]) * (((data[:,13]) - ((((data[:,7]) + (((((data[:,13]) / 2.0)) + (data[:,7]))))/2.0)))))) / 2.0)))) * 2.0)))) / 2.0)))) +\n",
    "                0.250000*np.tanh(((((((((((((((data[:,1]) / 2.0)) + ((1.0)))/2.0)) + ((1.0)))/2.0)) + ((((((((((1.0)) / 2.0)) + (np.tanh(((1.0)))))/2.0)) + (np.tanh((((((1.0)) + ((1.0)))/2.0)))))/2.0)))/2.0)) + ((((data[:,20]) + ((1.0)))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((data[:,1]) * ((((data[:,14]) + (np.tanh(((((0.0)) / 2.0)))))/2.0)))))\n",
    "    \n",
    "    def GP_class_10(self,data):\n",
    "        return(0.250000*np.tanh((((((((((data[:,2]) + (((data[:,9]) * (np.tanh((data[:,14]))))))/2.0)) + ((((((data[:,14]) + (data[:,20]))/2.0)) + (data[:,0]))))/2.0)) + (data[:,14]))/2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,9]) + ((-1.0*((((((((2.04309988021850586)) + (((data[:,11]) + (((np.tanh((data[:,0]))) / 2.0)))))/2.0)) * 2.0))))))/2.0)) + (data[:,2]))) +\n",
    "                0.250000*np.tanh(data[:,21]) +\n",
    "                0.250000*np.tanh((((((((data[:,14]) + (np.tanh((((data[:,6]) / 2.0)))))/2.0)) + (data[:,14]))) + (((((data[:,14]) * 2.0)) + ((((data[:,13]) + (data[:,14]))/2.0)))))) +\n",
    "                0.250000*np.tanh(data[:,9]) +\n",
    "                0.250000*np.tanh(((((((data[:,15]) * 2.0)) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((2.72836518287658691)) * ((((1.0)) / 2.0)))) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(((((np.tanh((((data[:,7]) + (np.tanh(((((((((((0.0)) / 2.0)) / 2.0)) / 2.0)) / 2.0)))))))) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(np.tanh((((np.tanh(((11.43236827850341797)))) / 2.0)))) +\n",
    "                0.250000*np.tanh(np.tanh((((data[:,7]) / 2.0)))))\n",
    "    \n",
    "    def GP_class_11(self,data):\n",
    "        return(0.250000*np.tanh((-1.0*((((((((((((((data[:,5]) - (((data[:,9]) - ((((-1.0*(((11.40053558349609375))))) / 2.0)))))) + ((((11.40053558349609375)) + ((((11.40053558349609375)) * 2.0)))))) / 2.0)) - (data[:,7]))) - ((-1.0*(((11.40053939819335938))))))) * 2.0))))) +\n",
    "                0.250000*np.tanh(((((data[:,14]) * 2.0)) + (data[:,14]))) +\n",
    "                0.250000*np.tanh(((data[:,2]) + (((((data[:,5]) + (data[:,3]))) + ((((data[:,2]) + (((data[:,3]) * 2.0)))/2.0)))))) +\n",
    "                0.250000*np.tanh(((((((((((data[:,21]) + (data[:,21]))) + ((-1.0*(((((np.tanh((np.tanh((((data[:,14]) / 2.0)))))) + (data[:,21]))/2.0))))))/2.0)) * 2.0)) + ((((data[:,14]) + (data[:,3]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((((data[:,0]) + ((((data[:,9]) + ((((data[:,9]) + (((((((((((((((data[:,9]) / 2.0)) - (data[:,10]))) + (data[:,5]))/2.0)) - (data[:,9]))) + (data[:,9]))/2.0)) / 2.0)))/2.0)))/2.0)))/2.0)) + (data[:,9]))/2.0)) +\n",
    "                0.250000*np.tanh((((((((data[:,13]) + ((((data[:,13]) + (data[:,13]))/2.0)))) + (data[:,1]))/2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(data[:,14]) +\n",
    "                0.250000*np.tanh(((((data[:,2]) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((data[:,9]) + (data[:,9]))/2.0)) +\n",
    "                0.250000*np.tanh(data[:,2]))\n",
    "    \n",
    "    def GP_class_12(self,data):\n",
    "        return(0.250000*np.tanh((((((((-1.0*((data[:,18])))) - (np.tanh((data[:,9]))))) + ((8.0)))) - ((14.74865913391113281)))) +\n",
    "                0.250000*np.tanh((((((data[:,21]) + (np.tanh((data[:,9]))))) + ((((((((data[:,5]) / 2.0)) * 2.0)) + (data[:,5]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((data[:,14]) + (data[:,14]))) + (((data[:,14]) * 2.0)))) +\n",
    "                0.250000*np.tanh(((data[:,2]) + (((((((data[:,14]) + ((((np.tanh((data[:,10]))) + (data[:,17]))/2.0)))/2.0)) + (data[:,21]))/2.0)))) +\n",
    "                0.250000*np.tanh((((data[:,9]) + ((((((((((((data[:,9]) + ((((((data[:,9]) / 2.0)) + (((data[:,9]) * 2.0)))/2.0)))/2.0)) + ((-1.0*((data[:,21])))))/2.0)) * (data[:,9]))) + (((((np.tanh((((data[:,21]) / 2.0)))) / 2.0)) / 2.0)))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((0.0)) + (data[:,13]))/2.0)) +\n",
    "                0.250000*np.tanh((((((((data[:,2]) / 2.0)) * 2.0)) + (data[:,7]))/2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,14]) * 2.0)) + (np.tanh((data[:,14]))))/2.0)) +\n",
    "                0.250000*np.tanh(np.tanh((((((((((-1.0*((((np.tanh((data[:,9]))) / 2.0))))) / 2.0)) / 2.0)) + (((data[:,3]) * (data[:,13]))))/2.0)))) +\n",
    "                0.250000*np.tanh((-1.0*((((((((-1.0*(((((((-1.0*((data[:,18])))) - ((((0.0)) / 2.0)))) / 2.0))))) + (np.tanh(((((-1.0*(((-1.0*((data[:,22]))))))) / 2.0)))))/2.0)) / 2.0))))))\n",
    "    \n",
    "    def GP_class_13(self,data):\n",
    "        return(0.250000*np.tanh(((((np.tanh((np.tanh((data[:,2]))))) - ((10.0)))) - (np.tanh((((((data[:,7]) - ((((((6.0)) - ((4.87243366241455078)))) - ((9.0)))))) - ((14.80352973937988281)))))))) +\n",
    "                0.250000*np.tanh(((np.tanh((((((3.0)) + (data[:,1]))/2.0)))) - ((7.0)))) +\n",
    "                0.250000*np.tanh(((((np.tanh((np.tanh((np.tanh((data[:,6]))))))) * 2.0)) - ((6.10337877273559570)))) +\n",
    "                0.250000*np.tanh(((((((data[:,9]) + (data[:,14]))) + (data[:,14]))) + (data[:,14]))) +\n",
    "                0.250000*np.tanh(((((((np.tanh(((((-1.0*(((((((data[:,2]) + ((10.0)))/2.0)) / 2.0))))) - ((13.28130435943603516)))))) + ((10.0)))) - ((13.28130435943603516)))) + ((-1.0*((data[:,5])))))) +\n",
    "                0.250000*np.tanh(((((((((((data[:,20]) + (((((((((data[:,20]) * 2.0)) * 2.0)) * 2.0)) + (data[:,13]))))/2.0)) + (((data[:,9]) + (((data[:,9]) + (((data[:,6]) + (data[:,9]))))))))/2.0)) + (data[:,20]))) + (data[:,15]))) +\n",
    "                0.250000*np.tanh(((((((((data[:,14]) / 2.0)) + ((((data[:,9]) + (((data[:,15]) + (((data[:,5]) + ((((((data[:,9]) + (((data[:,5]) + (data[:,14]))))) + (data[:,9]))/2.0)))))))/2.0)))) * 2.0)) + (data[:,14]))) +\n",
    "                0.250000*np.tanh((((data[:,13]) + (data[:,7]))/2.0)) +\n",
    "                0.250000*np.tanh(((data[:,9]) + ((((data[:,3]) + ((((data[:,21]) + (data[:,3]))/2.0)))/2.0)))) +\n",
    "                0.250000*np.tanh((((data[:,2]) + (((((((((((((((data[:,20]) + (data[:,1]))) + (((data[:,2]) + (data[:,14]))))) + (data[:,2]))) + (np.tanh((data[:,2]))))/2.0)) + (((data[:,14]) + (data[:,2]))))) + (data[:,14]))/2.0)))/2.0)))\n",
    "    \n",
    "    def GP_class_14(self,data):\n",
    "        return(0.250000*np.tanh((((((((((((5.54024744033813477)) - ((((((9.0)) * 2.0)) * 2.0)))) - (data[:,0]))) - ((((7.0)) + ((4.74105215072631836)))))) - (((((7.0)) + (((data[:,5]) * 2.0)))/2.0)))) - ((9.0)))) +\n",
    "                0.250000*np.tanh(((((((((9.0)) - ((14.27298927307128906)))) - (data[:,0]))) + (np.tanh(((((12.77708148956298828)) - ((14.80560111999511719)))))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((0.0)) + ((-1.0*((((data[:,22]) + (((((((((13.30077362060546875)) - (np.tanh((data[:,4]))))) + (((data[:,22]) / 2.0)))/2.0)) / 2.0))))))))/2.0)) - (((np.tanh((((data[:,7]) - (data[:,7]))))) / 2.0)))) +\n",
    "                0.250000*np.tanh(((((((data[:,6]) + (data[:,14]))/2.0)) + (((np.tanh((((((data[:,14]) + (data[:,14]))) + (((data[:,6]) - (((data[:,5]) + (((np.tanh((data[:,21]))) + ((((data[:,14]) + ((((data[:,14]) + (data[:,14]))/2.0)))/2.0)))))))))))) + (data[:,5]))))/2.0)) +\n",
    "                0.250000*np.tanh((((((((((((((((((data[:,2]) + (data[:,16]))) + ((((((data[:,2]) / 2.0)) + (data[:,9]))/2.0)))/2.0)) + (np.tanh((data[:,10]))))/2.0)) + (data[:,9]))) + (data[:,9]))/2.0)) + (data[:,21]))) + (data[:,3]))) +\n",
    "                0.250000*np.tanh((((data[:,13]) + (((((((((((data[:,3]) / 2.0)) / 2.0)) / 2.0)) * (data[:,3]))) / 2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((data[:,14]) + (((((((data[:,14]) / 2.0)) + (data[:,14]))) * 2.0)))) +\n",
    "                0.250000*np.tanh(data[:,9]) +\n",
    "                0.250000*np.tanh(((data[:,1]) / 2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,2]) + ((((((data[:,13]) + (data[:,14]))) + (data[:,13]))/2.0)))) + (np.tanh((data[:,2]))))/2.0)))\n",
    "    \n",
    "    def GP_class_15(self,data):\n",
    "        return(0.250000*np.tanh((((((((4.0)) + ((((8.0)) / 2.0)))) - ((9.56193733215332031)))) - (((((np.tanh(((13.93556308746337891)))) - (data[:,18]))) + ((13.93556308746337891)))))) +\n",
    "                0.250000*np.tanh(((data[:,4]) - ((((12.76094818115234375)) - (data[:,8]))))) +\n",
    "                0.250000*np.tanh((((-1.0*(((12.35446166992187500))))) - (((((12.35446166992187500)) + ((((((12.35446166992187500)) - ((-1.0*(((0.0))))))) - (data[:,0]))))/2.0)))) +\n",
    "                0.250000*np.tanh(((data[:,21]) - ((14.46367263793945312)))) +\n",
    "                0.250000*np.tanh(((((data[:,2]) + ((((data[:,9]) + ((-1.0*(((-1.0*(((-1.0*((((data[:,7]) * (((data[:,21]) * 2.0))))))))))))))/2.0)))) + (data[:,9]))) +\n",
    "                0.250000*np.tanh(((((((((((data[:,7]) + (data[:,3]))/2.0)) + (data[:,20]))/2.0)) - ((((2.33354020118713379)) / 2.0)))) - ((((2.0)) + ((8.78930377960205078)))))) +\n",
    "                0.250000*np.tanh(((((((data[:,14]) + (((((((data[:,14]) + (((data[:,15]) + (data[:,14]))))) + (((data[:,15]) + (data[:,14]))))) + (((data[:,14]) / 2.0)))))) + (data[:,14]))) + (data[:,14]))) +\n",
    "                0.250000*np.tanh(((((((((data[:,13]) + (data[:,13]))) + (((data[:,13]) + (data[:,12]))))) + (data[:,9]))) + ((((((data[:,9]) + (((data[:,13]) + ((((data[:,9]) + (((((data[:,13]) * 2.0)) / 2.0)))/2.0)))))/2.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((data[:,9]) + ((((((data[:,9]) + (data[:,9]))/2.0)) / 2.0)))/2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,14]) + (data[:,8]))) + (data[:,14]))/2.0)))\n",
    "    \n",
    "    def GP_class_16(self,data):\n",
    "        return(0.250000*np.tanh(((((((((((((9.37592792510986328)) - ((13.36316204071044922)))) + ((11.89122962951660156)))/2.0)) - ((((9.0)) - (((((((data[:,13]) / 2.0)) / 2.0)) + ((((-1.0*((((data[:,4]) / 2.0))))) * 2.0)))))))) - ((12.24639320373535156)))) - ((11.89122581481933594)))) +\n",
    "                0.250000*np.tanh(((((np.tanh(((4.51821422576904297)))) - ((13.23712635040283203)))) - ((((((13.23712635040283203)) + (((data[:,22]) - ((((11.40539550781250000)) - (((((9.0)) + ((((((((data[:,7]) + (((data[:,17]) / 2.0)))/2.0)) * 2.0)) / 2.0)))/2.0)))))))) - (data[:,5]))))) +\n",
    "                0.250000*np.tanh(((data[:,14]) - ((((4.0)) + (((((13.41770648956298828)) + ((12.42538261413574219)))/2.0)))))) +\n",
    "                0.250000*np.tanh((((5.0)) - ((9.27778816223144531)))) +\n",
    "                0.250000*np.tanh(((((data[:,16]) - (((((((data[:,1]) - (((np.tanh((((((((9.29507255554199219)) - (((((((14.34461498260498047)) * 2.0)) + (((((7.0)) + ((9.10683441162109375)))/2.0)))/2.0)))) + ((4.21145153045654297)))/2.0)))) * 2.0)))) - ((9.10683441162109375)))) * 2.0)))) - ((((14.34461498260498047)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((((((((data[:,17]) / 2.0)) + (((data[:,13]) + (data[:,9]))))/2.0)) + (((data[:,17]) + (data[:,9]))))) + (data[:,0]))) +\n",
    "                0.250000*np.tanh(((data[:,13]) + (((data[:,14]) - (data[:,21]))))) +\n",
    "                0.250000*np.tanh((((((data[:,14]) + (data[:,5]))/2.0)) + (((((((data[:,9]) / 2.0)) + (data[:,14]))) / 2.0)))) +\n",
    "                0.250000*np.tanh((((((data[:,17]) + (data[:,9]))) + (((((data[:,17]) / 2.0)) + ((((((((((data[:,9]) + (data[:,9]))) - ((3.0)))) + (data[:,7]))) + (data[:,9]))/2.0)))))/2.0)) +\n",
    "                0.250000*np.tanh(np.tanh(((((((((((((((data[:,2]) + (((((((((((data[:,22]) + (data[:,21]))/2.0)) + (data[:,2]))/2.0)) * 2.0)) + ((((((data[:,21]) * 2.0)) + (data[:,21]))/2.0)))))) + (data[:,2]))/2.0)) + (data[:,17]))/2.0)) + (np.tanh((data[:,8]))))/2.0)) + (data[:,2]))))))\n",
    "    \n",
    "    def GP_class_17(self,data):\n",
    "        return(0.250000*np.tanh(((((data[:,14]) - ((((data[:,5]) + (((((14.43326377868652344)) + ((6.0)))/2.0)))/2.0)))) - (((((((10.0)) + ((14.84462165832519531)))/2.0)) - ((((7.0)) + (data[:,13]))))))) +\n",
    "                0.250000*np.tanh((((((((((data[:,14]) + (((((((((data[:,11]) - ((9.71331787109375000)))) / 2.0)) + ((9.0)))) - ((3.0)))))/2.0)) - ((10.0)))) - ((((10.0)) + ((((9.0)) - ((((((10.0)) - ((9.0)))) / 2.0)))))))) - ((10.0)))) +\n",
    "                0.250000*np.tanh((((((((((8.0)) - ((12.78277492523193359)))) - (data[:,10]))) - (np.tanh(((((((7.0)) - ((14.95321178436279297)))) - ((8.0)))))))) - ((14.95321178436279297)))) +\n",
    "                0.250000*np.tanh((((7.45682907104492188)) - ((14.98023796081542969)))) +\n",
    "                0.250000*np.tanh(((((((((((7.0)) + (((((np.tanh((((((((8.0)) * (data[:,8]))) + (data[:,11]))/2.0)))) / 2.0)) - ((8.0)))))/2.0)) - (data[:,20]))) - ((((8.0)) * 2.0)))) + ((8.0)))) +\n",
    "                0.250000*np.tanh(((data[:,8]) + (((data[:,4]) + (((np.tanh((data[:,4]))) + (((data[:,13]) + (data[:,13]))))))))) +\n",
    "                0.250000*np.tanh(data[:,14]) +\n",
    "                0.250000*np.tanh(((((((((((data[:,14]) + (np.tanh((((data[:,3]) * (data[:,13]))))))) + (data[:,14]))) + (data[:,0]))) + (data[:,8]))) / 2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,9]) + (np.tanh(((((((data[:,19]) * (((((((data[:,1]) + (((((((data[:,21]) + (data[:,9]))/2.0)) + (data[:,6]))/2.0)))/2.0)) + (data[:,17]))/2.0)))) + (((data[:,15]) / 2.0)))/2.0)))))/2.0)) * 2.0)) +\n",
    "                0.250000*np.tanh(((data[:,1]) + (((((data[:,3]) + (data[:,15]))) + (np.tanh(((((data[:,20]) + (((data[:,1]) * 2.0)))/2.0)))))))))\n",
    "    \n",
    "    def GP_class_18(self,data):\n",
    "        return(0.250000*np.tanh((((((((((12.59485149383544922)) - ((12.59485149383544922)))) - ((12.59485149383544922)))) - ((((11.47756862640380859)) / 2.0)))) - ((12.59485149383544922)))) +\n",
    "                0.250000*np.tanh((((((-1.0*(((11.26121807098388672))))) - (((((((((11.33140659332275391)) - ((-1.0*(((9.76293182373046875))))))) - (((((11.33140659332275391)) + ((8.0)))/2.0)))) + ((9.76293182373046875)))/2.0)))) - (data[:,11]))) +\n",
    "                0.250000*np.tanh(((((((((((3.40250444412231445)) - (np.tanh(((14.86789989471435547)))))) - ((14.86789989471435547)))) + ((((((data[:,5]) + ((-1.0*(((((14.86789989471435547)) * 2.0))))))/2.0)) - ((14.86789989471435547)))))/2.0)) - (((((14.86789989471435547)) + (((((7.0)) + ((-1.0*((data[:,16])))))/2.0)))/2.0)))) +\n",
    "                0.250000*np.tanh(((data[:,18]) - ((11.84332561492919922)))) +\n",
    "                0.250000*np.tanh(((((np.tanh(((((8.96548557281494141)) * (data[:,12]))))) - ((-1.0*((((data[:,2]) * (((((data[:,4]) - ((-1.0*((data[:,9])))))) - ((9.0))))))))))) - ((8.96548557281494141)))) +\n",
    "                0.250000*np.tanh(((((((10.0)) - (data[:,12]))) + (((((((((data[:,13]) - ((12.43707370758056641)))) - ((((12.43707370758056641)) - (((data[:,12]) / 2.0)))))) - ((((12.43707370758056641)) - ((((data[:,13]) + ((12.43707370758056641)))/2.0)))))) - ((12.43707370758056641)))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((np.tanh((((np.tanh((data[:,14]))) + (data[:,13]))))) * 2.0)) + (data[:,14]))) + (data[:,13]))) +\n",
    "                0.250000*np.tanh(((np.tanh((data[:,14]))) + (data[:,14]))) +\n",
    "                0.250000*np.tanh(((((data[:,9]) + (((((data[:,13]) + (data[:,4]))) + (data[:,13]))))) / 2.0)) +\n",
    "                0.250000*np.tanh(((data[:,15]) - ((((data[:,3]) + ((5.0)))/2.0)))))\n",
    "    \n",
    "    def GP_class_19(self,data):\n",
    "        return(0.250000*np.tanh((((((data[:,13]) + (data[:,13]))/2.0)) + ((((((data[:,8]) + ((((data[:,14]) + (data[:,14]))/2.0)))/2.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((data[:,3]) + (((data[:,8]) + (np.tanh(((((((-1.0*((((((9.05535793304443359)) + ((((data[:,14]) + (((((((data[:,1]) - (((data[:,12]) * 2.0)))) * ((-1.0*((data[:,17])))))) / 2.0)))/2.0)))/2.0))))) + (data[:,2]))) * 2.0)))))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((data[:,3]) + (((((data[:,14]) + (data[:,14]))) * 2.0)))) + ((((data[:,14]) + (np.tanh((((data[:,14]) + (np.tanh((data[:,14]))))))))/2.0)))) * 2.0)) + ((((data[:,14]) + (data[:,2]))/2.0)))) +\n",
    "                0.250000*np.tanh(((((data[:,8]) + (((data[:,4]) + (((data[:,13]) + (data[:,10]))))))) + (((((data[:,13]) + (((((data[:,13]) / 2.0)) + (data[:,9]))))) + (np.tanh(((((data[:,8]) + (data[:,8]))/2.0)))))))) +\n",
    "                0.250000*np.tanh((((((data[:,19]) + (((((data[:,10]) + ((((data[:,11]) + (data[:,19]))/2.0)))) + (data[:,10]))))/2.0)) + (data[:,2]))) +\n",
    "                0.250000*np.tanh((((((data[:,0]) + (((((((((data[:,0]) + (((((data[:,0]) - (data[:,11]))) / 2.0)))/2.0)) * 2.0)) + ((((((np.tanh((data[:,13]))) + (((data[:,0]) / 2.0)))/2.0)) / 2.0)))/2.0)))/2.0)) * 2.0)) +\n",
    "                0.250000*np.tanh(((((-1.0*((data[:,15])))) + (((data[:,14]) + (data[:,14]))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((data[:,0]) + (data[:,15]))/2.0)) + (((data[:,15]) * (data[:,15]))))/2.0)) - (data[:,11]))) +\n",
    "                0.250000*np.tanh(data[:,13]) +\n",
    "                0.250000*np.tanh(((((((((data[:,18]) + ((((data[:,4]) + (data[:,18]))/2.0)))) / 2.0)) + ((((data[:,18]) + (data[:,4]))/2.0)))) * (data[:,4])))    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time for the actual submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission file has been saved!  Once you `Commit` your Notebook and it finishes running, you can submit the file to the competition from the Notebook Viewer `Output` tab.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from kaggle.competitions import nflrush\n",
    "env = nflrush.make_env()\n",
    "iter_test = env.iter_test()\n",
    "gp = GP()\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    basetable = create_features(test_df, deploy=True)\n",
    "    basetable.drop(['GameId','PlayId'], axis=1, inplace=True)\n",
    "    scaled_basetable = scaler.transform(basetable)\n",
    "    \n",
    "    y_pred_nn = model.predict(scaled_basetable)\n",
    "\n",
    "    y_pred_gp = np.zeros((test_df.shape[0],199))\n",
    "    ans = gp.GrabPredictions(scaled_basetable)\n",
    "    y_pred_gp[:,96:96+20] = ans\n",
    "    \n",
    "    y_pred = (.6*y_pred_nn+.4*y_pred_gp)\n",
    "    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1).tolist()[0]\n",
    "    \n",
    "    preds_df = pd.DataFrame(data=[y_pred], columns=sample_prediction_df.columns)\n",
    "    env.predict(preds_df)\n",
    "    \n",
    "env.write_submission_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
