{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Kaggle\n## Competition NFL Big Data Bowl"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/nfl-big-data-bowl-2020/train.csv\n/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/test.csv.encrypted\n/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/sample_submission.csv.encrypted\n/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/__init__.py\n/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/competition.cpython-36m-x86_64-linux-gnu.so\n","name":"stdout"}]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# Carregando os pacotes\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Statistic lib\nfrom scipy import stats\nfrom scipy.stats import skew, norm\n\n# Sklearn lib\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder\n\n# Models\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom mlxtend.regressor import StackingCVRegressor\nfrom lightgbm import LGBMRegressor\nimport lightgbm as lgb\nimport xgboost as XGB\nfrom sklearn.cluster import KMeans\nimport tqdm\n\n# Misc lib\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom functools import partial\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import make_pipeline\nfrom IPython.display import Image\n\n# Utils\nimport pandasql as ps\nimport re \nimport math, string, os\nimport datetime\n\n# Options\nimport warnings\nwarnings.filterwarnings('ignore')\npd.options.display.max_seq_items = 8000\npd.options.display.max_rows = 8000\npd.set_option('display.max_columns', None)\nimport gc\ngc.enable()","execution_count":2,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"f5fdc987f79035336b408413b3b3111d1b48fd2a","trusted":true},"cell_type":"code","source":"# Carregando os dados de treino\n#train = pd.read_csv('../data/train.csv', low_memory=False)\ntrain = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', low_memory=False)\nprint (\"Data is ready !!\")","execution_count":3,"outputs":[{"output_type":"stream","text":"Data is ready !!\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Criando as funções auxiliares de limpeza e conversao"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Funcao para tratar os dados missing de cada variavel\ndef fill_na(data):\n    data['WindDirection'].fillna('unknown',inplace=True)\n    data['OffenseFormation'].fillna('unknown',inplace=True)\n    data['StadiumType'].fillna('unknown',inplace=True)\n    data['GameWeather'].fillna('unknown',inplace=True)\n    data['FieldPosition'].fillna('NA',inplace=True)\n    \n    data['Temperature'].fillna(data['Temperature'].mean(), inplace=True)\n    data['Humidity'].fillna(data['Humidity'].mean(), inplace=True)\n    data['DefendersInTheBox'].fillna(math.ceil(data['DefendersInTheBox'].mean()),inplace=True)\n    \n# Funcao para agrupar as descricoes dos tipos de estadio\ndef agrupar_tipo_estadio(StadiumType):\n    outdoor       = ['Outdoor', 'Outdoors', 'Cloudy', 'Heinz Field', 'Outdor', 'Ourdoor', 'Outside', 'Outddors', 'Outdoor Retr Roof-Open', 'Oudoor', 'Bowl']\n    indoor_closed = ['Indoors', 'Indoor', 'Indoor, Roof Closed', 'Indoor, Roof Closed', 'Retractable Roof', 'Retr. Roof-Closed', 'Retr. Roof - Closed', 'Retr. Roof Closed']\n    indoor_open   = ['Indoor, Open Roof', 'Open', 'Retr. Roof-Open', 'Retr. Roof - Open']\n    dome_closed   = ['Dome', 'Domed, closed', 'Closed Dome', 'Domed', 'Dome, closed']\n    dome_open     = ['Domed, Open', 'Domed, open']\n    \n    if StadiumType in outdoor:\n        return 'outdoor'\n    elif StadiumType in indoor_closed:\n        return 'indoor_closed'\n    elif StadiumType in indoor_open:\n        return 'indoor_open'\n    elif StadiumType in dome_closed:\n        return 'dome_closed'\n    elif StadiumType in dome_open:\n        return 'dome_open'\n    else:\n        return 'unknown' # se for n/a\n    \n# Funcao para agrupar as descricoes dos estadios\ndef agrupar_estadio(Stadium):\n\n    if Stadium == 'Broncos Stadium at Mile High':\n        return 'Broncos Stadium At Mile High'\n    \n    elif Stadium in ('CenturyField', 'CenturyLink'):\n        return 'CenturyLink Field'\n    \n    elif Stadium == 'EverBank Field':\n        return 'Everbank Field'\n    \n    elif Stadium in ('FirstEnergy', 'FirstEnergy Stadium', 'FirstEnergyStadium'):\n        return 'First Energy Stadium'\n   \n    elif Stadium == 'Lambeau field':\n        return 'Lambeau Field'\n\n    elif Stadium == 'Los Angeles Memorial Coliesum':\n        return 'Los Angeles Memorial Coliseum'\n    \n    elif Stadium in ('M & T Bank Stadium', 'M&T Stadium'):\n        return 'M&T Bank Stadium'\n\n    elif Stadium in ('Mercedes-Benz Dome', 'Mercedes-Benz Superdome'):\n        return 'Mercedes-Benz SuperDome'\n    \n    elif Stadium in ('MetLife Stadium', 'Metlife Stadium', 'MetLife'):\n        return 'MetLife Stadium' \n    \n    elif Stadium == 'NRG':\n        return 'NRG Stadium' \n\n    elif Stadium == 'Oakland-Alameda County Coliseum':\n        return 'Oakland Alameda-County Coliseum' \n    \n    elif Stadium == 'Paul Brown Stdium':\n        return 'Paul Brown Stadium' \n\n    elif Stadium == 'Twickenham':\n        return 'Twickenham Stadium' \n    \n    else:\n        return Stadium\n    \n# Funcao para agrupar a localizacao do estadio e do jogo\ndef agrupar_local(Location):\n\n    if Location == \"Arlington, Texas\":\n        return \"Arlington, TX\"\n    elif Location in (\"Baltimore, Maryland\",\"Baltimore, Md.\"):\n        return \"Baltimore, MD\"\n    elif Location == \"Charlotte, North Carolina\":\n        return \"Charlotte, NC\"\n    elif Location == \"Chicago. IL\":\n        return \"Chicago, IL\"\n    elif Location == \"Cincinnati, Ohio\":\n        return \"Cincinnati, OH\"\n    elif Location in (\"Cleveland\",\"Cleveland Ohio\",\"Cleveland, Ohio\",\"Cleveland,Ohio\"):\n        return \"Cleveland, OH\"\n    elif Location == \"Detroit\":\n        return \"Detroit, MI\"\n    elif Location == \"E. Rutherford, NJ\" or Location == \"East Rutherford, N.J.\":\n        return \"East Rutherford, NJ\"\n    elif Location == \"Foxborough, Ma\":\n        return \"Foxborough, MA\"\n    elif Location == \"Houston, Texas\":\n        return \"Houston, TX\"\n    elif Location in (\"Jacksonville Florida\",\"Jacksonville, Fl\",\"Jacksonville, Florida\"):\n        return \"Jacksonville, FL\"\n    elif Location == \"London\":\n        return \"London, England\"\n    elif Location == \"Los Angeles, Calif.\":\n        return \"Los Angeles, CA\"\n    elif Location == \"Miami Gardens, Fla.\":\n        return \"Miami Gardens, FLA\"\n    elif Location in (\"New Orleans\",\"New Orleans, La.\"):\n        return \"New Orleans, LA\"\n    elif Location == \"Orchard Park NY\":\n        return \"Orchard Park, NY\"\n    elif Location == \"Philadelphia, Pa.\":\n        return \"Philadelphia, PA\"\n    elif Location == \"Pittsburgh\":\n        return \"Pittsburgh, PA\"\n    elif Location == \"Seattle\":\n        return \"Seattle, WA\"\n    else:\n        return Location\n    \n# Funcao para agrupar o gramado do estadio\ndef agrupar_gramado(Turf):\n    if Turf == 'Artifical':\n        return 'Artificial'\n    \n    elif Turf in ('FieldTurf', 'Field turf'):\n        return 'Field Turf'\n\n    elif Turf in ('FieldTurf360', 'FieldTurf 360'):\n        return 'Field Turf 360'\n\n    elif Turf in ('Natural', 'Natural grass', 'Naturall Grass', 'grass', 'natural grass', 'SISGrass', 'Natural Grass'):\n        return \"Grass\"\n\n    elif Turf == \"UBU Sports Speed S5-M\":\n        return \"UBU Speed Series-S5-M\"\n\n    else:\n        return Turf\n\n# Funcao para agrupar os dados de direcao do vento\ndef agrupa_wind_direction(WindDirection):\n    wd = str(WindDirection).upper()\n    \n    if wd == 'N' or 'FROM N' in wd:\n        return 'north'\n    if wd == 'S' or 'FROM S' in wd:\n        return 'south'\n    if wd == 'W' or 'FROM W' in wd:\n        return 'west'\n    if wd == 'E' or 'FROM E' in wd:\n        return 'east'\n    \n    if 'FROM SW' in wd or 'FROM SSW' in wd or 'FROM WSW' in wd:\n        return 'south west'\n    if 'FROM SE' in wd or 'FROM SSE' in wd or 'FROM ESE' in wd:\n        return 'south east'\n    if 'FROM NW' in wd or 'FROM NNW' in wd or 'FROM WNW' in wd:\n        return 'north west'\n    if 'FROM NE' in wd or 'FROM NNE' in wd or 'FROM ENE' in wd:\n        return 'north east'\n    \n    if 'NW' in wd or 'NORTHWEST' in wd:\n        return 'north west'\n    if 'NE' in wd or 'NORTH EAST' in wd:\n        return 'north east'\n    if 'SW' in wd or 'SOUTHWEST' in wd:\n        return 'south west'\n    if 'SE' in wd or 'SOUTHEAST' in wd:\n        return 'south east'\n\n    return 'unknown'\n\n# Funcao para agrupar as descricoes de clima\ndef agrupar_clima(GameWeather):\n    chuva   = ['Rainy', 'Rain Chance 40%', 'Showers',\n               'Cloudy with periods of rain, thunder possible. Winds shifting to WNW, 10-20 mph.',\n               'Scattered Showers', 'Cloudy, Rain', 'Rain shower', 'Light Rain', 'Rain']\n    nublado = ['Cloudy, light snow accumulating 1-3\"', 'Party Cloudy', 'Cloudy, chance of rain',\n               'Coudy', 'Cloudy, 50% change of rain', 'Rain likely, temps in low 40s.',\n               'Cloudy and cold', 'Cloudy, fog started developing in 2nd quarter',\n               'Partly Clouidy', '30% Chance of Rain', 'Mostly Coudy', 'Cloudy and Cool',\n               'cloudy', 'Partly cloudy', 'Overcast', 'Hazy', 'Mostly cloudy', 'Mostly Cloudy',\n               'Partly Cloudy', 'Cloudy']\n    limpo   = ['Partly clear', 'Sunny and clear', 'Sun & clouds', 'Clear and Sunny',\n               'Sunny and cold', 'Sunny Skies', 'Clear and Cool', 'Clear and sunny',\n               'Sunny, highs to upper 80s', 'Mostly Sunny Skies', 'Cold',\n               'Clear and warm', 'Sunny and warm', 'Clear and cold', 'Mostly sunny',\n               'T: 51; H: 55; W: NW 10 mph', 'Clear Skies', 'Clear skies', 'Partly sunny',\n               'Fair', 'Partly Sunny', 'Mostly Sunny', 'Clear', 'Sunny']\n    neve    = ['Heavy lake effect snow', 'Snow']\n    none    = ['N/A Indoor', 'Indoors', 'Indoor', 'N/A (Indoors)', 'Controlled Climate']\n\n    \n    if GameWeather in chuva:\n        return 'chuva'\n    elif GameWeather in nublado:\n        return 'nublado'\n    elif GameWeather in limpo:\n        return 'limpo'\n    elif GameWeather in neve:\n        return 'neve'\n    elif GameWeather in none:\n        return 'none'\n    else:\n        return 'none' # se for n/a\n    \n# Funcao para converter a velocidade do vento\ndef convert_wind_speed(WindSpeed):\n    ws = str(WindSpeed)\n\n    if ws.isdigit():\n        return int(ws)\n\n    if '-' in ws:\n        return int(ws.split('-')[0])\n\n    if ws.split(' ')[0].isdigit():\n        return int(ws.split(' ')[0])\n\n    if 'mph' in ws.lower():\n        return int(ws.lower().split('mph')[0])\n    else:\n        return 0\n    \n    \n# Funcao para converter altura de feet-inches para centimetros\ndef convert_to_cm(ft_in):\n    h_ft   = int(ft_in.split('-')[0])\n    h_inch = int(ft_in.split('-')[1])\n    h_inch += h_ft * 12\n    h_cm = round(h_inch * 2.54, 1)\n    #print(\"Your height is : %d cm.\" % h_cm)   \n    \n    return h_cm\n\n# Funcao para converter peso em lbs para kg\ndef convert_to_kg(lbs):\n    kg = lbs * 0.45359237\n    #print(\"The weight is\", kg, \"in kilograms\")\n    \n    return kg\n\n# Funcao para converter temperatura Fahrenheit para Celsius\ndef convert_to_celsius(fah):\n    celsius = (fah - 32) * 5.0/9.0\n    #print(\"Temperature:\", fah, \"Fahrenheit = \", celsius, \" C\")\n    return celsius\n\n# Funcao para converter as features de data e extrair dia, mes, ano, hora, minuto, segundo\ndef convert_data(data):\n    #data['PlayerBirthDate'] = pd.to_datetime(data['PlayerBirthDate'], \"%m/%d/%Y\")\n    data['PlayerBirthDate'] = data['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n    data['PlayerBirthDate_day'] = data['PlayerBirthDate'].dt.day.astype(int)\n    data['PlayerBirthDate_month'] = data['PlayerBirthDate'].dt.month.astype(int)\n    data['PlayerBirthDate_year'] = data['PlayerBirthDate'].dt.year.astype(int)\n\n    data['TimeSnap'] = data['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    #data['TimeSnap'] = pd.to_datetime(data['TimeSnap'], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n    data['TimeSnap_min'] = data['TimeSnap'].dt.minute.astype(int)\n    data['TimeSnap_seg'] = data['TimeSnap'].dt.second.astype(int)\n    \n    data['TimeHandoff'] = data['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    #data['TimeHandoff'] = pd.to_datetime(data['TimeHandoff'], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n    data['TimeHandoff_min'] = data['TimeHandoff'].dt.minute.astype(int)\n    data['TimeHandoff_seg'] = data['TimeHandoff'].dt.second.astype(int)\n    \n    \n# Funcao para converter uma string horario em segundos\ndef str_to_seconds(time):\n    time = time.split(':')\n    sec = int(time[0])*60 + int(time[1]) + int(time[2])/60\n    return sec\n\n# Funcao para a metrica de validacao do modelo\ndef funcao_crps(labels,predictions) :\n    y_pred = np.zeros((len(labels),199))\n    y_ans = np.zeros((len(labels),199))\n    j = np.array(range(199))\n    for i,(p,t) in enumerate(zip(np.round(scaler.inverse_transform(predictions)),labels)) :\n        k2 = j[j>=p-10]\n        y_pred[i][k2]=(k2+10-p)*0.05\n        k1 = j[j>=p+10]\n        y_pred[i][k1]= 1.0\n        k3 = j[j>=t]\n        y_ans[i][k3]= 1.0\n                           \n    return 'CRPS: ', np.sum((y_pred-y_ans)**2)/(199*y_pred.shape[0]), False","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Funcao para realizar feature engineering no dataset (treino ou teste)\ndef feature_engineering(df): \n    \n    # Limpeza e conversao dos dados\n    fill_na(df)\n    convert_data(df)\n    \n    df_median = df.median()\n    \n    # Conversao de algumas features\n    df['PlayerHeight']  = df['PlayerHeight'].apply(convert_to_cm)\n    df['PlayerWeight']  = df['PlayerWeight'].apply(convert_to_kg)\n    df['Temperature']   = df['Temperature'].apply(convert_to_celsius)\n    df['StadiumType']   = df['StadiumType'].apply(agrupar_tipo_estadio)\n    df['Stadium']       = df['Stadium'].apply(agrupar_estadio)\n    df['Location']      = df['Location'].apply(agrupar_local)\n    df['Turf']          = df['Turf'].apply(agrupar_gramado)\n    df['WindDirection'] = df['WindDirection'].apply(agrupa_wind_direction)\n    df['WindSpeed']     = df['WindSpeed'].apply(convert_wind_speed)\n    df['GameWeather']   = df['GameWeather'].apply(agrupar_clima)\n\n\n    # Corrigindo a feature Stadium\n    df.loc[df['Stadium'] == 'MetLife Stadium', 'StadiumType'] = 'outdoor'\n    df.loc[df['Stadium'] == 'StubHub Center', 'StadiumType'] = 'outdoor'    \n    \n    # Nova feature com a diferença entre o tempo de lançamento da bola até quando o jogador captura\n    df['TimeDifer'] = df.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)            \n         \n    # Nova feature para indicar se é o jogador que esta realizando a jogada (corredor)\n    df['IsRusher'] = df['NflId'] == df['NflIdRusher']\n    \n    # Novas features com base no horario do jogo\n    df['Morning']   = df['GameClock'].apply(lambda x : 1 if (int(x[0:2]) >=0 and int(x[0:2]) <12) else 0)\n    df['Afternoon'] = df['GameClock'].apply(lambda x : 1 if (int(x[0:2]) <18 and int(x[0:2]) >=12) else 0)\n    df['Evening']   = df['GameClock'].apply(lambda x : 1 if (int(x[0:2]) >= 18 and int(x[0:2]) < 24) else 0)\n    df['GameClock'] = df['GameClock'].apply(str_to_seconds) \n    \n    # Criando novas features com dados de Distance, YardLine e DefendersInTheBox\n    df['seconds_need_to_first_down'] = (df['Distance']*0.9144)/df['Dis']\n    df['seconds_need_to_YardsLine'] = (df['YardLine']*0.9144)/df['Dis']    \n    df['DefendersInTheBox_vs_Distance'] = df['DefendersInTheBox'] / df['Distance']\n    \n    # Ordenacao do dataset e renovando o index\n    df = df.sort_values(by=['PlayId', 'Team', 'IsRusher']).reset_index()\n    \n    # Removendo colunas que não serão utilizadas\n    df = df.drop(['index','Yards','GameId','PlayId','NflId', 'DisplayName','NflIdRusher', 'TimeHandoff', 'TimeSnap', 'PlayerBirthDate'], axis=1)\n\n    # Atribuindo media para os demais dados missing\n    df.fillna(df_median, inplace=True)\n\n    # Executar somente para alguns modelos que nao tratam valores INF ou NAN\n    #train_df.replace(-np.inf,0,inplace=True)\n    #train_df.replace(np.inf,0,inplace=True)\n\n    # Removendo todas as variaveis categoricas\n    cat_features = []\n    for col in df.columns:\n        if df[col].dtype =='object':\n            cat_features.append(col)\n\n    df = df.drop(cat_features, axis=1)\n    \n    return df","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando um novo dataset aplicando Feature Engineering\ntrain_df = feature_engineering(train)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"(509762, 38)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Criação e Validação dos Modelos de ML"},{"metadata":{},"cell_type":"markdown","source":"## Algumas considerações deste processo:\n- **Cross Validation:** Estou usando 5-fold cross-validation\n- **Models:** Light GBM Regression\n\n####  Validação\nContinuous Ranked Probability Score (CRPS) is derived based on the predicted scalar value.\nThe CRPS is computed as follows:\n$$\nC=\\frac{1}{199N}\\sum_{m=1}^N\\sum_{n=-99}^{99}(P(y\\geq n)-H(n-Y_m))^2\n$$\n$H(x)=1$ if $x\\geq 0$ else $0$"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fazendo uma limpeza na memoria\ngc.collect()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setup cross validation folds\nkf = 5\nfolds = KFold(n_splits=kf, shuffle=False, random_state=42)\nprint(str(kf) + ' Folds para treino...')","execution_count":9,"outputs":[{"output_type":"stream","text":"5 Folds para treino...\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Identificando as features para o modelo\nfeatures = list(train_df.columns)\nX = train_df[features]","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando matriz de treino\ntrain_data = np.zeros((509762//22,len(features))) \n\nfor i in tqdm.tqdm(range(0,509762,22)):\n    count=0\n    for c in features:\n        train_data[i//22][count] = train_df[c][i]\n        count+=1","execution_count":11,"outputs":[{"output_type":"stream","text":"100%|██████████| 23171/23171 [00:20<00:00, 1104.00it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split de dados e label\nX_train = pd.DataFrame(data=train_data,columns=features)\ny_train_ = np.array([train[\"Yards\"][i] for i in range(0,509762,22)])","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalizacao das features \ny_tr = np.zeros(len(y_train_),dtype=np.float)\nfor i in range(len(y_tr)):\n    y_tr[i]=(y_train_[i])\n\nscaler = preprocessing.StandardScaler()\nscaler.fit([[y] for y in y_tr])\ny_tr = np.array([y[0] for y in scaler.transform([[y] for y in y_tr])])","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params_lgb = {\n    \"boosting\": \"gbdt\",\n    \"verbosity\": -1,\n    \"num_leaves\":3,\n    \"min_data_in_leaf\": 10,\n    \"max_depth\": -1,\n    \"learning_rate\": 0.0005,\n    \"bagging_freq\": 4,\n    \"bagging_fraction\": 0.1,\n    \"bagging_seed\": 11,\n    \"feature_fraction\" : 1,\n    \"random_seed\": 19,\n    \"metric\": \"rmse\",\n    \"boost_from_average\" : False\n}","execution_count":14,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"oof = np.zeros(len(X_train))\ntr_rmse  = []\nval_rmse = []\nmodels   = []\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train,y_tr)):\n    strLog = \"fold {}\".format(fold_)\n    print(strLog)\n    \n    X_tr, X_val = train_df.iloc[trn_idx][features], train_df.iloc[val_idx][features]\n    train_y, y_val = y_tr[trn_idx], y_tr[val_idx]\n\n    model = lgb.LGBMRegressor(**best_params_lgb, n_estimators = 100, n_jobs = -1)\n    model.fit(X_tr, \n              train_y, \n              eval_set=[(X_tr, train_y), (X_val, y_val)], \n              eval_metric=funcao_crps,\n              verbose=10, \n              early_stopping_rounds=99)\n    \n    oof[val_idx] = model.predict(X_val)\n    \n    val_score = mean_squared_error(y_val, oof[val_idx])\n    val_rmse.append(val_score)\n    \n    tr_score = mean_squared_error(train_y, model.predict(X_tr))\n    tr_rmse.append(tr_score)\n    \n    models.append(model)","execution_count":15,"outputs":[{"output_type":"stream","text":"fold 0\nTraining until validation scores don't improve for 99 rounds.\n[10]\ttraining's rmse: 0.993689\ttraining's CRPS: : 0.0119145\tvalid_1's rmse: 1.02481\tvalid_1's CRPS: : 0.0119691\n[20]\ttraining's rmse: 0.993684\ttraining's CRPS: : 0.0119145\tvalid_1's rmse: 1.02481\tvalid_1's CRPS: : 0.0119691\n[30]\ttraining's rmse: 0.993677\ttraining's CRPS: : 0.0119145\tvalid_1's rmse: 1.02482\tvalid_1's CRPS: : 0.0119691\n[40]\ttraining's rmse: 0.99367\ttraining's CRPS: : 0.0119145\tvalid_1's rmse: 1.02482\tvalid_1's CRPS: : 0.0119691\n[50]\ttraining's rmse: 0.993661\ttraining's CRPS: : 0.0119145\tvalid_1's rmse: 1.02483\tvalid_1's CRPS: : 0.0119691\n[60]\ttraining's rmse: 0.993647\ttraining's CRPS: : 0.0119145\tvalid_1's rmse: 1.02482\tvalid_1's CRPS: : 0.0119691\n[70]\ttraining's rmse: 0.993639\ttraining's CRPS: : 0.0119145\tvalid_1's rmse: 1.02483\tvalid_1's CRPS: : 0.0119691\n[80]\ttraining's rmse: 0.993631\ttraining's CRPS: : 0.0119145\tvalid_1's rmse: 1.02483\tvalid_1's CRPS: : 0.0119691\n[90]\ttraining's rmse: 0.993624\ttraining's CRPS: : 0.0119145\tvalid_1's rmse: 1.02483\tvalid_1's CRPS: : 0.0119691\n[100]\ttraining's rmse: 0.99362\ttraining's CRPS: : 0.0119145\tvalid_1's rmse: 1.02482\tvalid_1's CRPS: : 0.0119691\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's rmse: 0.99362\ttraining's CRPS: : 0.0119145\tvalid_1's rmse: 1.02482\tvalid_1's CRPS: : 0.0119691\nfold 1\nTraining until validation scores don't improve for 99 rounds.\n[10]\ttraining's rmse: 1.00764\ttraining's CRPS: : 0.0119154\tvalid_1's rmse: 0.968809\tvalid_1's CRPS: : 0.0119653\n[20]\ttraining's rmse: 1.00763\ttraining's CRPS: : 0.0119154\tvalid_1's rmse: 0.968815\tvalid_1's CRPS: : 0.0119653\n[30]\ttraining's rmse: 1.00762\ttraining's CRPS: : 0.0119154\tvalid_1's rmse: 0.968807\tvalid_1's CRPS: : 0.0119653\n[40]\ttraining's rmse: 1.00762\ttraining's CRPS: : 0.0119154\tvalid_1's rmse: 0.968818\tvalid_1's CRPS: : 0.0119653\n[50]\ttraining's rmse: 1.00761\ttraining's CRPS: : 0.0119154\tvalid_1's rmse: 0.968814\tvalid_1's CRPS: : 0.0119653\n[60]\ttraining's rmse: 1.0076\ttraining's CRPS: : 0.0119154\tvalid_1's rmse: 0.968819\tvalid_1's CRPS: : 0.0119653\n[70]\ttraining's rmse: 1.0076\ttraining's CRPS: : 0.0119154\tvalid_1's rmse: 0.968825\tvalid_1's CRPS: : 0.0119653\n[80]\ttraining's rmse: 1.00759\ttraining's CRPS: : 0.0119154\tvalid_1's rmse: 0.968834\tvalid_1's CRPS: : 0.0119653\n[90]\ttraining's rmse: 1.00758\ttraining's CRPS: : 0.0119154\tvalid_1's rmse: 0.968832\tvalid_1's CRPS: : 0.0119653\n[100]\ttraining's rmse: 1.00757\ttraining's CRPS: : 0.0119154\tvalid_1's rmse: 0.968838\tvalid_1's CRPS: : 0.0119653\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's rmse: 1.00757\ttraining's CRPS: : 0.0119154\tvalid_1's rmse: 0.968838\tvalid_1's CRPS: : 0.0119653\nfold 2\nTraining until validation scores don't improve for 99 rounds.\n[10]\ttraining's rmse: 1.02665\ttraining's CRPS: : 0.0119227\tvalid_1's rmse: 0.88535\tvalid_1's CRPS: : 0.0119361\n[20]\ttraining's rmse: 1.02665\ttraining's CRPS: : 0.0119227\tvalid_1's rmse: 0.885358\tvalid_1's CRPS: : 0.0119361\n[30]\ttraining's rmse: 1.02664\ttraining's CRPS: : 0.0119227\tvalid_1's rmse: 0.885352\tvalid_1's CRPS: : 0.0119361\n[40]\ttraining's rmse: 1.02663\ttraining's CRPS: : 0.0119227\tvalid_1's rmse: 0.885352\tvalid_1's CRPS: : 0.0119361\n[50]\ttraining's rmse: 1.02662\ttraining's CRPS: : 0.0119227\tvalid_1's rmse: 0.885359\tvalid_1's CRPS: : 0.0119361\n[60]\ttraining's rmse: 1.02662\ttraining's CRPS: : 0.0119227\tvalid_1's rmse: 0.885359\tvalid_1's CRPS: : 0.0119361\n[70]\ttraining's rmse: 1.02661\ttraining's CRPS: : 0.0119227\tvalid_1's rmse: 0.88536\tvalid_1's CRPS: : 0.0119361\n[80]\ttraining's rmse: 1.0266\ttraining's CRPS: : 0.0119227\tvalid_1's rmse: 0.885357\tvalid_1's CRPS: : 0.0119361\n[90]\ttraining's rmse: 1.0266\ttraining's CRPS: : 0.0119227\tvalid_1's rmse: 0.885353\tvalid_1's CRPS: : 0.0119361\n[100]\ttraining's rmse: 1.02659\ttraining's CRPS: : 0.0119227\tvalid_1's rmse: 0.885357\tvalid_1's CRPS: : 0.0119361\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's rmse: 1.02659\ttraining's CRPS: : 0.0119227\tvalid_1's rmse: 0.885357\tvalid_1's CRPS: : 0.0119361\nfold 3\nTraining until validation scores don't improve for 99 rounds.\n[10]\ttraining's rmse: 0.989749\ttraining's CRPS: : 0.0119406\tvalid_1's rmse: 1.03996\tvalid_1's CRPS: : 0.0118646\n[20]\ttraining's rmse: 0.989742\ttraining's CRPS: : 0.0119406\tvalid_1's rmse: 1.03996\tvalid_1's CRPS: : 0.0118646\n[30]\ttraining's rmse: 0.989731\ttraining's CRPS: : 0.0119406\tvalid_1's rmse: 1.03997\tvalid_1's CRPS: : 0.0118646\n[40]\ttraining's rmse: 0.989718\ttraining's CRPS: : 0.0119406\tvalid_1's rmse: 1.03997\tvalid_1's CRPS: : 0.0118646\n[50]\ttraining's rmse: 0.98971\ttraining's CRPS: : 0.0119406\tvalid_1's rmse: 1.03998\tvalid_1's CRPS: : 0.0118646\n[60]\ttraining's rmse: 0.989702\ttraining's CRPS: : 0.0119406\tvalid_1's rmse: 1.03998\tvalid_1's CRPS: : 0.0118646\n[70]\ttraining's rmse: 0.989696\ttraining's CRPS: : 0.0119406\tvalid_1's rmse: 1.03999\tvalid_1's CRPS: : 0.0118646\n[80]\ttraining's rmse: 0.989689\ttraining's CRPS: : 0.0119406\tvalid_1's rmse: 1.03999\tvalid_1's CRPS: : 0.0118646\n[90]\ttraining's rmse: 0.989678\ttraining's CRPS: : 0.0119406\tvalid_1's rmse: 1.04\tvalid_1's CRPS: : 0.0118646\n[100]\ttraining's rmse: 0.989674\ttraining's CRPS: : 0.0119406\tvalid_1's rmse: 1.04\tvalid_1's CRPS: : 0.0118646\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's rmse: 0.989674\ttraining's CRPS: : 0.0119406\tvalid_1's rmse: 1.04\tvalid_1's CRPS: : 0.0118646\nfold 4\nTraining until validation scores don't improve for 99 rounds.\n[10]\ttraining's rmse: 0.981584\ttraining's CRPS: : 0.0119338\tvalid_1's rmse: 1.07045\tvalid_1's CRPS: : 0.0118919\n[20]\ttraining's rmse: 0.981577\ttraining's CRPS: : 0.0119338\tvalid_1's rmse: 1.07046\tvalid_1's CRPS: : 0.0118919\n[30]\ttraining's rmse: 0.981568\ttraining's CRPS: : 0.0119338\tvalid_1's rmse: 1.07047\tvalid_1's CRPS: : 0.0118919\n[40]\ttraining's rmse: 0.981561\ttraining's CRPS: : 0.0119338\tvalid_1's rmse: 1.07047\tvalid_1's CRPS: : 0.0118919\n[50]\ttraining's rmse: 0.981553\ttraining's CRPS: : 0.0119338\tvalid_1's rmse: 1.07047\tvalid_1's CRPS: : 0.0118919\n[60]\ttraining's rmse: 0.981542\ttraining's CRPS: : 0.0119338\tvalid_1's rmse: 1.07047\tvalid_1's CRPS: : 0.0118919\n[70]\ttraining's rmse: 0.981533\ttraining's CRPS: : 0.0119338\tvalid_1's rmse: 1.07046\tvalid_1's CRPS: : 0.0118919\n[80]\ttraining's rmse: 0.981527\ttraining's CRPS: : 0.0119338\tvalid_1's rmse: 1.07046\tvalid_1's CRPS: : 0.0118919\n[90]\ttraining's rmse: 0.981515\ttraining's CRPS: : 0.0119338\tvalid_1's rmse: 1.07048\tvalid_1's CRPS: : 0.0118919\n[100]\ttraining's rmse: 0.981503\ttraining's CRPS: : 0.0119338\tvalid_1's rmse: 1.07048\tvalid_1's CRPS: : 0.0118919\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's rmse: 0.981503\ttraining's CRPS: : 0.0119338\tvalid_1's rmse: 1.07048\tvalid_1's CRPS: : 0.0118919\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Validacao do modelo\n# Imprimir o score de treino e teste\n\nmean_rmse_tr = np.mean(tr_rmse)\nstd_rmse_tr =  np.std(tr_rmse)\n\nmean_rmse_val =  np.mean(val_rmse)\nstd_rmse_val =  np.std(val_rmse)\n\nall_rmse = mean_squared_error(oof,y_tr)\n\nprint(\"Score de Treino\")\nprint(\"Média RMSE: %.5f, std: %.5f.\" % (mean_rmse_tr, std_rmse_tr),'\\n')\n\nprint(\"Score de Validação\")\nprint(\"Média RMSE: %.5f, std: %.5f.\" % (mean_rmse_val, std_rmse_val),'\\n')\n\nprint(\"Geral: %.5f.\" % (all_rmse),'\\n')\n\nprint(\"CRPS: %.5f.\" % (funcao_crps(y_tr,oof)[1]))","execution_count":16,"outputs":[{"output_type":"stream","text":"Score de Treino\nMédia RMSE: 0.99983, std: 0.03182. \n\nScore de Validação\nMédia RMSE: 1.00006, std: 0.12725. \n\nGeral: 1.00006. \n\nCRPS: 0.01193.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Realizando a submissão"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Funcao para realizar feature engineering no dataset de teste\ndef feature_engineering_test(df): \n    \n    # Limpeza e conversao dos dados\n    fill_na(df)\n    convert_data(df)\n    \n    df_median = df.median()\n    \n    # Conversao de algumas features\n    df['PlayerHeight']  = df['PlayerHeight'].apply(convert_to_cm)\n    df['PlayerWeight']  = df['PlayerWeight'].apply(convert_to_kg)\n    df['Temperature']   = df['Temperature'].apply(convert_to_celsius)\n    df['StadiumType']   = df['StadiumType'].apply(agrupar_tipo_estadio)\n    df['Stadium']       = df['Stadium'].apply(agrupar_estadio)\n    df['Location']      = df['Location'].apply(agrupar_local)\n    df['Turf']          = df['Turf'].apply(agrupar_gramado)\n    df['WindDirection'] = df['WindDirection'].apply(agrupa_wind_direction)\n    df['WindSpeed']     = df['WindSpeed'].apply(convert_wind_speed)\n    df['GameWeather']   = df['GameWeather'].apply(agrupar_clima)\n\n\n    # Corrigindo a feature Stadium\n    df.loc[df['Stadium'] == 'MetLife Stadium', 'StadiumType'] = 'outdoor'\n    df.loc[df['Stadium'] == 'StubHub Center', 'StadiumType'] = 'outdoor'    \n    \n    # Nova feature com a diferença entre o tempo de lançamento da bola até quando o jogador captura\n    df['TimeDifer'] = df.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)            \n         \n    # Nova feature para indicar se é o jogador que esta realizando a jogada (corredor)\n    df['IsRusher'] = df['NflId'] == df['NflIdRusher']\n    \n    # Novas features com base no horario do jogo\n    df['Morning']   = df['GameClock'].apply(lambda x : 1 if (int(x[0:2]) >=0 and int(x[0:2]) <12) else 0)\n    df['Afternoon'] = df['GameClock'].apply(lambda x : 1 if (int(x[0:2]) <18 and int(x[0:2]) >=12) else 0)\n    df['Evening']   = df['GameClock'].apply(lambda x : 1 if (int(x[0:2]) >= 18 and int(x[0:2]) < 24) else 0)\n    df['GameClock'] = df['GameClock'].apply(str_to_seconds) \n    \n    # Criando novas features com dados de Distance, YardLine e DefendersInTheBox\n    df['seconds_need_to_first_down'] = (df['Distance']*0.9144)/df['Dis']\n    df['seconds_need_to_YardsLine'] = (df['YardLine']*0.9144)/df['Dis']    \n    df['DefendersInTheBox_vs_Distance'] = df['DefendersInTheBox'] / df['Distance']\n    \n    # Ordenacao do dataset e renovando o index\n    df = df.sort_values(by=['PlayId', 'Team', 'IsRusher']).reset_index()\n    \n    # Removendo colunas que não serão utilizadas\n    df = df.drop(['index', 'GameId','PlayId','NflId', 'DisplayName','NflIdRusher', 'TimeHandoff', 'TimeSnap', 'PlayerBirthDate'], axis=1)\n\n    # Atribuindo media para os demais dados missing\n    df.fillna(df_median, inplace=True)\n\n    # Executar somente para alguns modelos que nao tratam valores INF ou NAN\n    #train_df.replace(-np.inf,0,inplace=True)\n    #train_df.replace(np.inf,0,inplace=True)\n\n    # Removendo todas as variaveis categoricas\n    cat_features = []\n    for col in df.columns:\n        if df[col].dtype =='object':\n            cat_features.append(col)\n\n    df = df.drop(cat_features, axis=1)\n    \n    return df","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle.competitions import nflrush\n\npd.options.mode.chained_assignment = None\nindex = 0\n\nenv = nflrush.make_env()\n\nfor (test, sample_prediction_df) in tqdm.tqdm(env.iter_test()):\n    df_test = feature_engineering_test(test)\n    \n    count=0\n    test_data = np.zeros((1,len(features)))\n\n    for c in features:\n        if c in df_test:\n            try:\n                test_data[0][count] = df_test[c][index]\n            except:\n                test_data[0][count] = np.nan\n            count+=1\n    \n    y_pred = np.zeros(199)        \n    y_pred_p = np.sum(np.round(scaler.inverse_transform([model.predict(test_data)[0] for model in models])))/kf\n    y_pred_p += 99\n    \n    for j in range(199):\n        if j>=y_pred_p+10:\n            y_pred[j]=1.0\n        elif j>=y_pred_p-10:\n            y_pred[j]=(j+10-y_pred_p)*0.05\n    \n    env.predict(pd.DataFrame(data=[y_pred],columns=sample_prediction_df.columns))\n    \n    index += 22\n    \nenv.write_submission_file()\n\nprint([filename for filename in os.listdir('/kaggle/working') if '.csv' in filename])","execution_count":18,"outputs":[{"output_type":"stream","text":"3438it [06:52,  8.33it/s]\n","name":"stderr"},{"output_type":"stream","text":"Your submission file has been saved!  Once you `Commit` your Notebook and it finishes running, you can submit the file to the competition from the Notebook Viewer `Output` tab.\n['submission.csv']\n","name":"stdout"}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}