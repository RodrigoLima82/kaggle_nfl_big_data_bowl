{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import tqdm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import keras\n",
    "from tqdm import tqdm_notebook\n",
    "from string import punctuation\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Options\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_seq_items = 8000\n",
    "pd.options.display.max_rows = 8000\n",
    "pd.set_option('display.max_columns', None)\n",
    "import re\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "mpl.rcParams['figure.figsize'] = [15,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#train = pd.read_csv('../input/nfl-big-data-bowl-2020/train.csv', dtype={'WindSpeed': 'object'})\n",
    "train = pd.read_csv('../data/train.csv', dtype={'WindSpeed': 'object'}, low_memory=False)\n",
    "train = train[:2200]\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/rooshroosh/fork-of-neural-networks-different-architecture\n",
    "def strtoseconds(txt):\n",
    "    txt = txt.split(':')\n",
    "    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])/60\n",
    "    return ans\n",
    "\n",
    "def strtofloat(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def map_weather(txt):\n",
    "    ans = 1\n",
    "    if pd.isna(txt):\n",
    "        return 0\n",
    "    if 'partly' in txt:\n",
    "        ans*=0.5\n",
    "    if 'climate controlled' in txt or 'indoor' in txt:\n",
    "        return ans*3\n",
    "    if 'sunny' in txt or 'sun' in txt:\n",
    "        return ans*2\n",
    "    if 'clear' in txt:\n",
    "        return ans\n",
    "    if 'cloudy' in txt:\n",
    "        return -ans\n",
    "    if 'rain' in txt or 'rainy' in txt:\n",
    "        return -2*ans\n",
    "    if 'snow' in txt:\n",
    "        return -3*ans\n",
    "    return 0\n",
    "\n",
    "def OffensePersonnelSplit(x):\n",
    "    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0, 'QB' : 0, 'RB' : 0, 'TE' : 0, 'WR' : 0}\n",
    "    for xx in x.split(\",\"):\n",
    "        xxs = xx.split(\" \")\n",
    "        dic[xxs[-1]] = int(xxs[-2])\n",
    "    return dic\n",
    "\n",
    "def DefensePersonnelSplit(x):\n",
    "    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0}\n",
    "    for xx in x.split(\",\"):\n",
    "        xxs = xx.split(\" \")\n",
    "        dic[xxs[-1]] = int(xxs[-2])\n",
    "    return dic\n",
    "\n",
    "\n",
    "def orientation_to_cat(x):\n",
    "    x = np.clip(x, 0, 360 - 1)\n",
    "    try:\n",
    "        return str(int(x/15))\n",
    "    except:\n",
    "        return \"nan\"\n",
    "    \n",
    "# Funcao para agrupar as descricoes dos tipos de estadio\n",
    "def clean_StadiumType(txt):\n",
    "    if pd.isna(txt):\n",
    "        return np.nan\n",
    "    txt = txt.lower()\n",
    "    txt = ''.join([c for c in txt if c not in punctuation])\n",
    "    txt = re.sub(' +', ' ', txt)\n",
    "    txt = txt.strip()\n",
    "    txt = txt.replace('outside', 'outdoor')\n",
    "    txt = txt.replace('outdor', 'outdoor')\n",
    "    txt = txt.replace('outddors', 'outdoor')\n",
    "    txt = txt.replace('outdoors', 'outdoor')\n",
    "    txt = txt.replace('oudoor', 'outdoor')\n",
    "    txt = txt.replace('indoors', 'indoor')\n",
    "    txt = txt.replace('ourdoor', 'outdoor')\n",
    "    txt = txt.replace('retractable', 'rtr.')\n",
    "    return txt\n",
    "\n",
    "def transform_StadiumType(txt):\n",
    "    if pd.isna(txt):\n",
    "        return np.nan\n",
    "    if 'outdoor' in txt or 'open' in txt:\n",
    "        return 1\n",
    "    if 'indoor' in txt or 'closed' in txt:\n",
    "        return 0\n",
    "    return np.nan\n",
    "\n",
    "# Funcao para agrupar as descricoes dos estadios\n",
    "def agrupar_estadio(txt):\n",
    "    if pd.isna(txt):\n",
    "        return np.nan\n",
    "    txt = txt.lower()\n",
    "    txt = ''.join([c for c in txt if c not in punctuation])\n",
    "    txt = re.sub(' +', ' ', txt)\n",
    "    txt = txt.strip()\n",
    "    txt = txt.replace('outside', 'outdoor')\n",
    "    txt = txt.replace('outdor', 'outdoor')\n",
    "    txt = txt.replace('outddors', 'outdoor')\n",
    "    txt = txt.replace('outdoors', 'outdoor')\n",
    "    txt = txt.replace('oudoor', 'outdoor')\n",
    "    txt = txt.replace('indoors', 'indoor')\n",
    "    txt = txt.replace('ourdoor', 'outdoor')\n",
    "    txt = txt.replace('retractable', 'rtr.')\n",
    "    return txt\n",
    "\n",
    "    \n",
    "# Funcao para agrupar a localizacao do estadio e do jogo\n",
    "def clean_Location(Location):\n",
    "\n",
    "    if Location == \"Arlington, Texas\":\n",
    "        return \"Arlington, TX\"\n",
    "    elif Location in (\"Baltimore, Maryland\",\"Baltimore, Md.\"):\n",
    "        return \"Baltimore, MD\"\n",
    "    elif Location == \"Charlotte, North Carolina\":\n",
    "        return \"Charlotte, NC\"\n",
    "    elif Location == \"Chicago. IL\":\n",
    "        return \"Chicago, IL\"\n",
    "    elif Location == \"Cincinnati, Ohio\":\n",
    "        return \"Cincinnati, OH\"\n",
    "    elif Location in (\"Cleveland\",\"Cleveland Ohio\",\"Cleveland, Ohio\",\"Cleveland,Ohio\"):\n",
    "        return \"Cleveland, OH\"\n",
    "    elif Location == \"Detroit\":\n",
    "        return \"Detroit, MI\"\n",
    "    elif Location == \"E. Rutherford, NJ\" or Location == \"East Rutherford, N.J.\":\n",
    "        return \"East Rutherford, NJ\"\n",
    "    elif Location == \"Foxborough, Ma\":\n",
    "        return \"Foxborough, MA\"\n",
    "    elif Location == \"Houston, Texas\":\n",
    "        return \"Houston, TX\"\n",
    "    elif Location in (\"Jacksonville Florida\",\"Jacksonville, Fl\",\"Jacksonville, Florida\"):\n",
    "        return \"Jacksonville, FL\"\n",
    "    elif Location == \"London\":\n",
    "        return \"London, England\"\n",
    "    elif Location == \"Los Angeles, Calif.\":\n",
    "        return \"Los Angeles, CA\"\n",
    "    elif Location == \"Miami Gardens, Fla.\":\n",
    "        return \"Miami Gardens, FLA\"\n",
    "    elif Location in (\"New Orleans\",\"New Orleans, La.\"):\n",
    "        return \"New Orleans, LA\"\n",
    "    elif Location == \"Orchard Park NY\":\n",
    "        return \"Orchard Park, NY\"\n",
    "    elif Location == \"Philadelphia, Pa.\":\n",
    "        return \"Philadelphia, PA\"\n",
    "    elif Location == \"Pittsburgh\":\n",
    "        return \"Pittsburgh, PA\"\n",
    "    elif Location == \"Seattle\":\n",
    "        return \"Seattle, WA\"\n",
    "    else:\n",
    "        return Location\n",
    "    \n",
    "\n",
    "# Funcao para agrupar os dados de direcao do vento\n",
    "def clean_WindDirection(txt):\n",
    "    if pd.isna(txt):\n",
    "        return np.nan\n",
    "    txt = txt.lower()\n",
    "    txt = ''.join([c for c in txt if c not in punctuation])\n",
    "    txt = txt.replace('from', '')\n",
    "    txt = txt.replace(' ', '')\n",
    "    txt = txt.replace('north', 'n')\n",
    "    txt = txt.replace('south', 's')\n",
    "    txt = txt.replace('west', 'w')\n",
    "    txt = txt.replace('east', 'e')\n",
    "    return txt\n",
    "\n",
    "def transform_WindDirection(txt):\n",
    "    if pd.isna(txt):\n",
    "        return np.nan\n",
    "    \n",
    "    if txt=='n':\n",
    "        return 0\n",
    "    if txt=='nne' or txt=='nen':\n",
    "        return 1/8\n",
    "    if txt=='ne':\n",
    "        return 2/8\n",
    "    if txt=='ene' or txt=='nee':\n",
    "        return 3/8\n",
    "    if txt=='e':\n",
    "        return 4/8\n",
    "    if txt=='ese' or txt=='see':\n",
    "        return 5/8\n",
    "    if txt=='se':\n",
    "        return 6/8\n",
    "    if txt=='ses' or txt=='sse':\n",
    "        return 7/8\n",
    "    if txt=='s':\n",
    "        return 8/8\n",
    "    if txt=='ssw' or txt=='sws':\n",
    "        return 9/8\n",
    "    if txt=='sw':\n",
    "        return 10/8\n",
    "    if txt=='sww' or txt=='wsw':\n",
    "        return 11/8\n",
    "    if txt=='w':\n",
    "        return 12/8\n",
    "    if txt=='wnw' or txt=='nww':\n",
    "        return 13/8\n",
    "    if txt=='nw':\n",
    "        return 14/8\n",
    "    if txt=='nwn' or txt=='nnw':\n",
    "        return 15/8\n",
    "    return np.nan\n",
    "\n",
    "    \n",
    "# Funcao para converter a velocidade do vento\n",
    "def convert_wind_speed(WindSpeed):\n",
    "    ws = str(WindSpeed)\n",
    "\n",
    "    if ws.isdigit():\n",
    "        return int(ws)\n",
    "\n",
    "    if '-' in ws:\n",
    "        return int(ws.split('-')[0])\n",
    "\n",
    "    if ws.split(' ')[0].isdigit():\n",
    "        return int(ws.split(' ')[0])\n",
    "\n",
    "    if 'mph' in ws.lower():\n",
    "        return int(ws.lower().split('mph')[0])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def transform_time_quarter(str1):\n",
    "    return int(str1[:2])*60 + int(str1[3:5])\n",
    "\n",
    "def transform_time_all(str1,quarter):\n",
    "    if quarter<=4:\n",
    "        return 15*60 - (int(str1[:2])*60 + int(str1[3:5])) + (quarter-1)*15*60\n",
    "    if quarter ==5:\n",
    "        return 10*60 - (int(str1[:2])*60 + int(str1[3:5])) + (quarter-1)*15*60\n",
    "    \n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "\n",
    "def _kurtosis(x):\n",
    "    return kurtosis(x)\n",
    "\n",
    "def CPT5(x):\n",
    "    den = len(x)*np.exp(np.std(x))\n",
    "    return sum(np.exp(x))/den\n",
    "\n",
    "def skewness(x):\n",
    "    return skew(x)\n",
    "\n",
    "def SSC(x):\n",
    "    x = np.array(x)\n",
    "    x = np.append(x[-1], x)\n",
    "    x = np.append(x,x[1])\n",
    "    xn = x[1:len(x)-1]\n",
    "    xn_i2 = x[2:len(x)]    # xn+1 \n",
    "    xn_i1 = x[0:len(x)-2]  # xn-1\n",
    "    ans = np.heaviside((xn-xn_i1)*(xn-xn_i2),0)\n",
    "    return sum(ans[1:]) \n",
    "\n",
    "def wave_length(x):\n",
    "    x = np.array(x)\n",
    "    x = np.append(x[-1], x)\n",
    "    x = np.append(x,x[1])\n",
    "    xn = x[1:len(x)-1]\n",
    "    xn_i2 = x[2:len(x)]    # xn+1 \n",
    "    return sum(abs(xn_i2-xn))\n",
    "    \n",
    "def norm_entropy(x):\n",
    "    tresh = 3\n",
    "    return sum(np.power(abs(x),tresh))\n",
    "\n",
    "def SRAV(x):    \n",
    "    SRA = sum(np.sqrt(abs(x)))\n",
    "    return np.power(SRA/len(x),2)\n",
    "\n",
    "def mean_abs(x):\n",
    "    return sum(abs(x))/len(x)\n",
    "\n",
    "def zero_crossing(x):\n",
    "    x = np.array(x)\n",
    "    x = np.append(x[-1], x)\n",
    "    x = np.append(x,x[1])\n",
    "    xn = x[1:len(x)-1]\n",
    "    xn_i2 = x[2:len(x)]    # xn+1\n",
    "    return sum(np.heaviside(-xn*xn_i2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao para realizar feature engineering no dataset treino\n",
    "def features_estatisticas(data):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for col in data.columns:\n",
    "        if col in []:\n",
    "            continue\n",
    "        \n",
    "        #print(col)  \n",
    "        #df[col + '_mean'] = data.groupby(['PlayId','IsRusherTeam','IsRusher'])[col].mean()\n",
    "        #df[col + '_median'] = data.groupby(['PlayId','IsRusherTeam','IsRusher'])[col].median()\n",
    "        #df[col + '_max'] = data.groupby(['PlayId'])[col].max()\n",
    "        #df[col + '_min'] = data.groupby(['PlayId'])[col].min()\n",
    "        df[col + '_std'] = data.groupby(['PlayId'])[col].std()\n",
    "        #df[col + '_range'] = df[col + '_max'] - df[col + '_min']\n",
    "        #df[col + '_maxtoMin'] = df[col + '_max'] / df[col + '_min']\n",
    "        #df[col + '_mean_abs_chg'] = data.groupby(['PlayId'])[col].apply(lambda x: np.mean(np.abs(np.diff(x))))\n",
    "        #df[col + '_mean_change_of_abs_change'] = data.groupby(['PlayId'])[col].apply(mean_change_of_abs_change)\n",
    "        #df[col + '_abs_max'] = data.groupby(['PlayId'])[col].apply(lambda x: np.max(np.abs(x)))\n",
    "        #df[col + '_abs_min'] = data.groupby(['PlayId'])[col].apply(lambda x: np.min(np.abs(x)))\n",
    "        #df[col + '_abs_avg'] = (df[col + '_abs_min'] + df[col + '_abs_max'])/2\n",
    "\n",
    "        # Advanced Features\n",
    "        #df[col + '_skew'] = data.groupby(['PlayId'])[col].skew()\n",
    "        #df[col + '_mad'] = data.groupby(['PlayId'])[col].mad()\n",
    "        #df[col + '_q25'] = data.groupby(['PlayId'])[col].quantile(0.25)\n",
    "        #df[col + '_q75'] = data.groupby(['PlayId'])[col].quantile(0.75)\n",
    "        #df[col + '_q95'] = data.groupby(['PlayId'])[col].quantile(0.95)\n",
    "        #df[col + '_iqr'] = df[col + '_q75'] - df[col + '_q25']\n",
    "        #df[col + '_SSC'] = data.groupby(['PlayId'])[col].apply(SSC) \n",
    "        #df[col + '_skewness'] = data.groupby(['PlayId'])[col].apply(skewness)\n",
    "        #df[col + '_wave_lenght'] = data.groupby(['PlayId'])[col].apply(wave_length)\n",
    "        #df[col + '_norm_entropy'] = data.groupby(['PlayId','IsRusherTeam','IsRusher'])[col].apply(norm_entropy)\n",
    "        #df[col + '_SRAV'] = data.groupby(['PlayId','IsRusherTeam','IsRusher'])[col].apply(SRAV)\n",
    "        #df[col + '_kurtosis'] = data.groupby(['PlayId'])[col].apply(_kurtosis) \n",
    "        #df[col + '_zero_crossing'] = data.groupby(['PlayId'])[col].apply(zero_crossing) \n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train):\n",
    "\n",
    "    # Features Rodrigo\n",
    "    #INICIO ======================================================================\n",
    "    \n",
    "    train['StadiumType'] = train['StadiumType'].apply(clean_StadiumType)\n",
    "    train['StadiumType'] = train['StadiumType'].apply(transform_StadiumType)\n",
    "\n",
    "    train['Location'] = train['Location'].apply(clean_Location)\n",
    "    \n",
    "    Turf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', \n",
    "            'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', \n",
    "            'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', \n",
    "            'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', \n",
    "            'SISGrass':'Artificial', 'Twenty-Four/Seven Turf':'Artificial', 'natural grass':'Natural'} \n",
    "\n",
    "    train['Turf'] = train['Turf'].map(Turf)\n",
    "    train['Turf'] = train['Turf'] == 'Natural'    \n",
    "\n",
    "    train[(train['PossessionTeam']!=train['HomeTeamAbbr']) & (train['PossessionTeam']!=train['VisitorTeamAbbr'])][['PossessionTeam', 'HomeTeamAbbr', 'VisitorTeamAbbr']]\n",
    "    train['DefendersInTheBox_vs_Distance'] = train['DefendersInTheBox'] / train['Distance']\n",
    "\n",
    "    map_abbr = {'ARI': 'ARZ', 'BAL': 'BLT', 'CLE': 'CLV', 'HOU': 'HST'}\n",
    "    for abb in train['PossessionTeam'].unique():\n",
    "        map_abbr[abb] = abb\n",
    "\n",
    "    train['PossessionTeam'] = train['PossessionTeam'].map(map_abbr)\n",
    "    train['HomeTeamAbbr'] = train['HomeTeamAbbr'].map(map_abbr)\n",
    "    train['VisitorTeamAbbr'] = train['VisitorTeamAbbr'].map(map_abbr)\n",
    "    train['HomePossesion'] = train['PossessionTeam'] == train['HomeTeamAbbr']    \n",
    "    train['Field_eq_Possession'] = train['FieldPosition'] == train['PossessionTeam']\n",
    "    train['HomeField'] = train['FieldPosition'] == train['HomeTeamAbbr']\n",
    "    train['time_quarter'] = train.GameClock.map(lambda x:transform_time_quarter(x))\n",
    "    train['time_end'] = train.apply(lambda x:transform_time_all(x.loc['GameClock'],x.loc['Quarter']),axis=1)\n",
    "    train['WindDirection'] = train['WindDirection'].apply(clean_WindDirection)\n",
    "    train['WindDirection'] = train['WindDirection'].apply(transform_WindDirection)\n",
    "    train['PlayDirection'] = train['PlayDirection'].apply(lambda x: x.strip() == 'right')   \n",
    "    #train['Team'] = train['Team'].apply(lambda x: x.strip()=='home')\n",
    "    train['YardsLeft'] = train.apply(lambda row: 100-row['YardLine'] if row['HomeField'] else row['YardLine'], axis=1)\n",
    "    train['YardsLeft'] = train.apply(lambda row: row['YardsLeft'] if row['PlayDirection'] else 100-row['YardsLeft'], axis=1)\n",
    "\n",
    "    #FIM ======================================================================\n",
    "\n",
    "    ## GameClock\n",
    "    train['GameClock_sec'] = train['GameClock'].apply(strtoseconds)\n",
    "    train[\"GameClock_minute\"] = train[\"GameClock\"].apply(lambda x : x.split(\":\")[0]).astype(\"object\")\n",
    "\n",
    "    ## Height\n",
    "    train['PlayerHeight'] = train['PlayerHeight'].apply(lambda x: (12*int(x.split('-')[0])+int(x.split('-')[1]) * 2.54/100))\n",
    "\n",
    "    train['PlayerBMI'] = 703*(train['PlayerWeight']/(train['PlayerHeight'])**2)\n",
    "\n",
    "    ## Time\n",
    "    train['TimeHandoff'] = train['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    train['TimeSnap'] = train['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "\n",
    "    train['TimeDelta'] = train.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n",
    "    train['PlayerBirthDate'] = train['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n",
    "\n",
    "    ## Age\n",
    "    seconds_in_year = 60*60*24*365.25\n",
    "    train['PlayerAge'] = train.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n",
    "    train[\"PlayerAge_ob\"] = train['PlayerAge'].astype(np.int).astype(\"object\")\n",
    "\n",
    "    ## WindSpeed\n",
    "    train['WindSpeed_ob'] = train['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n",
    "    train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n",
    "    train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n",
    "    train['WindSpeed_dense'] = train['WindSpeed_ob'].apply(strtofloat)\n",
    "\n",
    "    ## Weather\n",
    "    train['GameWeather_process'] = train['GameWeather'].str.lower()\n",
    "    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: \"indoor\" if not pd.isna(x) and \"indoor\" in x else x)\n",
    "    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n",
    "    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n",
    "    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n",
    "    train['GameWeather_dense'] = train['GameWeather_process'].apply(map_weather)\n",
    "\n",
    "    ## Rusher\n",
    "    train['IsRusher'] = (train['NflId'] == train['NflIdRusher'])\n",
    "    train['IsRusher_ob'] = (train['NflId'] == train['NflIdRusher']).astype(\"object\")\n",
    "    temp = train[train[\"IsRusher\"]][[\"Team\", \"PlayId\"]].rename(columns={\"Team\":\"RusherTeam\"})\n",
    "    train = train.merge(temp, on = \"PlayId\")\n",
    "    train[\"IsRusherTeam\"] = train[\"Team\"] == train[\"RusherTeam\"]\n",
    "\n",
    "    ## dense -> categorical\n",
    "    train[\"Quarter_ob\"] = train[\"Quarter\"].astype(\"object\")\n",
    "    train[\"Down_ob\"] = train[\"Down\"].astype(\"object\")\n",
    "    train[\"JerseyNumber_ob\"] = train[\"JerseyNumber\"].astype(\"object\")\n",
    "    train[\"YardLine_ob\"] = train[\"YardLine\"].astype(\"object\")\n",
    "    train[\"DefendersInTheBox_ob\"] = train[\"DefendersInTheBox\"].astype(\"object\")\n",
    "    train[\"Week_ob\"] = train[\"Week\"].astype(\"object\")\n",
    "    train[\"TimeDelta_ob\"] = train[\"TimeDelta\"].astype(\"object\")\n",
    "\n",
    "\n",
    "    ## Orientation and Dir\n",
    "    train[\"Orientation_ob\"] = train[\"Orientation\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n",
    "    train[\"Dir_ob\"] = train[\"Dir\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n",
    "\n",
    "    train[\"Orientation_sin\"] = train[\"Orientation\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n",
    "    train[\"Orientation_cos\"] = train[\"Orientation\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n",
    "    train[\"Dir_sin\"] = train[\"Dir\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n",
    "    train[\"Dir_cos\"] = train[\"Dir\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n",
    "\n",
    "    \n",
    "    # Runner horizontal speed\n",
    "    radian_angle = (90 - train['Dir']) * np.pi / 180.0\n",
    "    train['v_horizontal'] = np.abs(train['S'] * np.cos(radian_angle))\n",
    "    train['v_vertical'] = np.abs(train['S'] * np.sin(radian_angle))\n",
    "\n",
    "\n",
    "    ## diff Score\n",
    "    train[\"diffScoreBeforePlay\"] = train[\"HomeScoreBeforePlay\"] - train[\"VisitorScoreBeforePlay\"]\n",
    "    train[\"diffScoreBeforePlay_binary_ob\"] = (train[\"HomeScoreBeforePlay\"] > train[\"VisitorScoreBeforePlay\"]).astype(\"object\")\n",
    "\n",
    "    ## Turf\n",
    "    #Turf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', 'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', 'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', 'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', 'SISGrass':'Artificial', 'Twenty-Four/Seven Turf':'Artificial', 'natural grass':'Natural'} \n",
    "    #train['Turf'] = train['Turf'].map(Turf)\n",
    "\n",
    "    ## OffensePersonnel\n",
    "    temp = train[\"OffensePersonnel\"].iloc[np.arange(0, len(train), 22)].apply(lambda x : pd.Series(OffensePersonnelSplit(x)))\n",
    "    temp.columns = [\"Offense\" + c for c in temp.columns]\n",
    "    temp[\"PlayId\"] = train[\"PlayId\"].iloc[np.arange(0, len(train), 22)]\n",
    "    train = train.merge(temp, on = \"PlayId\")\n",
    "\n",
    "    ## DefensePersonnel\n",
    "    temp = train[\"DefensePersonnel\"].iloc[np.arange(0, len(train), 22)].apply(lambda x : pd.Series(DefensePersonnelSplit(x)))\n",
    "    temp.columns = [\"Defense\" + c for c in temp.columns]\n",
    "    temp[\"PlayId\"] = train[\"PlayId\"].iloc[np.arange(0, len(train), 22)]\n",
    "    train = train.merge(temp, on = \"PlayId\")\n",
    " \n",
    "    # Feature estatistica\n",
    "    #temp = features_estatisticas(train)\n",
    "    #train = train.merge(temp, on = 'PlayId')\n",
    "    \n",
    "    ## sort\n",
    "    #train = train.sort_values(by = ['X']).sort_values(by = ['Dis']).sort_values(by=['PlayId', 'Team', 'IsRusher']).reset_index(drop = True)\n",
    "    train = train.sort_values(by = ['X']).sort_values(by = ['Dis']).sort_values(by=['PlayId', 'IsRusherTeam', 'IsRusher']).reset_index(drop = True)\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train = preprocess(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DisplayName remove Outlier\n",
    "v = train[\"DisplayName\"].value_counts()\n",
    "missing_values = list(v[v < 5].index)\n",
    "train[\"DisplayName\"] = train[\"DisplayName\"].where(~train[\"DisplayName\"].isin(missing_values), \"nan\")\n",
    "\n",
    "## PlayerCollegeName remove Outlier\n",
    "v = train[\"PlayerCollegeName\"].value_counts()\n",
    "missing_values = list(v[v < 10].index)\n",
    "train[\"PlayerCollegeName\"] = train[\"PlayerCollegeName\"].where(~train[\"PlayerCollegeName\"].isin(missing_values), \"nan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop(train):\n",
    "    drop_cols = ['GameId', 'GameWeather', 'NflId', 'Season', 'NflIdRusher'] \n",
    "    drop_cols += ['TimeHandoff', 'TimeSnap', 'PlayerBirthDate']\n",
    "    drop_cols += ['Orientation', \"Dir\", 'WindSpeed', 'GameClock']\n",
    "    #drop_cols += [\"DefensePersonnel\",\"OffensePersonnel\"]\n",
    "    train = train.drop(drop_cols, axis = 1)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = drop(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_features = []\n",
    "dense_features = []\n",
    "for col in train.columns:\n",
    "    if train[col].dtype =='object':\n",
    "        cat_features.append(col)\n",
    "        #print(\"*cat*\", col, len(train[col].unique()))\n",
    "    else:\n",
    "        dense_features.append(col)\n",
    "        #print(\"!dense!\", col, len(train[col].unique()))\n",
    "dense_features.remove(\"PlayId\")\n",
    "dense_features.remove(\"Yards\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat = train[cat_features]\n",
    "categories = []\n",
    "most_appear_each_categories = {}\n",
    "for col in tqdm_notebook(train_cat.columns):\n",
    "    train_cat.loc[:,col] = train_cat[col].fillna(\"nan\")\n",
    "    train_cat.loc[:,col] = col + \"__\" + train_cat[col].astype(str)\n",
    "    most_appear_each_categories[col] = list(train_cat[col].value_counts().index)[0]\n",
    "    categories.append(train_cat[col].unique())\n",
    "categories = np.hstack(categories)\n",
    "print(len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(categories)\n",
    "for col in tqdm_notebook(train_cat.columns):\n",
    "    train_cat.loc[:, col] = le.transform(train_cat[col])\n",
    "num_classes = len(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dense = train[dense_features]\n",
    "sss = {}\n",
    "medians = {}\n",
    "for col in tqdm_notebook(train_dense.columns):\n",
    "    #print(col)\n",
    "    medians[col] = np.nanmedian(train_dense[col])\n",
    "    train_dense.loc[:, col] = train_dense[col].fillna(medians[col])\n",
    "    ss = StandardScaler()\n",
    "    train_dense.loc[:, col] = ss.fit_transform(train_dense[col].values[:,None])\n",
    "    sss[col] = ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dense.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide features into groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dense features for play\n",
    "dense_game_features = train_dense.columns[train_dense[:22].std() == 0]\n",
    "## dense features for each player\n",
    "dense_player_features = train_dense.columns[train_dense[:22].std() != 0]\n",
    "## categorical features for play\n",
    "cat_game_features = train_cat.columns[train_cat[:22].std() == 0]\n",
    "## categorical features for each player\n",
    "cat_player_features = train_cat.columns[train_cat[:22].std() != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dense_game = train_dense[dense_game_features].iloc[np.arange(0, len(train), 22)].reset_index(drop = True).values\n",
    "train_dense_game = np.hstack([train_dense_game, train_dense[dense_player_features][train_dense[\"IsRusher\"] > 0]]) ## with rusher player feature\n",
    "\n",
    "train_dense_players = [train_dense[dense_player_features].iloc[np.arange(k, len(train), 22)].reset_index(drop = True) for k in range(22)]\n",
    "train_dense_players = np.stack([t.values for t in train_dense_players]).transpose(1, 0, 2)\n",
    "\n",
    "train_cat_game = train_cat[cat_game_features].iloc[np.arange(0, len(train), 22)].reset_index(drop = True).values\n",
    "train_cat_game = np.hstack([train_cat_game, train_cat[cat_player_features][train_dense[\"IsRusher\"] > 0]]) ## with rusher player feature\n",
    "\n",
    "train_cat_players = [train_cat[cat_player_features].iloc[np.arange(k, len(train), 22)].reset_index(drop = True) for k in range(22)]\n",
    "train_cat_players = np.stack([t.values for t in train_cat_players]).transpose(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_step(x):\n",
    "    temp = np.zeros(199)\n",
    "    temp[x + 99:] = 1\n",
    "    return temp\n",
    "\n",
    "train_y_raw = train[\"Yards\"].iloc[np.arange(0, len(train), 22)].reset_index(drop = True)\n",
    "train_y = np.vstack(train_y_raw.apply(return_step).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dense_game.shape, train_dense_players.shape, train_cat_game.shape, train_cat_players.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "def crps(y_true, y_pred):\n",
    "    loss = K.mean((K.cumsum(y_pred, axis = 1) - y_true)**2)\n",
    "    return loss\n",
    "\n",
    "def get_model(batch_size, epochs):\n",
    "    ## model dense\n",
    "    input_dense_game = keras.layers.Input(shape=(train_dense_game.shape[1],))\n",
    "    x1 = keras.layers.Dense(32, activation=\"relu\")(input_dense_game)\n",
    "    x1 = keras.layers.Dropout(0.5)(x1)\n",
    "    # x1 = keras.layers.Dropout(0.1)(x1)\n",
    "\n",
    "    input_dense_players = keras.layers.Input(shape=(train_dense_players.shape[1],train_dense_players.shape[2]))\n",
    "    x2 = keras.layers.Dense(32, activation=\"relu\")(input_dense_players)\n",
    "    x2 = keras.layers.Dropout(0.5)(x2)\n",
    "    # x2 = keras.layers.Flatten()(x2)\n",
    "    # x2 = keras.layers.Dropout(0.1)(x2)\n",
    "\n",
    "    ## model categorical\n",
    "    input_cat_game = keras.layers.Input(shape=(train_cat_game.shape[1], ))\n",
    "    embedding = keras.layers.Embedding(num_classes, 8, embeddings_regularizer=regularizers.l2(1))\n",
    "\n",
    "    x3 = embedding(input_cat_game)\n",
    "    x3 = keras.layers.Flatten()(x3)\n",
    "    x3 = keras.layers.Dense(8, activation=\"relu\")(x3)\n",
    "    x3 = keras.layers.Dropout(0.6)(x3)\n",
    "\n",
    "    input_cat_players = keras.layers.Input(shape=(train_cat_players.shape[1], train_cat_players.shape[2]))\n",
    "    x4 = embedding(input_cat_players)\n",
    "\n",
    "    x4 = keras.layers.Reshape((int(x4.shape[1]), int(x4.shape[2]) * int(x4.shape[3])))(x4)\n",
    "    x4 = keras.layers.Dense(16, activation=\"relu\")(x4)\n",
    "    x4 = keras.layers.Dropout(0.6)(x4)\n",
    "\n",
    "    ### concat players\n",
    "    x_concat_players = keras.layers.Concatenate()([x2,x4])\n",
    "    x_concat_players = keras.layers.Dense(16, activation=\"relu\")(x_concat_players)\n",
    "    # x_concat_players = keras.layers.GlobalAveragePooling1D()(x_concat_players)\n",
    "\n",
    "    ## flatten\n",
    "    x2 = keras.layers.Flatten()(x2)\n",
    "    x4 = keras.layers.Flatten()(x4)\n",
    "    x_concat_players = keras.layers.Flatten()(x_concat_players)\n",
    "\n",
    "    ### concat all\n",
    "    x_concat = keras.layers.Concatenate()([x1,x3,x_concat_players] + [x2, x4])\n",
    "    x_concats = []\n",
    "    n_unit = 128\n",
    "    decay_rate = 0.5\n",
    "    for k in range(5):\n",
    "        x_concat = keras.layers.Dense(n_unit, activation=\"relu\")(x_concat)\n",
    "        x_concats.append(x_concat)\n",
    "        n_unit = int(n_unit * decay_rate)\n",
    "    x_concat = keras.layers.Concatenate()(x_concats)\n",
    "    x_concat = keras.layers.Dropout(0.5)(x_concat)\n",
    "\n",
    "    ## concat\n",
    "    x_concat = keras.layers.Concatenate()([x1,x3,x_concat_players,x_concat] + [x2, x4])\n",
    "    out_soft = keras.layers.Dense(199, activation=\"softmax\", name = \"out_soft\")(x_concat)\n",
    "    out_reg = keras.layers.Dense(1, activation=None, name = \"out_reg\")(x_concat)\n",
    "    model = keras.models.Model(inputs = [input_dense_game, input_dense_players, input_cat_game, input_cat_players],\n",
    "                               outputs = [out_soft, out_reg])\n",
    "\n",
    "    ## compile\n",
    "    #er = EarlyStopping(patience=10, min_delta=1e-4, restore_best_weights=True, monitor='val_out_soft_loss')\n",
    "    model.compile(loss=[crps, keras.losses.mae],\n",
    "                  loss_weights=[1.0, 0.01],\n",
    "                  #optimizer=RAdam(warmup_proportion=0.1, min_lr=1e-7, learning_rate=0.0009, decay = 1e-5))\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate=0.006, decay = 1e-5))\n",
    "\n",
    "    ## train\n",
    "    tr_x = [train_dense_game[tr_inds], train_dense_players[tr_inds], train_cat_game[tr_inds], train_cat_players[tr_inds]]\n",
    "    tr_y = [train_y[tr_inds], train_y_raw[tr_inds]/100]\n",
    "    val_x = [train_dense_game[val_inds], train_dense_players[val_inds], train_cat_game[val_inds], train_cat_players[val_inds]]\n",
    "    val_y = [train_y[val_inds], train_y_raw[val_inds]/100]\n",
    "    model.fit(tr_x,\n",
    "              tr_y,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(val_x, val_y)\n",
    "              #callbacks=[er]\n",
    "             )\n",
    "    loss = model.history.history[\"val_out_soft_loss\"][-1]\n",
    "    return model, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "losses = []\n",
    "models = []\n",
    "#for k in range(2):\n",
    "kfold = KFold(10, shuffle = True)\n",
    "for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(train_y)):\n",
    "    print(\"-----------\")\n",
    "    model, loss = get_model(32, 100)    \n",
    "    if (loss < 0.012):\n",
    "        print('Append KFold:',k_fold,'| Loss:', loss)\n",
    "        models.append(model)\n",
    "        losses.append(loss)\n",
    "        if (len(losses) > 10):\n",
    "            break\n",
    "    else:\n",
    "        print('Ignore KFold:',k_fold, '| Loss:', loss)        \n",
    "print(\"-------\")\n",
    "print('Loss Mean:', np.mean(losses), ' | List:', losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(losses)\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# com nova estrutura de NN 16/100 e (2 * 10) e 100 registros : 0.01402696009193148\n",
    "# com nova estrutura de NN 32/100 e (2 * 10) e 100 registros : 0.012427266997595629\n",
    "# com nova estrutura de NN 64/100 e (2 * 10) e 100 registros : 0.013305273631380664\n",
    "# com nova estrutura de NN 128/100 e (2 * 10) e 100 registros: 0.013863528993996706\n",
    "#======================\n",
    "# com old estrutura de NN 16/100 e (2 * 10) e 100 registros : 0.011385330930352211\n",
    "# com old estrutura de NN 32/100 e (2 * 10) e 100 registros : 0.0132803592661565\n",
    "#======================\n",
    "# Com feature Location\n",
    "# com old estrutura de NN 32/100 e (2 * 10) e 100 registros : 0.009102115221321583\n",
    "# com old estrutura de NN 32/100 e (2 * 10) e todos registros : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred(test, sample, env, model):\n",
    "    test = preprocess(test)\n",
    "    test = drop(test)\n",
    "\n",
    "    ### categorical\n",
    "    test_cat = test[cat_features]\n",
    "    for col in (test_cat.columns):\n",
    "        test_cat.loc[:,col] = test_cat[col].fillna(\"nan\")\n",
    "        test_cat.loc[:,col] = col + \"__\" + test_cat[col].astype(str)\n",
    "        isnan = ~test_cat.loc[:,col].isin(categories)\n",
    "        if np.sum(isnan) > 0:\n",
    "            if not ((col + \"__nan\") in categories):\n",
    "                test_cat.loc[isnan,col] = most_appear_each_categories[col]\n",
    "            else:\n",
    "                test_cat.loc[isnan,col] = col + \"__nan\"\n",
    "    for col in (test_cat.columns):\n",
    "        test_cat.loc[:, col] = le.transform(test_cat[col])\n",
    "\n",
    "    ### dense\n",
    "    test_dense = test[dense_features]\n",
    "    for col in (test_dense.columns):\n",
    "        test_dense.loc[:, col] = test_dense[col].fillna(medians[col])\n",
    "        test_dense.loc[:, col] = sss[col].transform(test_dense[col].values[:,None])\n",
    "\n",
    "    ### divide\n",
    "    test_dense_players = [test_dense[dense_player_features].iloc[np.arange(k, len(test), 22)].reset_index(drop = True) for k in range(22)]\n",
    "    test_dense_players = np.stack([t.values for t in test_dense_players]).transpose(1,0, 2)\n",
    "\n",
    "    test_dense_game = test_dense[dense_game_features].iloc[np.arange(0, len(test), 22)].reset_index(drop = True).values\n",
    "    test_dense_game = np.hstack([test_dense_game, test_dense[dense_player_features][test_dense[\"IsRusher\"] > 0]])\n",
    "    \n",
    "    test_cat_players = [test_cat[cat_player_features].iloc[np.arange(k, len(test), 22)].reset_index(drop = True) for k in range(22)]\n",
    "    test_cat_players = np.stack([t.values for t in test_cat_players]).transpose(1,0, 2)\n",
    "\n",
    "    test_cat_game = test_cat[cat_game_features].iloc[np.arange(0, len(test), 22)].reset_index(drop = True).values\n",
    "    test_cat_game = np.hstack([test_cat_game, test_cat[cat_player_features][test_dense[\"IsRusher\"] > 0]])\n",
    "\n",
    "    test_inp = [test_dense_game, test_dense_players, test_cat_game, test_cat_players]\n",
    "    \n",
    "    ## pred\n",
    "    pred = 0\n",
    "    for model in models:\n",
    "        _pred = model.predict(test_inp)[0]\n",
    "        _pred = np.cumsum(_pred, axis = 1)\n",
    "        pred += _pred\n",
    "    pred /= len(models)\n",
    "    pred = np.clip(pred, 0, 1)\n",
    "    env.predict(pd.DataFrame(data=pred,columns=sample.columns))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.competitions import nflrush\n",
    "env = nflrush.make_env()\n",
    "preds = []\n",
    "for test, sample in tqdm_notebook(env.iter_test()):\n",
    "    pred = make_pred(test, sample, env, models)\n",
    "    preds.append(pred)\n",
    "env.write_submission_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.vstack(preds)\n",
    "## check whether prediction is submittable\n",
    "print(np.mean(np.diff(preds, axis = 1) >= 0) == 1.0)\n",
    "print(np.mean(preds > 1) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(losses)\n",
    "print(np.mean(losses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
