{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle\n",
    "## Competition NFL Big Data Bowl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Carregando os pacotes\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Statistic lib\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, norm\n",
    "\n",
    "# Sklearn lib\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Models\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost as XGB\n",
    "from sklearn.cluster import KMeans\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "# Misc lib\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from functools import partial\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from IPython.display import Image\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# Utils\n",
    "import pandasql as ps\n",
    "import re \n",
    "import math, string, os\n",
    "import datetime\n",
    "import tqdm\n",
    "\n",
    "# Options\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_seq_items = 8000\n",
    "pd.options.display.max_rows = 8000\n",
    "pd.set_option('display.max_columns', None)\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f5fdc987f79035336b408413b3b3111d1b48fd2a"
   },
   "outputs": [],
   "source": [
    "# Carregando os dados de treino\n",
    "train = pd.read_csv('../data/train.csv', low_memory=False)\n",
    "\n",
    "# Dataset criado gerando valores estatisticos\n",
    "estat = pd.read_csv('../data/data.csv', low_memory=False)\n",
    "\n",
    "# Merge com dataset estatistico (contem estatistica basica e avançada das features numericas)\n",
    "train = pd.merge(train, estat, on='PlayId', how='outer')\n",
    "\n",
    "#train = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', low_memory=False)\n",
    "print (\"Data is ready !!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando as funções auxiliares de limpeza e conversao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao para tratar os dados missing de cada variavel\n",
    "def fill_na(data):\n",
    "    data['WindDirection'].fillna('unknown',inplace=True)\n",
    "    data['OffenseFormation'].fillna('unknown',inplace=True)\n",
    "    data['StadiumType'].fillna('unknown',inplace=True)\n",
    "    data['GameWeather'].fillna('unknown',inplace=True)\n",
    "    data['FieldPosition'].fillna('NA',inplace=True)\n",
    "    \n",
    "    data['Temperature'].fillna(data['Temperature'].mean(), inplace=True)\n",
    "    data['Humidity'].fillna(data['Humidity'].mean(), inplace=True)\n",
    "    data['DefendersInTheBox'].fillna(math.ceil(data['DefendersInTheBox'].mean()),inplace=True)\n",
    "    \n",
    "# Funcao para agrupar as descricoes dos tipos de estadio\n",
    "def agrupar_tipo_estadio(StadiumType):\n",
    "    outdoor       = ['Outdoor', 'Outdoors', 'Cloudy', 'Heinz Field', 'Outdor', 'Ourdoor', 'Outside', 'Outddors', 'Outdoor Retr Roof-Open', 'Oudoor', 'Bowl']\n",
    "    indoor_closed = ['Indoors', 'Indoor', 'Indoor, Roof Closed', 'Indoor, Roof Closed', 'Retractable Roof', 'Retr. Roof-Closed', 'Retr. Roof - Closed', 'Retr. Roof Closed']\n",
    "    indoor_open   = ['Indoor, Open Roof', 'Open', 'Retr. Roof-Open', 'Retr. Roof - Open']\n",
    "    dome_closed   = ['Dome', 'Domed, closed', 'Closed Dome', 'Domed', 'Dome, closed']\n",
    "    dome_open     = ['Domed, Open', 'Domed, open']\n",
    "    \n",
    "    if StadiumType in outdoor:\n",
    "        return 'outdoor'\n",
    "    elif StadiumType in indoor_closed:\n",
    "        return 'indoor_closed'\n",
    "    elif StadiumType in indoor_open:\n",
    "        return 'indoor_open'\n",
    "    elif StadiumType in dome_closed:\n",
    "        return 'dome_closed'\n",
    "    elif StadiumType in dome_open:\n",
    "        return 'dome_open'\n",
    "    else:\n",
    "        return 'unknown' # se for n/a\n",
    "    \n",
    "# Funcao para agrupar as descricoes dos estadios\n",
    "def agrupar_estadio(Stadium):\n",
    "\n",
    "    if Stadium == 'Broncos Stadium at Mile High':\n",
    "        return 'Broncos Stadium At Mile High'\n",
    "    \n",
    "    elif Stadium in ('CenturyField', 'CenturyLink'):\n",
    "        return 'CenturyLink Field'\n",
    "    \n",
    "    elif Stadium == 'EverBank Field':\n",
    "        return 'Everbank Field'\n",
    "    \n",
    "    elif Stadium in ('FirstEnergy', 'FirstEnergy Stadium', 'FirstEnergyStadium'):\n",
    "        return 'First Energy Stadium'\n",
    "   \n",
    "    elif Stadium == 'Lambeau field':\n",
    "        return 'Lambeau Field'\n",
    "\n",
    "    elif Stadium == 'Los Angeles Memorial Coliesum':\n",
    "        return 'Los Angeles Memorial Coliseum'\n",
    "    \n",
    "    elif Stadium in ('M & T Bank Stadium', 'M&T Stadium'):\n",
    "        return 'M&T Bank Stadium'\n",
    "\n",
    "    elif Stadium in ('Mercedes-Benz Dome', 'Mercedes-Benz Superdome'):\n",
    "        return 'Mercedes-Benz SuperDome'\n",
    "    \n",
    "    elif Stadium in ('MetLife Stadium', 'Metlife Stadium', 'MetLife'):\n",
    "        return 'MetLife Stadium' \n",
    "    \n",
    "    elif Stadium == 'NRG':\n",
    "        return 'NRG Stadium' \n",
    "\n",
    "    elif Stadium == 'Oakland-Alameda County Coliseum':\n",
    "        return 'Oakland Alameda-County Coliseum' \n",
    "    \n",
    "    elif Stadium == 'Paul Brown Stdium':\n",
    "        return 'Paul Brown Stadium' \n",
    "\n",
    "    elif Stadium == 'Twickenham':\n",
    "        return 'Twickenham Stadium' \n",
    "    \n",
    "    else:\n",
    "        return Stadium\n",
    "    \n",
    "# Funcao para agrupar a localizacao do estadio e do jogo\n",
    "def agrupar_local(Location):\n",
    "\n",
    "    if Location == \"Arlington, Texas\":\n",
    "        return \"Arlington, TX\"\n",
    "    elif Location in (\"Baltimore, Maryland\",\"Baltimore, Md.\"):\n",
    "        return \"Baltimore, MD\"\n",
    "    elif Location == \"Charlotte, North Carolina\":\n",
    "        return \"Charlotte, NC\"\n",
    "    elif Location == \"Chicago. IL\":\n",
    "        return \"Chicago, IL\"\n",
    "    elif Location == \"Cincinnati, Ohio\":\n",
    "        return \"Cincinnati, OH\"\n",
    "    elif Location in (\"Cleveland\",\"Cleveland Ohio\",\"Cleveland, Ohio\",\"Cleveland,Ohio\"):\n",
    "        return \"Cleveland, OH\"\n",
    "    elif Location == \"Detroit\":\n",
    "        return \"Detroit, MI\"\n",
    "    elif Location == \"E. Rutherford, NJ\" or Location == \"East Rutherford, N.J.\":\n",
    "        return \"East Rutherford, NJ\"\n",
    "    elif Location == \"Foxborough, Ma\":\n",
    "        return \"Foxborough, MA\"\n",
    "    elif Location == \"Houston, Texas\":\n",
    "        return \"Houston, TX\"\n",
    "    elif Location in (\"Jacksonville Florida\",\"Jacksonville, Fl\",\"Jacksonville, Florida\"):\n",
    "        return \"Jacksonville, FL\"\n",
    "    elif Location == \"London\":\n",
    "        return \"London, England\"\n",
    "    elif Location == \"Los Angeles, Calif.\":\n",
    "        return \"Los Angeles, CA\"\n",
    "    elif Location == \"Miami Gardens, Fla.\":\n",
    "        return \"Miami Gardens, FLA\"\n",
    "    elif Location in (\"New Orleans\",\"New Orleans, La.\"):\n",
    "        return \"New Orleans, LA\"\n",
    "    elif Location == \"Orchard Park NY\":\n",
    "        return \"Orchard Park, NY\"\n",
    "    elif Location == \"Philadelphia, Pa.\":\n",
    "        return \"Philadelphia, PA\"\n",
    "    elif Location == \"Pittsburgh\":\n",
    "        return \"Pittsburgh, PA\"\n",
    "    elif Location == \"Seattle\":\n",
    "        return \"Seattle, WA\"\n",
    "    else:\n",
    "        return Location\n",
    "    \n",
    "# Funcao para agrupar o gramado do estadio\n",
    "def agrupar_gramado(Turf):\n",
    "    if Turf == 'Artifical':\n",
    "        return 'Artificial'\n",
    "    \n",
    "    elif Turf in ('FieldTurf', 'Field turf'):\n",
    "        return 'Field Turf'\n",
    "\n",
    "    elif Turf in ('FieldTurf360', 'FieldTurf 360'):\n",
    "        return 'Field Turf 360'\n",
    "\n",
    "    elif Turf in ('Natural', 'Natural grass', 'Naturall Grass', 'grass', 'natural grass', 'SISGrass', 'Natural Grass'):\n",
    "        return \"Grass\"\n",
    "\n",
    "    elif Turf == \"UBU Sports Speed S5-M\":\n",
    "        return \"UBU Speed Series-S5-M\"\n",
    "\n",
    "    else:\n",
    "        return Turf\n",
    "\n",
    "# Funcao para agrupar os dados de direcao do vento\n",
    "def agrupa_wind_direction(WindDirection):\n",
    "    wd = str(WindDirection).upper()\n",
    "    \n",
    "    if wd == 'N' or 'FROM N' in wd:\n",
    "        return 'north'\n",
    "    if wd == 'S' or 'FROM S' in wd:\n",
    "        return 'south'\n",
    "    if wd == 'W' or 'FROM W' in wd:\n",
    "        return 'west'\n",
    "    if wd == 'E' or 'FROM E' in wd:\n",
    "        return 'east'\n",
    "    \n",
    "    if 'FROM SW' in wd or 'FROM SSW' in wd or 'FROM WSW' in wd:\n",
    "        return 'south west'\n",
    "    if 'FROM SE' in wd or 'FROM SSE' in wd or 'FROM ESE' in wd:\n",
    "        return 'south east'\n",
    "    if 'FROM NW' in wd or 'FROM NNW' in wd or 'FROM WNW' in wd:\n",
    "        return 'north west'\n",
    "    if 'FROM NE' in wd or 'FROM NNE' in wd or 'FROM ENE' in wd:\n",
    "        return 'north east'\n",
    "    \n",
    "    if 'NW' in wd or 'NORTHWEST' in wd:\n",
    "        return 'north west'\n",
    "    if 'NE' in wd or 'NORTH EAST' in wd:\n",
    "        return 'north east'\n",
    "    if 'SW' in wd or 'SOUTHWEST' in wd:\n",
    "        return 'south west'\n",
    "    if 'SE' in wd or 'SOUTHEAST' in wd:\n",
    "        return 'south east'\n",
    "\n",
    "    return 'unknown'\n",
    "\n",
    "# Funcao para agrupar as descricoes de clima\n",
    "def agrupar_clima(GameWeather):\n",
    "    chuva   = ['Rainy', 'Rain Chance 40%', 'Showers',\n",
    "               'Cloudy with periods of rain, thunder possible. Winds shifting to WNW, 10-20 mph.',\n",
    "               'Scattered Showers', 'Cloudy, Rain', 'Rain shower', 'Light Rain', 'Rain']\n",
    "    nublado = ['Cloudy, light snow accumulating 1-3\"', 'Party Cloudy', 'Cloudy, chance of rain',\n",
    "               'Coudy', 'Cloudy, 50% change of rain', 'Rain likely, temps in low 40s.',\n",
    "               'Cloudy and cold', 'Cloudy, fog started developing in 2nd quarter',\n",
    "               'Partly Clouidy', '30% Chance of Rain', 'Mostly Coudy', 'Cloudy and Cool',\n",
    "               'cloudy', 'Partly cloudy', 'Overcast', 'Hazy', 'Mostly cloudy', 'Mostly Cloudy',\n",
    "               'Partly Cloudy', 'Cloudy']\n",
    "    limpo   = ['Partly clear', 'Sunny and clear', 'Sun & clouds', 'Clear and Sunny',\n",
    "               'Sunny and cold', 'Sunny Skies', 'Clear and Cool', 'Clear and sunny',\n",
    "               'Sunny, highs to upper 80s', 'Mostly Sunny Skies', 'Cold',\n",
    "               'Clear and warm', 'Sunny and warm', 'Clear and cold', 'Mostly sunny',\n",
    "               'T: 51; H: 55; W: NW 10 mph', 'Clear Skies', 'Clear skies', 'Partly sunny',\n",
    "               'Fair', 'Partly Sunny', 'Mostly Sunny', 'Clear', 'Sunny']\n",
    "    neve    = ['Heavy lake effect snow', 'Snow']\n",
    "    none    = ['N/A Indoor', 'Indoors', 'Indoor', 'N/A (Indoors)', 'Controlled Climate']\n",
    "\n",
    "    \n",
    "    if GameWeather in chuva:\n",
    "        return 'chuva'\n",
    "    elif GameWeather in nublado:\n",
    "        return 'nublado'\n",
    "    elif GameWeather in limpo:\n",
    "        return 'limpo'\n",
    "    elif GameWeather in neve:\n",
    "        return 'neve'\n",
    "    elif GameWeather in none:\n",
    "        return 'none'\n",
    "    else:\n",
    "        return 'none' # se for n/a\n",
    "    \n",
    "# Funcao para converter a velocidade do vento\n",
    "def convert_wind_speed(WindSpeed):\n",
    "    ws = str(WindSpeed)\n",
    "\n",
    "    if ws.isdigit():\n",
    "        return int(ws)\n",
    "\n",
    "    if '-' in ws:\n",
    "        return int(ws.split('-')[0])\n",
    "\n",
    "    if ws.split(' ')[0].isdigit():\n",
    "        return int(ws.split(' ')[0])\n",
    "\n",
    "    if 'mph' in ws.lower():\n",
    "        return int(ws.lower().split('mph')[0])\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "# Funcao para converter altura de feet-inches para centimetros\n",
    "def convert_to_cm(ft_in):\n",
    "    h_ft   = int(ft_in.split('-')[0])\n",
    "    h_inch = int(ft_in.split('-')[1])\n",
    "    h_inch += h_ft * 12\n",
    "    h_cm = round(h_inch * 2.54, 1)\n",
    "    #print(\"Your height is : %d cm.\" % h_cm)   \n",
    "    \n",
    "    return h_cm\n",
    "\n",
    "# Funcao para converter peso em lbs para kg\n",
    "def convert_to_kg(lbs):\n",
    "    kg = lbs * 0.45359237\n",
    "    #print(\"The weight is\", kg, \"in kilograms\")\n",
    "    \n",
    "    return kg\n",
    "\n",
    "# Funcao para converter temperatura Fahrenheit para Celsius\n",
    "def convert_to_celsius(fah):\n",
    "    celsius = (fah - 32) * 5.0/9.0\n",
    "    #print(\"Temperature:\", fah, \"Fahrenheit = \", celsius, \" C\")\n",
    "    return celsius\n",
    "\n",
    "# Funcao para converter as features de data e extrair dia, mes, ano, hora, minuto, segundo\n",
    "def convert_data(data):\n",
    "    data['PlayerBirthDate'] = data['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n",
    "    data['PlayerBirthDate_day'] = data['PlayerBirthDate'].dt.day.astype(int)\n",
    "    data['PlayerBirthDate_month'] = data['PlayerBirthDate'].dt.month.astype(int)\n",
    "    data['PlayerBirthDate_year'] = data['PlayerBirthDate'].dt.year.astype(int)\n",
    "\n",
    "    data['TimeSnap'] = data['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    data['TimeSnap_min'] = data['TimeSnap'].dt.minute.astype(int)\n",
    "    data['TimeSnap_seg'] = data['TimeSnap'].dt.second.astype(int)\n",
    "    \n",
    "    data['TimeHandoff'] = data['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    data['TimeHandoff_min'] = data['TimeHandoff'].dt.minute.astype(int)\n",
    "    data['TimeHandoff_seg'] = data['TimeHandoff'].dt.second.astype(int)\n",
    "    \n",
    "    \n",
    "# Funcao para converter uma string horario em segundos\n",
    "def str_to_seconds(time):\n",
    "    time = time.split(':')\n",
    "    sec = int(time[0])*60 + int(time[1]) + int(time[2])/60\n",
    "    return sec\n",
    "\n",
    "# Funcao para a metrica de validacao do modelo\n",
    "def funcao_crps(labels,predictions) :\n",
    "    y_pred = np.zeros((len(labels),199))\n",
    "    y_ans = np.zeros((len(labels),199))\n",
    "    j = np.array(range(199))\n",
    "    for i,(p,t) in enumerate(zip(np.round(scaler.inverse_transform(predictions)),labels)) :\n",
    "        k2 = j[j>=p-10]\n",
    "        y_pred[i][k2]=(k2+10-p)*0.05\n",
    "        k1 = j[j>=p+10]\n",
    "        y_pred[i][k1]= 1.0\n",
    "        k3 = j[j>=t]\n",
    "        y_ans[i][k3]= 1.0\n",
    "                           \n",
    "    return 'CRPS: ', np.sum((y_pred-y_ans)**2)/(199*y_pred.shape[0]), False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao para realizar feature engineering no dataset (treino ou teste)\n",
    "def feature_engineering(df): \n",
    "    \n",
    "    # Limpeza e conversao dos dados\n",
    "    fill_na(df)\n",
    "    convert_data(df)\n",
    "    \n",
    "    # Conversao de algumas features\n",
    "    df['PlayerHeight']  = df['PlayerHeight'].apply(convert_to_cm)\n",
    "    df['PlayerWeight']  = df['PlayerWeight'].apply(convert_to_kg)\n",
    "    df['Temperature']   = df['Temperature'].apply(convert_to_celsius)\n",
    "    df['StadiumType']   = df['StadiumType'].apply(agrupar_tipo_estadio)\n",
    "    df['Stadium']       = df['Stadium'].apply(agrupar_estadio)\n",
    "    df['Location']      = df['Location'].apply(agrupar_local)\n",
    "    df['Turf']          = df['Turf'].apply(agrupar_gramado)\n",
    "    df['WindDirection'] = df['WindDirection'].apply(agrupa_wind_direction)\n",
    "    df['WindSpeed']     = df['WindSpeed'].apply(convert_wind_speed)\n",
    "    df['GameWeather']   = df['GameWeather'].apply(agrupar_clima)\n",
    "\n",
    "\n",
    "    # Corrigindo a feature Stadium\n",
    "    df.loc[df['Stadium'] == 'MetLife Stadium', 'StadiumType'] = 'outdoor'\n",
    "    df.loc[df['Stadium'] == 'StubHub Center', 'StadiumType'] = 'outdoor'    \n",
    "    \n",
    "    # Nova feature com a diferença entre o tempo de lançamento da bola até quando o jogador captura\n",
    "    df['TimeDifer'] = df.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)            \n",
    "         \n",
    "    # Nova feature para indicar se é o jogador que esta realizando a jogada (corredor)\n",
    "    df['IsRusher'] = df['NflId'] == df['NflIdRusher']\n",
    "    \n",
    "    # Novas features com base no horario do jogo\n",
    "    df['Morning']   = df['GameClock'].apply(lambda x : 1 if (int(x[0:2]) >=0 and int(x[0:2]) <12) else 0)\n",
    "    df['Afternoon'] = df['GameClock'].apply(lambda x : 1 if (int(x[0:2]) <18 and int(x[0:2]) >=12) else 0)\n",
    "    df['Evening']   = df['GameClock'].apply(lambda x : 1 if (int(x[0:2]) >= 18 and int(x[0:2]) < 24) else 0)\n",
    "    df['GameClock'] = df['GameClock'].apply(str_to_seconds) \n",
    "    \n",
    "    # Criando novas features com dados de Distance, YardLine e DefendersInTheBox\n",
    "    df['seconds_need_to_first_down'] = (df['Distance']*0.9144)/df['Dis']\n",
    "    df['seconds_need_to_YardsLine'] = (df['YardLine']*0.9144)/df['Dis']    \n",
    "    df['DefendersInTheBox_vs_Distance'] = df['DefendersInTheBox'] / df['Distance']\n",
    "    \n",
    "    # Ordenacao do dataset e renovando o index\n",
    "    df = df.sort_values(by=['PlayId', 'Team', 'IsRusher']).reset_index()\n",
    "    \n",
    "    # Removendo colunas que não serão utilizadas\n",
    "    df = df.drop(['index','Yards','GameId','PlayId','TimeHandoff','TimeSnap','PlayerBirthDate'], axis=1)\n",
    "\n",
    "    # Atribuindo media para os demais dados missing\n",
    "    #df_median = df.median()\n",
    "    #df.fillna(df_median, inplace=True)\n",
    "\n",
    "    # Removendo todas as variaveis categoricas\n",
    "    #cat_features = []\n",
    "    #for col in df.columns:\n",
    "    #    if df[col].dtype =='object':\n",
    "    #        cat_features.append(col)\n",
    "\n",
    "    #df = df.drop(cat_features, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um novo dataset aplicando Feature Engineering\n",
    "train_df = feature_engineering(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar somente para alguns modelos que nao tratam valores INF ou NAN\n",
    "train_df.replace(-np.inf,0,inplace=True)\n",
    "train_df.replace(np.inf,0,inplace=True)\n",
    "train_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando algumas variaveis categoricas para inteiro\n",
    "cleanup_nums = {\"StadiumType\": {\"outdoor\"      : 73, \n",
    "                                \"indoor_closed\": 17,\n",
    "                                \"dome_closed\"  : 5, \n",
    "                                \"indoor_open\"  : 2, \n",
    "                                \"dome_open\"    : 0,\n",
    "                                \"unknown\"      : 0\n",
    "                               },\n",
    "                \"Turf\":        {\"A-Turf Titan\"           : 33, \n",
    "                                \"Artificial\"             : 94,\n",
    "                                \"DD GrassMaster\"         : 15, \n",
    "                                \"Field Turf\"             : 16,\n",
    "                                \"Field Turf 360\"         : 2, \n",
    "                                \"Grass\"                  : 56,\n",
    "                                \"Twenty-Four/Seven Turf\" : 1,\n",
    "                                \"UBU Speed Series-S5-M\"  : 8\n",
    "                               },\n",
    "                \"GameWeather\": {\"nublado\" : 49, \n",
    "                                \"limpo\"   : 41,\n",
    "                                \"none\"    : 20, \n",
    "                                \"chuva\"   : 10,\n",
    "                                \"neve\"    : 0\n",
    "                               },\n",
    "                \"WindDirection\": {\"unknown\"    : 30, \n",
    "                                  \"south west\" : 15,\n",
    "                                  \"north west\" : 13, \n",
    "                                  \"north east\" : 13,\n",
    "                                  \"south east\" : 10,\n",
    "                                  \"south\"      : 6,\n",
    "                                  \"north\"      : 5,\n",
    "                                  \"west\"       : 5,\n",
    "                                  \"east\"       : 3\n",
    "                                 },               \n",
    "               \n",
    "               }\n",
    "train_df.replace(cleanup_nums, inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Instancia um label encoder object\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Iteracao para cada coluna do dataset de treino\n",
    "col_label_encoder = ['PlayerCollegeName','Team','Stadium','Location','PlayDirection','DisplayName']\n",
    "for col_label_encoder in train_df:\n",
    "    if train_df[col_label_encoder].dtype == 'object':\n",
    "        le.fit_transform(train_df[col_label_encoder].astype(str))\n",
    "        train_df[col_label_encoder] = le.transform(train_df[col_label_encoder])   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Aplicando One_hot_encoding\n",
    "train_df = pd.concat([train_df.drop(['Position'], axis=1), \n",
    "                      pd.get_dummies(train_df['Position'], prefix='Position')], axis=1)\n",
    "\n",
    "train_df = pd.concat([train_df.drop(['Season'], axis=1), \n",
    "                      pd.get_dummies(train_df['Season'], prefix='Season')], axis=1)\n",
    "\n",
    "train_df = pd.concat([train_df.drop(['HomeTeamAbbr'], axis=1), \n",
    "                      pd.get_dummies(train_df['HomeTeamAbbr'], prefix='HomeTeamAbbr')], axis=1)\n",
    "\n",
    "train_df = pd.concat([train_df.drop(['VisitorTeamAbbr'], axis=1), \n",
    "                      pd.get_dummies(train_df['VisitorTeamAbbr'], prefix='VisitorTeamAbbr')], axis=1)\n",
    "\n",
    "train_df = pd.concat([train_df.drop(['PossessionTeam'], axis=1), \n",
    "                      pd.get_dummies(train_df['PossessionTeam'], prefix='PossessionTeam')], axis=1)\n",
    "\n",
    "train_df = pd.concat([train_df.drop(['FieldPosition'], axis=1), \n",
    "                      pd.get_dummies(train_df['FieldPosition'], prefix='FieldPosition')], axis=1)\n",
    "\n",
    "train_df = pd.concat([train_df.drop(['Quarter'], axis=1), \n",
    "                      pd.get_dummies(train_df['Quarter'], prefix='Quarter')], axis=1)\n",
    "\n",
    "train_df = pd.concat([train_df.drop(['OffenseFormation'], axis=1), \n",
    "                      pd.get_dummies(train_df['OffenseFormation'], prefix='OffenseFormation')], axis=1)\n",
    "\n",
    "train_df = pd.concat([train_df.drop(['DefensePersonnel'], axis=1), \n",
    "                      pd.get_dummies(train_df['DefensePersonnel'], prefix='DefensePersonnel')], axis=1)\n",
    "\n",
    "train_df = pd.concat([train_df.drop(['OffensePersonnel'], axis=1), \n",
    "                      pd.get_dummies(train_df['OffensePersonnel'], prefix='OffensePersonnel')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_names = ['Team','NflId','DisplayName','JerseyNumber','NflIdRusher','PlayerCollegeName',\n",
    "                      'Stadium','Location','PlayDirection','DisplayName','StadiumType',\n",
    "                      'Turf','GameWeather','WindDirection','Position','Season','HomeTeamAbbr','VisitorTeamAbbr',\n",
    "                      'PossessionTeam','FieldPosition','Quarter','OffenseFormation','DefensePersonnel',\n",
    "                      'OffensePersonnel']\n",
    "cat_features = [train.columns.get_loc(col) for col in cat_features_names]\n",
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_new = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo todas as variaveis categoricas\n",
    "drop_features = []\n",
    "for col in train_df_new.columns:\n",
    "    if train_df_new[col].dtype =='object':\n",
    "        drop_features.append(col)\n",
    "\n",
    "train_df_new = train_df_new.drop(drop_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar somente para alguns modelos que nao tratam valores INF ou NAN\n",
    "train_df_new.replace(-np.inf,0,inplace=True)\n",
    "train_df_new.replace(np.inf,0,inplace=True)\n",
    "train_df_new.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_new = train_df_new.drop(['NflId','NflIdRusher'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_new[\"JerseyNumber\"] = train_df_new[\"JerseyNumber\"].astype(int)\n",
    "train_df_new[\"Season\"] = train_df_new[\"Season\"].astype(int)\n",
    "train_df_new[\"Quarter\"] = train_df_new[\"Quarter\"].astype(int)\n",
    "train_df_new[\"Week\"] = train_df_new[\"Week\"].astype(int)\n",
    "train_df_new[\"StadiumType\"] = train_df_new[\"StadiumType\"].astype(int)\n",
    "train_df_new[\"Turf\"] = train_df_new[\"Turf\"].astype(int)\n",
    "train_df_new[\"GameWeather\"] = train_df_new[\"GameWeather\"].astype(int)\n",
    "train_df_new[\"WindDirection\"] = train_df_new[\"WindDirection\"].astype(int)\n",
    "train_df_new[\"Morning\"] = train_df_new[\"Morning\"].astype(int)\n",
    "train_df_new[\"Afternoon\"] = train_df_new[\"Afternoon\"].astype(int)\n",
    "train_df_new[\"Evening\"] = train_df_new[\"Evening\"].astype(int)\n",
    "train_df_new[\"PlayerBirthDate_day\"] = train_df_new[\"PlayerBirthDate_day\"].astype(int)\n",
    "train_df_new[\"PlayerBirthDate_month\"] = train_df_new[\"PlayerBirthDate_month\"].astype(int)\n",
    "train_df_new[\"PlayerBirthDate_year\"] = train_df_new[\"PlayerBirthDate_year\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação e Validação dos Modelos de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo uma limpeza na memoria\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup cross validation folds\n",
    "kf = 5\n",
    "folds = KFold(n_splits=kf, shuffle=False, random_state=42)\n",
    "print(str(kf) + ' Folds para treino...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificando as features para o modelo\n",
    "features = list(train_df_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando matriz de treino\n",
    "train_data = np.zeros((509762//22,len(features))) \n",
    "\n",
    "for i in tqdm.tqdm(range(0,509762,22)):\n",
    "    count=0\n",
    "    for c in features:\n",
    "        train_data[i//22][count] = train_df_new[c][i]\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split de dados e label\n",
    "X_train = pd.DataFrame(data=train_data,columns=features)\n",
    "y_train_ = np.array([train[\"Yards\"][i] for i in range(0,509762,22)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizacao das features \n",
    "y_tr = np.zeros(len(y_train_),dtype=np.float)\n",
    "for i in range(len(y_tr)):\n",
    "    y_tr[i]=(y_train_[i])\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit([[y] for y in y_tr])\n",
    "y_tr = np.array([y[0] for y in scaler.transform([[y] for y in y_tr])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame()\n",
    "oof = np.zeros(len(X_train))\n",
    "tr_rmse  = []\n",
    "val_rmse = []\n",
    "models   = []\n",
    "\n",
    "for fold_, (tr_idx, val_idx) in enumerate(folds.split(X_train,y_tr)):\n",
    "\n",
    "    tr_x, vl_x = X_train.iloc[tr_idx][features], X_train.iloc[val_idx][features]\n",
    "    tr_y, vl_y = y_tr[tr_idx], y_tr[val_idx]\n",
    "\n",
    "    print({'Fold: ':fold_, 'Train size':len(tr_x), 'Val size':len(vl_x)})\n",
    "\n",
    "    tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "    vl_data = lgb.Dataset(vl_x, label=vl_y)  \n",
    "    \n",
    "    \"\"\"model = lgb.LGBMRegressor(n_estimators=1000,\n",
    "                              learning_rate=0.01,\n",
    "                              boosting=\"gbdt\",\n",
    "                              feature_fraction=0.9,\n",
    "                              subsample=0.2,\n",
    "                              subsample_freq=1,\n",
    "                              num_leaves=20,\n",
    "                              metric='rmse')\n",
    "    model.fit(tr_x, tr_y,\n",
    "              eval_set=[(vl_x, vl_y)],\n",
    "              eval_metric=funcao_crps,\n",
    "              early_stopping_rounds=100,\n",
    "              verbose=200)\"\"\"\n",
    "    \n",
    "    \"\"\"model = XGB.XGBRegressor(objective='reg:squarederror',\n",
    "                             max_depth=8,\n",
    "                             n_estimators=100,\n",
    "                             min_child_weight=300,\n",
    "                             colsample_bytree=0.8,\n",
    "                             subsample=0.8,\n",
    "                             eta=0.01,\n",
    "                             metric='rmse',\n",
    "                             seed=42)\n",
    "\n",
    "    model.fit(tr_x, tr_y,\n",
    "              #eval_metric=funcao_crps,\n",
    "              eval_set=[(vl_x, vl_y)],\n",
    "              verbose=200,\n",
    "              early_stopping_rounds = 100)\"\"\"\n",
    "    \n",
    "    \n",
    "    model = CatBoostRegressor(n_estimators=1000,\n",
    "                              learning_rate=0.01)\n",
    "\n",
    "    model.fit(tr_x, tr_y,\n",
    "              eval_set=[(vl_x, vl_y)],\n",
    "              early_stopping_rounds=100,\n",
    "              use_best_model=True,\n",
    "              verbose=20)\n",
    "\n",
    "    oof[val_idx] = model.predict(vl_x)\n",
    "    \n",
    "    val_score = mean_squared_error(vl_y, oof[val_idx])\n",
    "    val_rmse.append(val_score)\n",
    "    \n",
    "    tr_score = mean_squared_error(tr_y, model.predict(tr_x))\n",
    "    tr_rmse.append(tr_score)\n",
    "    \n",
    "    models.append(model)\n",
    "    \n",
    "    # Feature importance\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = tr_x.columns\n",
    "    fold_importance_df[\"importance\"] = model.feature_importances_[:len(tr_x.columns)]\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = XGB.plot_importance(models[3], importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n",
    "        .groupby(\"Feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:50].index)\n",
    "best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(18,18))\n",
    "sns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\n",
    "plt.title('XBoost Features Importance (media dos folds)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = lgb.plot_importance(models[3], importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n",
    "        .groupby(\"Feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:50].index)\n",
    "best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(18,18))\n",
    "sns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\n",
    "plt.title('LightGBM Features Importance (media dos folds)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validacao do modelo\n",
    "# Imprimir o score de treino e teste\n",
    "\n",
    "mean_rmse_tr = np.mean(tr_rmse)\n",
    "std_rmse_tr =  np.std(tr_rmse)\n",
    "\n",
    "mean_rmse_val =  np.mean(val_rmse)\n",
    "std_rmse_val =  np.std(val_rmse)\n",
    "\n",
    "all_rmse = mean_squared_error(oof,y_tr)\n",
    "\n",
    "print(\"Score de Treino\")\n",
    "print(\"Média RMSE: %.5f, std: %.5f.\" % (mean_rmse_tr, std_rmse_tr),'\\n')\n",
    "\n",
    "print(\"Score de Validação\")\n",
    "print(\"Média RMSE: %.5f, std: %.5f.\" % (mean_rmse_val, std_rmse_val),'\\n')\n",
    "\n",
    "print(\"Geral: %.5f.\" % (all_rmse),'\\n')\n",
    "\n",
    "print(\"CRPS: %.6f.\" % (funcao_crps(y_tr,oof)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realizando a submissão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao para realizar feature engineering no dataset de teste\n",
    "def feature_engineering_test(df): \n",
    "    \n",
    "    # Limpeza e conversao dos dados\n",
    "    fill_na(df)\n",
    "    convert_data(df)\n",
    "    \n",
    "    df_median = df.median()\n",
    "    \n",
    "    # Conversao de algumas features\n",
    "    df['PlayerHeight']  = df['PlayerHeight'].apply(convert_to_cm)\n",
    "    df['PlayerWeight']  = df['PlayerWeight'].apply(convert_to_kg)\n",
    "    df['Temperature']   = df['Temperature'].apply(convert_to_celsius)\n",
    "    df['StadiumType']   = df['StadiumType'].apply(agrupar_tipo_estadio)\n",
    "    df['Stadium']       = df['Stadium'].apply(agrupar_estadio)\n",
    "    df['Location']      = df['Location'].apply(agrupar_local)\n",
    "    df['Turf']          = df['Turf'].apply(agrupar_gramado)\n",
    "    df['WindDirection'] = df['WindDirection'].apply(agrupa_wind_direction)\n",
    "    df['WindSpeed']     = df['WindSpeed'].apply(convert_wind_speed)\n",
    "    df['GameWeather']   = df['GameWeather'].apply(agrupar_clima)\n",
    "\n",
    "\n",
    "    # Corrigindo a feature Stadium\n",
    "    df.loc[df['Stadium'] == 'MetLife Stadium', 'StadiumType'] = 'outdoor'\n",
    "    df.loc[df['Stadium'] == 'StubHub Center', 'StadiumType'] = 'outdoor'    \n",
    "    \n",
    "    # Nova feature com a diferença entre o tempo de lançamento da bola até quando o jogador captura\n",
    "    df['TimeDifer'] = df.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)            \n",
    "         \n",
    "    # Nova feature para indicar se é o jogador que esta realizando a jogada (corredor)\n",
    "    df['IsRusher'] = df['NflId'] == df['NflIdRusher']\n",
    "    \n",
    "    # Novas features com base no horario do jogo\n",
    "    df['Morning']   = df['GameClock'].apply(lambda x : 1 if (int(x[0:2]) >=0 and int(x[0:2]) <12) else 0)\n",
    "    df['Afternoon'] = df['GameClock'].apply(lambda x : 1 if (int(x[0:2]) <18 and int(x[0:2]) >=12) else 0)\n",
    "    df['Evening']   = df['GameClock'].apply(lambda x : 1 if (int(x[0:2]) >= 18 and int(x[0:2]) < 24) else 0)\n",
    "    df['GameClock'] = df['GameClock'].apply(str_to_seconds) \n",
    "    \n",
    "    # Criando novas features com dados de Distance, YardLine e DefendersInTheBox\n",
    "    df['seconds_need_to_first_down'] = (df['Distance']*0.9144)/df['Dis']\n",
    "    df['seconds_need_to_YardsLine'] = (df['YardLine']*0.9144)/df['Dis']    \n",
    "    df['DefendersInTheBox_vs_Distance'] = df['DefendersInTheBox'] / df['Distance']\n",
    "    \n",
    "    # Ordenacao do dataset e renovando o index\n",
    "    df = df.sort_values(by=['PlayId', 'Team', 'IsRusher']).reset_index()\n",
    "    \n",
    "    # Removendo colunas que não serão utilizadas\n",
    "    df = df.drop(['index', 'GameId','PlayId','NflId', 'DisplayName','NflIdRusher', 'TimeHandoff', 'TimeSnap', 'PlayerBirthDate'], axis=1)\n",
    "\n",
    "    # Atribuindo media para os demais dados missing\n",
    "    df.fillna(df_median, inplace=True)\n",
    "\n",
    "    # Executar somente para alguns modelos que nao tratam valores INF ou NAN\n",
    "    #train_df.replace(-np.inf,0,inplace=True)\n",
    "    #train_df.replace(np.inf,0,inplace=True)\n",
    "\n",
    "    # Removendo todas as variaveis categoricas\n",
    "    cat_features = []\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype =='object':\n",
    "            cat_features.append(col)\n",
    "\n",
    "    df = df.drop(cat_features, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.competitions import nflrush\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "index = 0\n",
    "\n",
    "env = nflrush.make_env()\n",
    "\n",
    "for (test, sample_prediction_df) in tqdm.tqdm(env.iter_test()):\n",
    "    df_test = feature_engineering_test(test)\n",
    "    \n",
    "    count=0\n",
    "    test_data = np.zeros((1,len(features)))\n",
    "\n",
    "    for c in features:\n",
    "        if c in df_test:\n",
    "            try:\n",
    "                test_data[0][count] = df_test[c][index]\n",
    "            except:\n",
    "                test_data[0][count] = np.nan\n",
    "            count+=1\n",
    "    \n",
    "    y_pred = np.zeros(199)        \n",
    "    y_pred_p = np.sum(np.round(scaler.inverse_transform([model.predict(test_data)[0] for model in models])))/n_folds\n",
    "    y_pred_p += 99\n",
    "    \n",
    "    for j in range(199):\n",
    "        if j>=y_pred_p+10:\n",
    "            y_pred[j]=1.0\n",
    "        elif j>=y_pred_p-10:\n",
    "            y_pred[j]=(j+10-y_pred_p)*0.05\n",
    "    \n",
    "    env.predict(pd.DataFrame(data=[y_pred],columns=sample_prediction_df.columns))\n",
    "    \n",
    "    index += 22\n",
    "    \n",
    "env.write_submission_file()\n",
    "\n",
    "print([filename for filename in os.listdir('/kaggle/working') if '.csv' in filename])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
