{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following kernel here shows how the excellent kernel [here](https://www.kaggle.com/scirpus/hybrid-gp-and-nn) may benefit from adding some regularisation. Overfitting was suspected because the validation scores on the neural network were considerably below the public leaderboard score. [scirpus](https://www.kaggle.com/scirpus) produces a lot of high quality kernels for Kaggle so please be sure to upvote the kernel listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as mtr\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/kaggle/input/nfl-big-data-bowl-2020/train.csv\n",
    "train = pd.read_csv('../data/train.csv', usecols=['GameId', 'PlayId', 'Team', 'X', 'Y', 'S', 'A', 'Dis',\n",
    "                                                                               'Orientation', 'Dir', 'NflId', 'DisplayName', 'YardLine',\n",
    "                                                                               'Quarter', 'GameClock', 'PossessionTeam', 'Down', 'Distance',\n",
    "                                                                               'FieldPosition', 'NflIdRusher', 'OffenseFormation', \n",
    "                                                                               'OffensePersonnel', 'DefendersInTheBox', 'DefensePersonnel', \n",
    "                                                                               'PlayDirection', 'TimeHandoff', 'TimeSnap', 'Yards'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = train[['GameId','PlayId','Yards']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for anchoring offense moving left from {0,0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, deploy=False):\n",
    "    def new_X(x_coordinate, play_direction):\n",
    "        if play_direction == 'left':\n",
    "            return 120.0 - x_coordinate\n",
    "        else:\n",
    "            return x_coordinate\n",
    "\n",
    "    def new_line(rush_team, field_position, yardline):\n",
    "        if rush_team == field_position:\n",
    "            # offense starting at X = 0 plus the 10 yard endzone plus the line of scrimmage\n",
    "            return 10.0 + yardline\n",
    "        else:\n",
    "            # half the field plus the yards between midfield and the line of scrimmage\n",
    "            return 60.0 + (50 - yardline)\n",
    "\n",
    "    def new_orientation(angle, play_direction):\n",
    "        if play_direction == 'left':\n",
    "            new_angle = 360.0 - angle\n",
    "            if new_angle == 360.0:\n",
    "                new_angle = 0.0\n",
    "            return new_angle\n",
    "        else:\n",
    "            return angle\n",
    "\n",
    "    def euclidean_distance(x1,y1,x2,y2):\n",
    "        x_diff = (x1-x2)**2\n",
    "        y_diff = (y1-y2)**2\n",
    "\n",
    "        return np.sqrt(x_diff + y_diff)\n",
    "\n",
    "    def back_direction(orientation):\n",
    "        if orientation > 180.0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def update_yardline(df):\n",
    "        new_yardline = df[df['NflId'] == df['NflIdRusher']]\n",
    "        new_yardline['YardLine'] = new_yardline[['PossessionTeam','FieldPosition','YardLine']].apply(lambda x: new_line(x[0],x[1],x[2]), axis=1)\n",
    "        new_yardline = new_yardline[['GameId','PlayId','YardLine']]\n",
    "\n",
    "        return new_yardline\n",
    "\n",
    "    def update_orientation(df, yardline):\n",
    "        df['X'] = df[['X','PlayDirection']].apply(lambda x: new_X(x[0],x[1]), axis=1)\n",
    "        df['Orientation'] = df[['Orientation','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n",
    "        df['Dir'] = df[['Dir','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n",
    "\n",
    "        df = df.drop('YardLine', axis=1)\n",
    "        df = pd.merge(df, yardline, on=['GameId','PlayId'], how='inner')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def back_features(df):\n",
    "        carriers = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','NflIdRusher','X','Y','Orientation','Dir','YardLine']]\n",
    "        carriers['back_from_scrimmage'] = carriers['YardLine'] - carriers['X']\n",
    "        carriers['back_oriented_down_field'] = carriers['Orientation'].apply(lambda x: back_direction(x))\n",
    "        carriers['back_moving_down_field'] = carriers['Dir'].apply(lambda x: back_direction(x))\n",
    "        carriers = carriers.rename(columns={'X':'back_X',\n",
    "                                            'Y':'back_Y'})\n",
    "        carriers = carriers[['GameId','PlayId','NflIdRusher','back_X','back_Y','back_from_scrimmage','back_oriented_down_field','back_moving_down_field']]\n",
    "\n",
    "        return carriers\n",
    "\n",
    "    def features_relative_to_back(df, carriers):\n",
    "        player_distance = df[['GameId','PlayId','NflId','X','Y']]\n",
    "        player_distance = pd.merge(player_distance, carriers, on=['GameId','PlayId'], how='inner')\n",
    "        player_distance = player_distance[player_distance['NflId'] != player_distance['NflIdRusher']]\n",
    "        player_distance['dist_to_back'] = player_distance[['X','Y','back_X','back_Y']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n",
    "\n",
    "        player_distance = player_distance.groupby(['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field'])\\\n",
    "                                         .agg({'dist_to_back':['min','max','mean','std']})\\\n",
    "                                         .reset_index()\n",
    "        player_distance.columns = ['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field',\n",
    "                                   'min_dist','max_dist','mean_dist','std_dist']\n",
    "\n",
    "        return player_distance\n",
    "\n",
    "    def defense_features(df):\n",
    "        rusher = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','Team','X','Y']]\n",
    "        rusher.columns = ['GameId','PlayId','RusherTeam','RusherX','RusherY']\n",
    "\n",
    "        defense = pd.merge(df,rusher,on=['GameId','PlayId'],how='inner')\n",
    "        defense = defense[defense['Team'] != defense['RusherTeam']][['GameId','PlayId','X','Y','RusherX','RusherY']]\n",
    "        defense['def_dist_to_back'] = defense[['X','Y','RusherX','RusherY']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n",
    "\n",
    "        defense = defense.groupby(['GameId','PlayId'])\\\n",
    "                         .agg({'def_dist_to_back':['min','max','mean','std']})\\\n",
    "                         .reset_index()\n",
    "        defense.columns = ['GameId','PlayId','def_min_dist','def_max_dist','def_mean_dist','def_std_dist']\n",
    "\n",
    "        return defense\n",
    "\n",
    "    def static_features(df):\n",
    "        static_features = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','X','Y','S','A','Dis','Orientation','Dir',\n",
    "                                                            'YardLine','Quarter','Down','Distance','DefendersInTheBox']].drop_duplicates()\n",
    "        static_features['DefendersInTheBox'] = static_features['DefendersInTheBox'].fillna(np.mean(static_features['DefendersInTheBox']))\n",
    "\n",
    "        return static_features\n",
    "\n",
    "    def split_personnel(s):\n",
    "        splits = s.split(',')\n",
    "        for i in range(len(splits)):\n",
    "            splits[i] = splits[i].strip()\n",
    "\n",
    "        return splits\n",
    "\n",
    "    def defense_formation(l):\n",
    "        dl = 0\n",
    "        lb = 0\n",
    "        db = 0\n",
    "        other = 0\n",
    "\n",
    "        for position in l:\n",
    "            sub_string = position.split(' ')\n",
    "            if sub_string[1] == 'DL':\n",
    "                dl += int(sub_string[0])\n",
    "            elif sub_string[1] in ['LB','OL']:\n",
    "                lb += int(sub_string[0])\n",
    "            else:\n",
    "                db += int(sub_string[0])\n",
    "\n",
    "        counts = (dl,lb,db,other)\n",
    "\n",
    "        return counts\n",
    "\n",
    "    def offense_formation(l):\n",
    "        qb = 0\n",
    "        rb = 0\n",
    "        wr = 0\n",
    "        te = 0\n",
    "        ol = 0\n",
    "\n",
    "        sub_total = 0\n",
    "        qb_listed = False\n",
    "        for position in l:\n",
    "            sub_string = position.split(' ')\n",
    "            pos = sub_string[1]\n",
    "            cnt = int(sub_string[0])\n",
    "\n",
    "            if pos == 'QB':\n",
    "                qb += cnt\n",
    "                sub_total += cnt\n",
    "                qb_listed = True\n",
    "            # Assuming LB is a line backer lined up as full back\n",
    "            elif pos in ['RB','LB']:\n",
    "                rb += cnt\n",
    "                sub_total += cnt\n",
    "            # Assuming DB is a defensive back and lined up as WR\n",
    "            elif pos in ['WR','DB']:\n",
    "                wr += cnt\n",
    "                sub_total += cnt\n",
    "            elif pos == 'TE':\n",
    "                te += cnt\n",
    "                sub_total += cnt\n",
    "            # Assuming DL is a defensive lineman lined up as an additional line man\n",
    "            else:\n",
    "                ol += cnt\n",
    "                sub_total += cnt\n",
    "\n",
    "        # If not all 11 players were noted at given positions we need to make some assumptions\n",
    "        # I will assume if a QB is not listed then there was 1 QB on the play\n",
    "        # If a QB is listed then I'm going to assume the rest of the positions are at OL\n",
    "        # This might be flawed but it looks like RB, TE and WR are always listed in the personnel\n",
    "        if sub_total < 11:\n",
    "            diff = 11 - sub_total\n",
    "            if not qb_listed:\n",
    "                qb += 1\n",
    "                diff -= 1\n",
    "            ol += diff\n",
    "\n",
    "        counts = (qb,rb,wr,te,ol)\n",
    "\n",
    "        return counts    \n",
    "\n",
    "    def personnel_features(df):\n",
    "        personnel = df[['GameId','PlayId','OffensePersonnel','DefensePersonnel']].drop_duplicates()\n",
    "        personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: split_personnel(x))\n",
    "        personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: defense_formation(x))\n",
    "        #personnel['num_DL'] = personnel['DefensePersonnel'].apply(lambda x: x[0])\n",
    "        #personnel['num_LB'] = personnel['DefensePersonnel'].apply(lambda x: x[1])\n",
    "        #personnel['num_DB'] = personnel['DefensePersonnel'].apply(lambda x: x[2])\n",
    "\n",
    "        personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: split_personnel(x))\n",
    "        personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: offense_formation(x))\n",
    "        #personnel['num_QB'] = personnel['OffensePersonnel'].apply(lambda x: x[0])\n",
    "        #personnel['num_RB'] = personnel['OffensePersonnel'].apply(lambda x: x[1])\n",
    "        #personnel['num_WR'] = personnel['OffensePersonnel'].apply(lambda x: x[2])\n",
    "        #personnel['num_TE'] = personnel['OffensePersonnel'].apply(lambda x: x[3])\n",
    "        #personnel['num_OL'] = personnel['OffensePersonnel'].apply(lambda x: x[4])\n",
    "\n",
    "        # Let's create some features to specify if the OL is covered\n",
    "        #personnel['OL_diff'] = personnel['num_OL'] - personnel['num_DL']\n",
    "        #personnel['OL_TE_diff'] = (personnel['num_OL'] + personnel['num_TE']) - personnel['num_DL']\n",
    "        # Let's create a feature to specify if the defense is preventing the run\n",
    "        # Let's just assume 7 or more DL and LB is run prevention\n",
    "        #personnel['run_def'] = (personnel['num_DL'] + personnel['num_LB'] > 6).astype(int)\n",
    "\n",
    "        personnel.drop(['OffensePersonnel','DefensePersonnel'], axis=1, inplace=True)\n",
    "        \n",
    "        return personnel\n",
    "\n",
    "    def combine_features(relative_to_back, defense, static, personnel, deploy=deploy):\n",
    "        df = pd.merge(relative_to_back,defense,on=['GameId','PlayId'],how='inner')\n",
    "        df = pd.merge(df,static,on=['GameId','PlayId'],how='inner')\n",
    "        df = pd.merge(df,personnel,on=['GameId','PlayId'],how='inner')\n",
    "\n",
    "        if not deploy:\n",
    "            df = pd.merge(df, outcomes, on=['GameId','PlayId'], how='inner')\n",
    "\n",
    "        return df\n",
    "    \n",
    "    yardline = update_yardline(df)\n",
    "    df = update_orientation(df, yardline)\n",
    "    back_feats = back_features(df)\n",
    "    rel_back = features_relative_to_back(df, back_feats)\n",
    "    def_feats = defense_features(df)\n",
    "    static_feats = static_features(df)\n",
    "    personnel = personnel_features(df)\n",
    "    basetable = combine_features(rel_back, def_feats, static_feats, personnel, deploy=deploy)\n",
    "    \n",
    "    return basetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodrigolima82/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 873 ms, total: 1min 14s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%time train_basetable = create_features(train, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GameId</th>\n",
       "      <th>PlayId</th>\n",
       "      <th>back_from_scrimmage</th>\n",
       "      <th>back_oriented_down_field</th>\n",
       "      <th>back_moving_down_field</th>\n",
       "      <th>min_dist</th>\n",
       "      <th>max_dist</th>\n",
       "      <th>mean_dist</th>\n",
       "      <th>std_dist</th>\n",
       "      <th>def_min_dist</th>\n",
       "      <th>def_max_dist</th>\n",
       "      <th>def_mean_dist</th>\n",
       "      <th>def_std_dist</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>S</th>\n",
       "      <th>A</th>\n",
       "      <th>Dis</th>\n",
       "      <th>Orientation</th>\n",
       "      <th>Dir</th>\n",
       "      <th>YardLine</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Down</th>\n",
       "      <th>Distance</th>\n",
       "      <th>DefendersInTheBox</th>\n",
       "      <th>Yards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907000118</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.449724</td>\n",
       "      <td>22.415872</td>\n",
       "      <td>8.046559</td>\n",
       "      <td>4.873845</td>\n",
       "      <td>4.593310</td>\n",
       "      <td>22.415872</td>\n",
       "      <td>9.752491</td>\n",
       "      <td>5.327299</td>\n",
       "      <td>41.25</td>\n",
       "      <td>30.53</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.38</td>\n",
       "      <td>198.02</td>\n",
       "      <td>114.26</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907000139</td>\n",
       "      <td>4.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.792023</td>\n",
       "      <td>23.025872</td>\n",
       "      <td>8.614623</td>\n",
       "      <td>5.598683</td>\n",
       "      <td>4.287773</td>\n",
       "      <td>23.025872</td>\n",
       "      <td>10.297028</td>\n",
       "      <td>5.833217</td>\n",
       "      <td>48.93</td>\n",
       "      <td>27.16</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.34</td>\n",
       "      <td>149.30</td>\n",
       "      <td>47.80</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907000189</td>\n",
       "      <td>3.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.646390</td>\n",
       "      <td>20.726285</td>\n",
       "      <td>8.482583</td>\n",
       "      <td>4.642121</td>\n",
       "      <td>4.221670</td>\n",
       "      <td>20.726285</td>\n",
       "      <td>9.903689</td>\n",
       "      <td>5.073290</td>\n",
       "      <td>71.34</td>\n",
       "      <td>19.11</td>\n",
       "      <td>5.77</td>\n",
       "      <td>2.42</td>\n",
       "      <td>0.60</td>\n",
       "      <td>219.18</td>\n",
       "      <td>138.04</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907000345</td>\n",
       "      <td>3.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.918096</td>\n",
       "      <td>9.791231</td>\n",
       "      <td>5.549379</td>\n",
       "      <td>1.983128</td>\n",
       "      <td>4.528002</td>\n",
       "      <td>9.791231</td>\n",
       "      <td>6.309354</td>\n",
       "      <td>1.834174</td>\n",
       "      <td>104.47</td>\n",
       "      <td>25.36</td>\n",
       "      <td>4.45</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.46</td>\n",
       "      <td>173.78</td>\n",
       "      <td>84.56</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907000395</td>\n",
       "      <td>5.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.502892</td>\n",
       "      <td>21.214806</td>\n",
       "      <td>9.168819</td>\n",
       "      <td>5.611232</td>\n",
       "      <td>4.288088</td>\n",
       "      <td>21.214806</td>\n",
       "      <td>11.056456</td>\n",
       "      <td>5.900009</td>\n",
       "      <td>29.99</td>\n",
       "      <td>27.12</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.44</td>\n",
       "      <td>34.27</td>\n",
       "      <td>157.92</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       GameId          PlayId  back_from_scrimmage  back_oriented_down_field  \\\n",
       "0  2017090700  20170907000118                 3.75                         1   \n",
       "1  2017090700  20170907000139                 4.07                         0   \n",
       "2  2017090700  20170907000189                 3.66                         1   \n",
       "3  2017090700  20170907000345                 3.53                         0   \n",
       "4  2017090700  20170907000395                 5.01                         0   \n",
       "\n",
       "   back_moving_down_field  min_dist   max_dist  mean_dist  std_dist  \\\n",
       "0                       0  1.449724  22.415872   8.046559  4.873845   \n",
       "1                       0  0.792023  23.025872   8.614623  5.598683   \n",
       "2                       0  1.646390  20.726285   8.482583  4.642121   \n",
       "3                       0  0.918096   9.791231   5.549379  1.983128   \n",
       "4                       0  0.502892  21.214806   9.168819  5.611232   \n",
       "\n",
       "   def_min_dist  def_max_dist  def_mean_dist  def_std_dist       X      Y  \\\n",
       "0      4.593310     22.415872       9.752491      5.327299   41.25  30.53   \n",
       "1      4.287773     23.025872      10.297028      5.833217   48.93  27.16   \n",
       "2      4.221670     20.726285       9.903689      5.073290   71.34  19.11   \n",
       "3      4.528002      9.791231       6.309354      1.834174  104.47  25.36   \n",
       "4      4.288088     21.214806      11.056456      5.900009   29.99  27.12   \n",
       "\n",
       "      S     A   Dis  Orientation     Dir  YardLine  Quarter  Down  Distance  \\\n",
       "0  3.63  3.35  0.38       198.02  114.26      45.0        1     3         2   \n",
       "1  3.06  2.41  0.34       149.30   47.80      53.0        1     1        10   \n",
       "2  5.77  2.42  0.60       219.18  138.04      75.0        1     1        10   \n",
       "3  4.45  3.20  0.46       173.78   84.56     108.0        1     2         2   \n",
       "4  3.90  2.53  0.44        34.27  157.92      35.0        1     1        10   \n",
       "\n",
       "   DefendersInTheBox  Yards  \n",
       "0                6.0      8  \n",
       "1                6.0      3  \n",
       "2                7.0      5  \n",
       "3                9.0      2  \n",
       "4                7.0      7  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_basetable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's split our data into train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_basetable.copy()\n",
    "yards = X.Yards\n",
    "\n",
    "y = np.zeros((yards.shape[0], 199))\n",
    "for idx, target in enumerate(list(yards)):\n",
    "    y[idx][99 + target] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_two(t_):\n",
    "    #t_['fe1'] = pd.Series(np.sqrt(np.absolute(np.square(t_.X.values) - np.square(t_.Y.values))))\n",
    "    #t_['fe5'] = np.square(t_['S'].values) + 2 * t_['A'].values * t_['Dis'].values  # N\n",
    "    #t_['fe7'] = np.arccos(np.clip(t_['X'].values / t_['Y'].values, -1, 1))  # N\n",
    "    #t_['fe8'] = t_['S'].values / np.clip(t_['fe1'].values, 0.6, None)\n",
    "    radian_angle = (90 - t_['Dir']) * np.pi / 180.0\n",
    "    t_['fe10'] = np.abs(t_['S'] * np.cos(radian_angle))\n",
    "    t_['fe11'] = np.abs(t_['S'] * np.sin(radian_angle))\n",
    "    return t_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = process_two(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['GameId','PlayId','Yards'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's build NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19695, 25) (3476, 25)\n",
      "(19695, 199) (3476, 199)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape)\n",
    "print(y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below class Metric based entirely on: https://www.kaggle.com/kingychiu/keras-nn-starter-crps-early-stopping\n",
    "<br></br>\n",
    "Below early stopping entirely based on: https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/112868#latest-656533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation metric\n",
    "def crps(y_true, y_pred):\n",
    "    y_true = np.clip(np.cumsum(y_true, axis=1), 0, 1)\n",
    "    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "    return ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * y_true.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric(Callback):\n",
    "    def __init__(self, model, callbacks, data):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.callbacks = callbacks\n",
    "        self.data = data\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_train_begin(logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_train_end(logs)\n",
    "\n",
    "    def on_epoch_end(self, batch, logs=None):\n",
    "        X_train, y_train = self.data[0][0], self.data[0][1]\n",
    "        y_pred = self.model.predict(X_train)\n",
    "        y_true = np.clip(np.cumsum(y_train, axis=1), 0, 1)\n",
    "        y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "        tr_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_train.shape[0])\n",
    "        tr_s = np.round(tr_s, 6)\n",
    "        logs['tr_CRPS'] = tr_s\n",
    "\n",
    "        X_valid, y_valid = self.data[1][0], self.data[1][1]\n",
    "\n",
    "        y_pred = self.model.predict(X_valid)\n",
    "        y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n",
    "        y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "        val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_valid.shape[0])\n",
    "        val_s = np.round(val_s, 6)\n",
    "        logs['val_CRPS'] = val_s\n",
    "        print('tr CRPS', tr_s, 'val CRPS', val_s)\n",
    "\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_epoch_end(batch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.4)) #dropout is a type of regularisation. Regularisation helps to control overfitting\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2)) #dropout is a type of regularisation. Regularisation helps to control overfitting\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2)) #dropout is a type of regularisation. Regularisation helps to control overfitting\n",
    "model.add(Dense(199, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 512)               13312     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 199)               51143     \n",
      "=================================================================\n",
      "Total params: 261,575\n",
      "Trainable params: 261,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_CRPS', \n",
    "                   mode='min',\n",
    "                   restore_best_weights=True, \n",
    "                   verbose=1, \n",
    "                   patience=15)\n",
    "es.set_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = Metric(model, [es], [(X_train,y_train), (X_val,y_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "19695/19695 [==============================] - 1s 34us/step - loss: 3.9452\n",
      "tr CRPS 0.014083 val CRPS 0.013691\n",
      "Epoch 2/250\n",
      "19695/19695 [==============================] - 1s 33us/step - loss: 3.0211\n",
      "tr CRPS 0.01415 val CRPS 0.013738\n",
      "Epoch 3/250\n",
      "19695/19695 [==============================] - 0s 23us/step - loss: 2.9184\n",
      "tr CRPS 0.013623 val CRPS 0.01321\n",
      "Epoch 4/250\n",
      "19695/19695 [==============================] - 0s 22us/step - loss: 2.8706\n",
      "tr CRPS 0.013396 val CRPS 0.012954\n",
      "Epoch 5/250\n",
      "19695/19695 [==============================] - 0s 22us/step - loss: 2.8407\n",
      "tr CRPS 0.013296 val CRPS 0.012865\n",
      "Epoch 6/250\n",
      "19695/19695 [==============================] - 0s 22us/step - loss: 2.8133\n",
      "tr CRPS 0.013195 val CRPS 0.012774\n",
      "Epoch 7/250\n",
      "19695/19695 [==============================] - 0s 22us/step - loss: 2.7969\n",
      "tr CRPS 0.013117 val CRPS 0.01271\n",
      "Epoch 8/250\n",
      "19695/19695 [==============================] - 0s 22us/step - loss: 2.7841\n",
      "tr CRPS 0.013073 val CRPS 0.012678\n",
      "Epoch 9/250\n",
      "19695/19695 [==============================] - 1s 26us/step - loss: 2.7795\n",
      "tr CRPS 0.01304 val CRPS 0.01265\n",
      "Epoch 10/250\n",
      "19695/19695 [==============================] - 1s 28us/step - loss: 2.7643\n",
      "tr CRPS 0.013007 val CRPS 0.012631\n",
      "Epoch 11/250\n",
      "19695/19695 [==============================] - 0s 24us/step - loss: 2.7523\n",
      "tr CRPS 0.012962 val CRPS 0.012594\n",
      "Epoch 12/250\n",
      "19695/19695 [==============================] - 0s 25us/step - loss: 2.7442\n",
      "tr CRPS 0.01292 val CRPS 0.012568\n",
      "Epoch 13/250\n",
      "19695/19695 [==============================] - 0s 22us/step - loss: 2.7408\n",
      "tr CRPS 0.012893 val CRPS 0.012568\n",
      "Epoch 14/250\n",
      "19695/19695 [==============================] - 1s 26us/step - loss: 2.7305\n",
      "tr CRPS 0.012872 val CRPS 0.012542\n",
      "Epoch 15/250\n",
      "19695/19695 [==============================] - 0s 22us/step - loss: 2.7250\n",
      "tr CRPS 0.01286 val CRPS 0.012551\n",
      "Epoch 16/250\n",
      "19695/19695 [==============================] - 0s 25us/step - loss: 2.7220\n",
      "tr CRPS 0.012803 val CRPS 0.012513\n",
      "Epoch 17/250\n",
      "19695/19695 [==============================] - 1s 27us/step - loss: 2.7121\n",
      "tr CRPS 0.012784 val CRPS 0.012506\n",
      "Epoch 18/250\n",
      "19695/19695 [==============================] - 0s 23us/step - loss: 2.7131\n",
      "tr CRPS 0.012798 val CRPS 0.01253\n",
      "Epoch 19/250\n",
      "19695/19695 [==============================] - 0s 24us/step - loss: 2.7031\n",
      "tr CRPS 0.012732 val CRPS 0.012489\n",
      "Epoch 20/250\n",
      "19695/19695 [==============================] - 0s 24us/step - loss: 2.6990\n",
      "tr CRPS 0.012738 val CRPS 0.01251\n",
      "Epoch 21/250\n",
      "19695/19695 [==============================] - 0s 23us/step - loss: 2.6928\n",
      "tr CRPS 0.012682 val CRPS 0.012446\n",
      "Epoch 22/250\n",
      "19695/19695 [==============================] - 0s 21us/step - loss: 2.6920\n",
      "tr CRPS 0.012708 val CRPS 0.012498\n",
      "Epoch 23/250\n",
      "19695/19695 [==============================] - 0s 22us/step - loss: 2.6872\n",
      "tr CRPS 0.012644 val CRPS 0.01245\n",
      "Epoch 24/250\n",
      "19695/19695 [==============================] - 0s 22us/step - loss: 2.6788\n",
      "tr CRPS 0.012652 val CRPS 0.012468\n",
      "Epoch 25/250\n",
      "19695/19695 [==============================] - 0s 24us/step - loss: 2.6716\n",
      "tr CRPS 0.012632 val CRPS 0.012464\n",
      "Epoch 26/250\n",
      "19695/19695 [==============================] - 0s 24us/step - loss: 2.6717\n",
      "tr CRPS 0.012589 val CRPS 0.012458\n",
      "Epoch 27/250\n",
      "19695/19695 [==============================] - 0s 23us/step - loss: 2.6675\n",
      "tr CRPS 0.01257 val CRPS 0.012422\n",
      "Epoch 28/250\n",
      "19695/19695 [==============================] - 1s 26us/step - loss: 2.6627\n",
      "tr CRPS 0.01256 val CRPS 0.012448\n",
      "Epoch 29/250\n",
      "19695/19695 [==============================] - 0s 21us/step - loss: 2.6573\n",
      "tr CRPS 0.012522 val CRPS 0.012417\n",
      "Epoch 30/250\n",
      "19695/19695 [==============================] - 0s 23us/step - loss: 2.6534\n",
      "tr CRPS 0.012498 val CRPS 0.012383\n",
      "Epoch 31/250\n",
      "19695/19695 [==============================] - 0s 22us/step - loss: 2.6471\n",
      "tr CRPS 0.012504 val CRPS 0.012414\n",
      "Epoch 32/250\n",
      "19695/19695 [==============================] - 0s 22us/step - loss: 2.6398\n",
      "tr CRPS 0.012479 val CRPS 0.012428\n",
      "Epoch 33/250\n",
      "19695/19695 [==============================] - 0s 23us/step - loss: 2.6404\n",
      "tr CRPS 0.012438 val CRPS 0.012392\n",
      "Epoch 34/250\n",
      "19695/19695 [==============================] - 0s 21us/step - loss: 2.6329\n",
      "tr CRPS 0.012406 val CRPS 0.012351\n",
      "Epoch 35/250\n",
      "19695/19695 [==============================] - 0s 22us/step - loss: 2.6333\n",
      "tr CRPS 0.012421 val CRPS 0.012403\n",
      "Epoch 36/250\n",
      "19695/19695 [==============================] - 0s 24us/step - loss: 2.6261\n",
      "tr CRPS 0.012413 val CRPS 0.012429\n",
      "Epoch 37/250\n",
      "19695/19695 [==============================] - 0s 21us/step - loss: 2.6255\n",
      "tr CRPS 0.012363 val CRPS 0.012387\n",
      "Epoch 38/250\n",
      "19695/19695 [==============================] - 0s 23us/step - loss: 2.6127\n",
      "tr CRPS 0.01232 val CRPS 0.012319\n",
      "Epoch 39/250\n",
      "19695/19695 [==============================] - 0s 22us/step - loss: 2.6124\n",
      "tr CRPS 0.012318 val CRPS 0.012384\n",
      "Epoch 40/250\n",
      "19695/19695 [==============================] - 0s 22us/step - loss: 2.6078\n",
      "tr CRPS 0.012302 val CRPS 0.012381\n",
      "Epoch 41/250\n",
      "19695/19695 [==============================] - 0s 22us/step - loss: 2.6022\n",
      "tr CRPS 0.012285 val CRPS 0.012395\n",
      "Epoch 42/250\n",
      "19695/19695 [==============================] - 0s 23us/step - loss: 2.6004\n",
      "tr CRPS 0.012274 val CRPS 0.012393\n",
      "Epoch 43/250\n",
      "19695/19695 [==============================] - 0s 25us/step - loss: 2.5990\n",
      "tr CRPS 0.012242 val CRPS 0.012393\n",
      "Epoch 44/250\n",
      "19695/19695 [==============================] - 1s 26us/step - loss: 2.5889\n",
      "tr CRPS 0.012206 val CRPS 0.012347\n",
      "Epoch 45/250\n",
      "19695/19695 [==============================] - 0s 21us/step - loss: 2.5872\n",
      "tr CRPS 0.012172 val CRPS 0.012355\n",
      "Epoch 46/250\n",
      "19695/19695 [==============================] - 0s 23us/step - loss: 2.5832\n",
      "tr CRPS 0.012181 val CRPS 0.01239\n",
      "Epoch 47/250\n",
      "19695/19695 [==============================] - 0s 23us/step - loss: 2.5763\n",
      "tr CRPS 0.012142 val CRPS 0.012381\n",
      "Epoch 48/250\n",
      "19695/19695 [==============================] - 0s 22us/step - loss: 2.5760\n",
      "tr CRPS 0.012113 val CRPS 0.01238\n",
      "Epoch 49/250\n",
      "19695/19695 [==============================] - 1s 28us/step - loss: 2.5688\n",
      "tr CRPS 0.012106 val CRPS 0.012369\n",
      "Epoch 50/250\n",
      "19695/19695 [==============================] - 1s 41us/step - loss: 2.5637\n",
      "tr CRPS 0.012067 val CRPS 0.012367\n",
      "Epoch 51/250\n",
      "19695/19695 [==============================] - 0s 24us/step - loss: 2.5609\n",
      "tr CRPS 0.012077 val CRPS 0.012442\n",
      "Epoch 52/250\n",
      "19695/19695 [==============================] - 0s 23us/step - loss: 2.5582\n",
      "tr CRPS 0.012091 val CRPS 0.012433\n",
      "Epoch 53/250\n",
      "19695/19695 [==============================] - 0s 23us/step - loss: 2.5562\n",
      "tr CRPS 0.012011 val CRPS 0.01236\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00053: early stopping\n",
      "CPU times: user 2min 44s, sys: 1min 1s, total: 3min 45s\n",
      "Wall time: 1min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a48927cf8>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train, callbacks=[metric], epochs=250, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012319495295185088\n"
     ]
    }
   ],
   "source": [
    "score_ = crps(y_val, model.predict(X_val))\n",
    "print(score_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.012390261971806146 somente DefensePersonnel\n",
    "0.012358864468665062 somente OffensePersonnel\n",
    "0.01235284042335581 sem novas features fe\n",
    "0.012322177504069477 so com radian_angle e OffensePersonnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GP:\n",
    "    def __init__(self):\n",
    "        self.classes = 20\n",
    "        self.class_names = [ 'class_0',\n",
    "                             'class_1',\n",
    "                             'class_2',\n",
    "                             'class_3',\n",
    "                             'class_4',\n",
    "                             'class_5',\n",
    "                             'class_6',\n",
    "                             'class_7',\n",
    "                             'class_8',\n",
    "                             'class_9',\n",
    "                             'class_10',\n",
    "                             'class_11',\n",
    "                             'class_12',\n",
    "                             'class_13',\n",
    "                            'class_14',\n",
    "                            'class_15',\n",
    "                            'class_16',\n",
    "                            'class_17',\n",
    "                            'class_18',\n",
    "                            'class_19',\n",
    "                           ]\n",
    "\n",
    "\n",
    "    def GrabPredictions(self, data):\n",
    "        oof_preds = np.zeros((len(data), len(self.class_names)))\n",
    "        oof_preds[:,0] = self.GP_class_0(data)\n",
    "        oof_preds[:,1] = self.GP_class_1(data)\n",
    "        oof_preds[:,2] = self.GP_class_2(data)\n",
    "        oof_preds[:,3] = self.GP_class_3(data)\n",
    "        oof_preds[:,4] = self.GP_class_4(data)\n",
    "        oof_preds[:,5] = self.GP_class_5(data)\n",
    "        oof_preds[:,6] = self.GP_class_6(data)\n",
    "        oof_preds[:,7] = self.GP_class_7(data)\n",
    "        oof_preds[:,8] = self.GP_class_8(data)\n",
    "        oof_preds[:,9] = self.GP_class_9(data)\n",
    "        oof_preds[:,10] = self.GP_class_10(data)\n",
    "        oof_preds[:,11] = self.GP_class_11(data)\n",
    "        oof_preds[:,12] = self.GP_class_12(data)\n",
    "        oof_preds[:,13] = self.GP_class_13(data)\n",
    "        oof_preds[:,14] = self.GP_class_14(data)\n",
    "        oof_preds[:,15] = self.GP_class_15(data)\n",
    "        oof_preds[:,16] = self.GP_class_16(data)\n",
    "        oof_preds[:,17] = self.GP_class_17(data)\n",
    "        oof_preds[:,18] = self.GP_class_18(data)\n",
    "        oof_preds[:,19] = self.GP_class_19(data)\n",
    "        oof_df = pd.DataFrame(np.exp(oof_preds), columns=self.class_names)\n",
    "        oof_df =oof_df.div(oof_df.sum(axis=1), axis=0)\n",
    "        \n",
    "        return oof_df.values\n",
    "\n",
    "\n",
    "    def GP_class_0(self,data):\n",
    "        return(0.250000*np.tanh(((((((data[:,0]) - (((data[:,0]) + (data[:,0]))))) + (data[:,0]))) + (((((data[:,0]) * 2.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh(((((((((((((data[:,2]) - (data[:,7]))) * 2.0)) + (data[:,7]))) * 2.0)) + (data[:,0]))) + (((((data[:,2]) + (data[:,0]))) - (data[:,7]))))) +\n",
    "                0.250000*np.tanh(((((((((((((((((((data[:,3]) - (data[:,7]))) - (((data[:,0]) / 2.0)))) + (data[:,0]))) - (data[:,7]))) + (data[:,2]))) + (((data[:,7]) + (data[:,2]))))) + (data[:,7]))) - (data[:,7]))) + (data[:,0]))) +\n",
    "                0.250000*np.tanh(((((((((data[:,0]) - (data[:,7]))) - (data[:,14]))) + (((data[:,17]) - (data[:,14]))))) + (((((((data[:,0]) - ((1.0)))) - (data[:,0]))) + (data[:,20]))))) +\n",
    "                0.250000*np.tanh(((((data[:,18]) + (((((((data[:,0]) - (data[:,7]))) + (data[:,2]))) + (data[:,0]))))) - (((data[:,7]) + (data[:,2]))))) +\n",
    "                0.250000*np.tanh((((((((data[:,8]) + ((((((((data[:,13]) + (data[:,3]))) + (data[:,0]))/2.0)) + ((((((((data[:,0]) + (((((data[:,0]) - (data[:,0]))) / 2.0)))) + (data[:,17]))/2.0)) + (data[:,11]))))))/2.0)) + (data[:,0]))) - (data[:,13]))) +\n",
    "                0.250000*np.tanh(((((data[:,0]) * 2.0)) + (((((((((data[:,2]) + (data[:,2]))) * 2.0)) - (((data[:,14]) - (((np.tanh((data[:,2]))) * 2.0)))))) - (data[:,7]))))) +\n",
    "                0.250000*np.tanh(((((((((((((data[:,17]) - (((data[:,17]) * (((((data[:,17]) * (data[:,17]))) * 2.0)))))) + (((((((data[:,17]) * 2.0)) * 2.0)) * 2.0)))/2.0)) / 2.0)) + (((data[:,17]) - ((7.76236486434936523)))))/2.0)) + (((((((data[:,17]) * (data[:,17]))) * 2.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh(((((((((((data[:,17]) + (data[:,17]))/2.0)) + ((((data[:,17]) + ((((data[:,17]) + (data[:,17]))/2.0)))/2.0)))/2.0)) * (data[:,17]))) - (data[:,13]))) +\n",
    "                0.250000*np.tanh((((((data[:,19]) + (((((((((data[:,19]) * 2.0)) + (data[:,19]))) - ((1.07645297050476074)))) + (((data[:,22]) + (data[:,22]))))))/2.0)) + (((data[:,22]) + (data[:,4]))))))\n",
    "    \n",
    "    def GP_class_1(self,data):\n",
    "        return(0.250000*np.tanh(((((((((((((data[:,3]) + (((np.tanh((data[:,2]))) - (data[:,14]))))) - ((10.0)))) - ((4.88989353179931641)))) - ((13.92175483703613281)))) / 2.0)) - (data[:,6]))) +\n",
    "                0.250000*np.tanh(data[:,3]) +\n",
    "                0.250000*np.tanh(((data[:,2]) + (((((np.tanh((((data[:,14]) * 2.0)))) - (((((((data[:,7]) * 2.0)) - (((((data[:,0]) - (data[:,14]))) - (data[:,7]))))) - (data[:,0]))))) + (data[:,0]))))) +\n",
    "                0.250000*np.tanh(((((((data[:,0]) - ((-1.0*((data[:,14])))))) + ((((((((((data[:,0]) - (data[:,7]))) - ((((data[:,14]) + (data[:,14]))/2.0)))) + (((data[:,2]) - (((data[:,0]) * (data[:,14]))))))/2.0)) - (data[:,14]))))) - (data[:,7]))) +\n",
    "                0.250000*np.tanh(((((data[:,0]) / 2.0)) + (data[:,0]))) +\n",
    "                0.250000*np.tanh(((((data[:,19]) - (data[:,19]))) / 2.0)) +\n",
    "                0.250000*np.tanh(((((np.tanh((((np.tanh((data[:,5]))) - ((((1.69341480731964111)) + ((((((np.tanh((data[:,14]))) - (data[:,14]))) + (data[:,14]))/2.0)))))))) - (data[:,2]))) - (((data[:,14]) * 2.0)))) +\n",
    "                0.250000*np.tanh((((((data[:,22]) + (((data[:,0]) + ((((((((data[:,22]) / 2.0)) + ((-1.0*((data[:,13])))))/2.0)) + (data[:,19]))))))/2.0)) - (data[:,13]))) +\n",
    "                0.250000*np.tanh(((((((data[:,17]) / 2.0)) * (data[:,17]))) * (((data[:,17]) + (((data[:,17]) * (((((((((data[:,17]) + (data[:,17]))) * (data[:,17]))) * (data[:,17]))) + (((np.tanh((data[:,17]))) / 2.0)))))))))) +\n",
    "                0.250000*np.tanh((((((data[:,14]) * (((data[:,13]) + (data[:,3]))))) + (((data[:,14]) * (((data[:,14]) - ((-1.0*((data[:,3])))))))))/2.0)))\n",
    "    \n",
    "    def GP_class_2(self,data):\n",
    "        return(0.250000*np.tanh(((data[:,0]) + (np.tanh((((((((((data[:,2]) + (((data[:,2]) / 2.0)))/2.0)) + (data[:,0]))/2.0)) * (data[:,7]))))))) +\n",
    "                0.250000*np.tanh((((data[:,22]) + (data[:,22]))/2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,14]) + ((-1.0*((((((4.73206138610839844)) + (((((((((((np.tanh((data[:,7]))) + (data[:,1]))/2.0)) - (np.tanh((((((data[:,0]) - (data[:,20]))) - (data[:,14]))))))) * ((7.0)))) + (data[:,14]))/2.0)))/2.0))))))/2.0)) - (data[:,14]))) +\n",
    "                0.250000*np.tanh(((((data[:,1]) + ((4.15603733062744141)))) / 2.0)) +\n",
    "                0.250000*np.tanh(((((((((((((data[:,0]) - (data[:,7]))) - (data[:,7]))) + ((((data[:,0]) + (data[:,0]))/2.0)))) * 2.0)) + (data[:,0]))) * 2.0)) +\n",
    "                0.250000*np.tanh(((((data[:,11]) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(((((((((((((((((((((((data[:,2]) / 2.0)) + (((data[:,2]) / 2.0)))/2.0)) / 2.0)) / 2.0)) / 2.0)) + ((((-1.0*((((data[:,0]) / 2.0))))) * (((data[:,0]) / 2.0)))))/2.0)) + (data[:,0]))/2.0)) + (np.tanh((data[:,0]))))/2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(((((data[:,0]) + (((data[:,0]) + (((((((data[:,14]) * (data[:,14]))) + (data[:,14]))) - (data[:,0]))))))) - (data[:,14]))) +\n",
    "                0.250000*np.tanh((((((np.tanh((np.tanh(((0.0)))))) * (data[:,15]))) + (data[:,20]))/2.0)) +\n",
    "                0.250000*np.tanh(((data[:,14]) * ((((data[:,13]) + ((((data[:,13]) + ((((data[:,14]) + ((((((data[:,14]) + ((((data[:,14]) + (((data[:,13]) - ((((-1.0*(((((data[:,14]) + (data[:,14]))/2.0))))) * 2.0)))))/2.0)))) + (data[:,14]))/2.0)))/2.0)))/2.0)))/2.0)))))\n",
    "    \n",
    "    def GP_class_3(self,data):\n",
    "        return(0.250000*np.tanh(((((((((8.0)) + (((((((5.33416414260864258)) + ((9.0)))/2.0)) + ((((8.0)) * 2.0)))))) * 2.0)) + ((5.33416414260864258)))/2.0)) +\n",
    "                0.250000*np.tanh((((9.48088836669921875)) + (((((10.56953334808349609)) + ((((4.48959350585937500)) + (np.tanh(((((3.0)) + ((9.0)))))))))/2.0)))) +\n",
    "                0.250000*np.tanh((((((((((data[:,22]) / 2.0)) + (data[:,22]))/2.0)) * 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((10.44883441925048828)) +\n",
    "                0.250000*np.tanh(((((data[:,0]) + (((data[:,0]) + ((-1.0*((data[:,9])))))))) + (((((data[:,0]) - (data[:,7]))) - (data[:,9]))))) +\n",
    "                0.250000*np.tanh(((np.tanh((data[:,6]))) - (data[:,21]))) +\n",
    "                0.250000*np.tanh(((data[:,0]) - (((((data[:,14]) + (((((data[:,14]) + (((data[:,14]) + (((data[:,14]) - (data[:,0]))))))) - (((((data[:,0]) - (data[:,14]))) + (data[:,14]))))))) - (((((data[:,14]) * (data[:,14]))) + (data[:,18]))))))) +\n",
    "                0.250000*np.tanh(((data[:,14]) * ((((data[:,13]) + (data[:,14]))/2.0)))) +\n",
    "                0.250000*np.tanh((((((data[:,8]) * (((data[:,8]) / 2.0)))) + ((((((data[:,9]) * (data[:,8]))) + (data[:,8]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh((((data[:,2]) + (((((((data[:,2]) + (data[:,20]))/2.0)) + ((((((((data[:,2]) + (data[:,8]))/2.0)) / 2.0)) - (data[:,8]))))/2.0)))/2.0)))\n",
    "    \n",
    "    def GP_class_4(self,data):\n",
    "        return(0.250000*np.tanh((((12.98819637298583984)) / 2.0)) +\n",
    "                0.250000*np.tanh(((((4.75780344009399414)) + (((((((8.66014671325683594)) + ((4.18107128143310547)))/2.0)) * ((8.97841739654541016)))))/2.0)) +\n",
    "                0.250000*np.tanh((((9.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(((((((((((10.0)) + (np.tanh((((((6.0)) + ((((13.80149555206298828)) + ((7.0)))))/2.0)))))) + ((10.0)))) + (((((((data[:,0]) + ((8.0)))) / 2.0)) / 2.0)))/2.0)) + ((((-1.0*((((data[:,2]) * (data[:,9])))))) * 2.0)))) +\n",
    "                0.250000*np.tanh(((((data[:,0]) + (((((((data[:,22]) + (data[:,22]))/2.0)) + (data[:,22]))/2.0)))) + ((((((data[:,22]) + ((((((data[:,22]) * 2.0)) + (data[:,22]))/2.0)))) + (data[:,18]))/2.0)))) +\n",
    "                0.250000*np.tanh(((((((((((((np.tanh((data[:,18]))) + ((((data[:,1]) + (data[:,18]))/2.0)))/2.0)) * (data[:,18]))) * (data[:,18]))) + (((data[:,18]) * (data[:,18]))))/2.0)) - (((((((np.tanh((data[:,18]))) + (((data[:,18]) * (data[:,18]))))/2.0)) + (data[:,17]))/2.0)))) +\n",
    "                0.250000*np.tanh(((np.tanh(((((((np.tanh((data[:,6]))) - (((np.tanh((data[:,6]))) - (data[:,6]))))) + (np.tanh((data[:,6]))))/2.0)))) - ((((data[:,10]) + ((((data[:,2]) + (((np.tanh((data[:,6]))) - (((np.tanh((np.tanh((data[:,6]))))) - (data[:,10]))))))/2.0)))/2.0)))) +\n",
    "                0.250000*np.tanh((((((((((((data[:,10]) + (data[:,4]))) + (((data[:,10]) + (((data[:,0]) * (data[:,10]))))))/2.0)) + (((data[:,4]) * (((data[:,10]) + (data[:,4]))))))/2.0)) + (data[:,7]))/2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,11]) + (((((data[:,18]) / 2.0)) * (((data[:,11]) * (data[:,18]))))))/2.0)) * (((data[:,18]) * (((((((((data[:,18]) * (((((((data[:,11]) / 2.0)) / 2.0)) * (data[:,18]))))) / 2.0)) / 2.0)) * ((-1.0*((data[:,21])))))))))) +\n",
    "                0.250000*np.tanh((((-1.0*((((((((((((data[:,2]) - (data[:,2]))) * (np.tanh((data[:,2]))))) + (np.tanh((((data[:,14]) * 2.0)))))/2.0)) + (data[:,2]))/2.0))))) - (data[:,2]))))\n",
    "    \n",
    "    def GP_class_5(self,data):\n",
    "        return(0.250000*np.tanh(((((((((((3.46574378013610840)) + ((((np.tanh(((3.46574378013610840)))) + ((8.46705245971679688)))/2.0)))/2.0)) * 2.0)) + ((((3.46574378013610840)) + ((4.0)))))) + ((((4.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((10.55856513977050781)) / 2.0)) +\n",
    "                0.250000*np.tanh((((3.76695251464843750)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((6.0)) / 2.0)) + ((((8.57984828948974609)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((((((((((3.42168045043945312)) + (data[:,7]))) + (np.tanh((data[:,7]))))) + (np.tanh((np.tanh((np.tanh(((3.42168045043945312)))))))))/2.0)) + (data[:,7]))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((((data[:,6]) - (data[:,9]))) + (data[:,7]))/2.0)) * 2.0)) + ((((((data[:,7]) + (data[:,9]))/2.0)) - (data[:,9]))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((((data[:,22]) + (data[:,22]))) + (data[:,11]))/2.0)) + (data[:,22]))/2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((((0.76044219732284546)) / 2.0)) + ((0.76044219732284546)))/2.0)) + (np.tanh((np.tanh((((((((0.76043862104415894)) / 2.0)) + ((1.0)))/2.0)))))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((data[:,12]) + (np.tanh((data[:,9]))))/2.0)) + (((((((((((data[:,12]) + (((((0.0)) + (np.tanh((((((((data[:,7]) + (data[:,6]))/2.0)) + (data[:,7]))/2.0)))))/2.0)))/2.0)) / 2.0)) / 2.0)) + (data[:,7]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((data[:,20]) / 2.0)) / 2.0)) * (((np.tanh((data[:,20]))) * (((data[:,20]) / 2.0)))))) * ((((((data[:,20]) / 2.0)) + (((data[:,20]) / 2.0)))/2.0)))))\n",
    "    \n",
    "    def GP_class_6(self,data):\n",
    "        return(0.250000*np.tanh(((((((11.68076229095458984)) + (((((11.68075847625732422)) + ((((11.47270107269287109)) + (((((11.47269725799560547)) + ((11.68076229095458984)))/2.0)))))/2.0)))/2.0)) + ((((4.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((8.0)) + ((((10.0)) + ((6.59042119979858398)))))) +\n",
    "                0.250000*np.tanh(((((((((((13.33760547637939453)) + (((((3.86388397216796875)) + (((((((8.18321037292480469)) + (data[:,4]))) + (((((((5.95386552810668945)) + ((12.93883609771728516)))) + (((((10.73907089233398438)) + ((4.0)))/2.0)))/2.0)))/2.0)))/2.0)))/2.0)) + (np.tanh(((3.0)))))) - ((2.0)))) + (((((10.61559963226318359)) + (data[:,1]))/2.0)))) +\n",
    "                0.250000*np.tanh(((np.tanh(((((((((((7.13513946533203125)) + ((12.48778533935546875)))/2.0)) + (((((((7.13513565063476562)) - ((8.12031841278076172)))) + (((((((((7.13513565063476562)) + ((((10.69830417633056641)) + ((10.69830799102783203)))))) + ((10.69830799102783203)))) + ((7.83078956604003906)))/2.0)))/2.0)))/2.0)) * 2.0)))) + ((3.0)))) +\n",
    "                0.250000*np.tanh(((((((((((data[:,7]) - (data[:,0]))) * 2.0)) - (data[:,7]))) + (data[:,7]))) + (data[:,0]))) +\n",
    "                0.250000*np.tanh(((((data[:,7]) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((((((((((1.0)) + (((((((data[:,2]) + (((((((1.0)) * (data[:,2]))) + (data[:,14]))/2.0)))/2.0)) + ((1.0)))/2.0)))) + ((((1.0)) - (((data[:,2]) * (data[:,14]))))))/2.0)) - (data[:,2]))) * 2.0)) + (data[:,14]))/2.0)) + (data[:,14]))) +\n",
    "                0.250000*np.tanh(((np.tanh((np.tanh(((((((data[:,19]) * ((0.0)))) + ((0.0)))/2.0)))))) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((0.0)) / 2.0)) / 2.0)) * (((((((((data[:,15]) / 2.0)) * ((0.0)))) / 2.0)) * ((((-1.0*(((0.0))))) / 2.0)))))) +\n",
    "                0.250000*np.tanh(((((data[:,15]) * (((((((((((((np.tanh(((((0.09032609313726425)) / 2.0)))) / 2.0)) / 2.0)) / 2.0)) / 2.0)) / 2.0)) / 2.0)))) / 2.0)))\n",
    "    \n",
    "    def GP_class_7(self,data):\n",
    "        return(0.250000*np.tanh((10.27210903167724609)) +\n",
    "                0.250000*np.tanh((((((((((10.0)) + (((((((((8.26972770690917969)) + ((11.06334972381591797)))/2.0)) * 2.0)) / 2.0)))) + ((((((5.0)) + ((((5.0)) + ((7.92727756500244141)))))) * 2.0)))) * ((7.92728137969970703)))) + ((10.0)))) +\n",
    "                0.250000*np.tanh((8.42519950866699219)) +\n",
    "                0.250000*np.tanh(((((((data[:,14]) + (data[:,14]))) + ((((((1.59392631053924561)) + (data[:,14]))) + (data[:,14]))))) + (np.tanh((((((data[:,14]) + (((((((3.0)) + (((data[:,14]) * 2.0)))/2.0)) + ((1.59391915798187256)))))) + ((1.59392631053924561)))))))) +\n",
    "                0.250000*np.tanh((((data[:,7]) + (((data[:,0]) + (((((((data[:,7]) + (data[:,4]))/2.0)) + (((data[:,7]) * 2.0)))/2.0)))))/2.0)) +\n",
    "                0.250000*np.tanh((((((((((((((data[:,9]) - (((data[:,0]) - (data[:,0]))))) - (((data[:,0]) / 2.0)))) / 2.0)) - (((data[:,21]) - (data[:,7]))))) + (data[:,21]))/2.0)) - (data[:,0]))) +\n",
    "                0.250000*np.tanh((((((((((2.0)) + ((((((data[:,21]) + ((((data[:,13]) + (((((((((((data[:,13]) * 2.0)) + (data[:,21]))/2.0)) + (data[:,13]))/2.0)) * 2.0)))/2.0)))/2.0)) - (np.tanh(((((0.0)) - (data[:,21]))))))))) + ((1.0)))/2.0)) + (data[:,13]))/2.0)) +\n",
    "                0.250000*np.tanh(((((data[:,14]) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((((((((((-1.0*(((((((data[:,21]) / 2.0)) + (data[:,8]))/2.0))))) / 2.0)) / 2.0)) / 2.0)) + (data[:,9]))/2.0)) / 2.0)) + ((((((((((((data[:,7]) / 2.0)) / 2.0)) / 2.0)) / 2.0)) + (data[:,7]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((((np.tanh(((1.0)))) / 2.0)) / 2.0)) / 2.0)))\n",
    "    \n",
    "    def GP_class_8(self,data):\n",
    "        return(0.250000*np.tanh(((((((data[:,0]) + (((((6.71804094314575195)) + (data[:,15]))/2.0)))) + ((((((11.56385326385498047)) * 2.0)) * ((((10.48986148834228516)) + ((11.56385326385498047)))))))) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((((data[:,14]) / 2.0)) + ((2.83755254745483398)))/2.0)) + ((((((data[:,12]) + (data[:,14]))/2.0)) + (data[:,14]))))) + ((((data[:,9]) + (((data[:,12]) + (data[:,14]))))/2.0)))) +\n",
    "                0.250000*np.tanh(((((((((data[:,6]) + (((((((3.50821948051452637)) + ((((data[:,21]) + ((11.92932796478271484)))/2.0)))) + ((1.0)))/2.0)))) + (data[:,10]))/2.0)) + (data[:,21]))/2.0)) +\n",
    "                0.250000*np.tanh(((data[:,14]) + (np.tanh((np.tanh(((-1.0*((((data[:,22]) - (data[:,13])))))))))))) +\n",
    "                0.250000*np.tanh(((((1.0)) + ((((data[:,7]) + (data[:,7]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((data[:,21]) / 2.0)) / 2.0)) * (((((((np.tanh((((np.tanh((data[:,13]))) / 2.0)))) / 2.0)) + (((((((np.tanh(((((data[:,21]) + (data[:,21]))/2.0)))) / 2.0)) - (data[:,12]))) / 2.0)))) / 2.0)))) - (data[:,12]))) +\n",
    "                0.250000*np.tanh((((data[:,7]) + (np.tanh(((((data[:,12]) + (((data[:,7]) * ((((data[:,13]) + (data[:,13]))/2.0)))))/2.0)))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((data[:,13]) / 2.0)) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((((np.tanh((data[:,9]))) + (data[:,13]))/2.0)) + ((((((((data[:,21]) / 2.0)) * 2.0)) + ((((3.94983267784118652)) / 2.0)))/2.0)))/2.0)) + ((((np.tanh(((3.94983267784118652)))) + (data[:,9]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((((((((data[:,14]) * (((((((((data[:,19]) / 2.0)) * (np.tanh((((data[:,2]) / 2.0)))))) / 2.0)) / 2.0)))) / 2.0)) / 2.0)) / 2.0)) / 2.0)) / 2.0)) * (((((data[:,11]) / 2.0)) / 2.0)))))\n",
    "    \n",
    "    def GP_class_9(self,data):\n",
    "        return(0.250000*np.tanh(((((((data[:,14]) * 2.0)) / 2.0)) + (((((data[:,14]) + (np.tanh((((data[:,14]) * 2.0)))))) + (data[:,14]))))) +\n",
    "                0.250000*np.tanh(((data[:,9]) - (((((-1.0*((data[:,11])))) + (data[:,9]))/2.0)))) +\n",
    "                0.250000*np.tanh(((data[:,21]) * 2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,14]) + (data[:,14]))/2.0)) + ((((data[:,13]) + ((((np.tanh((((data[:,9]) + ((6.0)))))) + (data[:,9]))/2.0)))/2.0)))) +\n",
    "                0.250000*np.tanh(np.tanh(((1.0)))) +\n",
    "                0.250000*np.tanh(((np.tanh((np.tanh(((((np.tanh((((data[:,20]) * (((((((np.tanh((((data[:,20]) / 2.0)))) + (data[:,12]))/2.0)) + ((((data[:,15]) + ((((data[:,17]) + (data[:,9]))/2.0)))/2.0)))/2.0)))))) + (data[:,9]))/2.0)))))) / 2.0)) +\n",
    "                0.250000*np.tanh(((((data[:,2]) - (data[:,11]))) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((data[:,13]) / 2.0)) + (((data[:,7]) + (data[:,7]))))/2.0)) - (((((data[:,22]) + (((((data[:,14]) * (((((data[:,7]) * (((data[:,13]) - ((((data[:,7]) + (((((data[:,13]) / 2.0)) + (data[:,7]))))/2.0)))))) / 2.0)))) * 2.0)))) / 2.0)))) +\n",
    "                0.250000*np.tanh(((((((((((((((data[:,1]) / 2.0)) + ((1.0)))/2.0)) + ((1.0)))/2.0)) + ((((((((((1.0)) / 2.0)) + (np.tanh(((1.0)))))/2.0)) + (np.tanh((((((1.0)) + ((1.0)))/2.0)))))/2.0)))/2.0)) + ((((data[:,20]) + ((1.0)))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((data[:,1]) * ((((data[:,14]) + (np.tanh(((((0.0)) / 2.0)))))/2.0)))))\n",
    "    \n",
    "    def GP_class_10(self,data):\n",
    "        return(0.250000*np.tanh((((((((((data[:,2]) + (((data[:,9]) * (np.tanh((data[:,14]))))))/2.0)) + ((((((data[:,14]) + (data[:,20]))/2.0)) + (data[:,0]))))/2.0)) + (data[:,14]))/2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,9]) + ((-1.0*((((((((2.04309988021850586)) + (((data[:,11]) + (((np.tanh((data[:,0]))) / 2.0)))))/2.0)) * 2.0))))))/2.0)) + (data[:,2]))) +\n",
    "                0.250000*np.tanh(data[:,21]) +\n",
    "                0.250000*np.tanh((((((((data[:,14]) + (np.tanh((((data[:,6]) / 2.0)))))/2.0)) + (data[:,14]))) + (((((data[:,14]) * 2.0)) + ((((data[:,13]) + (data[:,14]))/2.0)))))) +\n",
    "                0.250000*np.tanh(data[:,9]) +\n",
    "                0.250000*np.tanh(((((((data[:,15]) * 2.0)) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((((((2.72836518287658691)) * ((((1.0)) / 2.0)))) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(((((np.tanh((((data[:,7]) + (np.tanh(((((((((((0.0)) / 2.0)) / 2.0)) / 2.0)) / 2.0)))))))) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(np.tanh((((np.tanh(((11.43236827850341797)))) / 2.0)))) +\n",
    "                0.250000*np.tanh(np.tanh((((data[:,7]) / 2.0)))))\n",
    "    \n",
    "    def GP_class_11(self,data):\n",
    "        return(0.250000*np.tanh((-1.0*((((((((((((((data[:,5]) - (((data[:,9]) - ((((-1.0*(((11.40053558349609375))))) / 2.0)))))) + ((((11.40053558349609375)) + ((((11.40053558349609375)) * 2.0)))))) / 2.0)) - (data[:,7]))) - ((-1.0*(((11.40053939819335938))))))) * 2.0))))) +\n",
    "                0.250000*np.tanh(((((data[:,14]) * 2.0)) + (data[:,14]))) +\n",
    "                0.250000*np.tanh(((data[:,2]) + (((((data[:,5]) + (data[:,3]))) + ((((data[:,2]) + (((data[:,3]) * 2.0)))/2.0)))))) +\n",
    "                0.250000*np.tanh(((((((((((data[:,21]) + (data[:,21]))) + ((-1.0*(((((np.tanh((np.tanh((((data[:,14]) / 2.0)))))) + (data[:,21]))/2.0))))))/2.0)) * 2.0)) + ((((data[:,14]) + (data[:,3]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((((data[:,0]) + ((((data[:,9]) + ((((data[:,9]) + (((((((((((((((data[:,9]) / 2.0)) - (data[:,10]))) + (data[:,5]))/2.0)) - (data[:,9]))) + (data[:,9]))/2.0)) / 2.0)))/2.0)))/2.0)))/2.0)) + (data[:,9]))/2.0)) +\n",
    "                0.250000*np.tanh((((((((data[:,13]) + ((((data[:,13]) + (data[:,13]))/2.0)))) + (data[:,1]))/2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh(data[:,14]) +\n",
    "                0.250000*np.tanh(((((data[:,2]) / 2.0)) / 2.0)) +\n",
    "                0.250000*np.tanh((((data[:,9]) + (data[:,9]))/2.0)) +\n",
    "                0.250000*np.tanh(data[:,2]))\n",
    "    \n",
    "    def GP_class_12(self,data):\n",
    "        return(0.250000*np.tanh((((((((-1.0*((data[:,18])))) - (np.tanh((data[:,9]))))) + ((8.0)))) - ((14.74865913391113281)))) +\n",
    "                0.250000*np.tanh((((((data[:,21]) + (np.tanh((data[:,9]))))) + ((((((((data[:,5]) / 2.0)) * 2.0)) + (data[:,5]))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((data[:,14]) + (data[:,14]))) + (((data[:,14]) * 2.0)))) +\n",
    "                0.250000*np.tanh(((data[:,2]) + (((((((data[:,14]) + ((((np.tanh((data[:,10]))) + (data[:,17]))/2.0)))/2.0)) + (data[:,21]))/2.0)))) +\n",
    "                0.250000*np.tanh((((data[:,9]) + ((((((((((((data[:,9]) + ((((((data[:,9]) / 2.0)) + (((data[:,9]) * 2.0)))/2.0)))/2.0)) + ((-1.0*((data[:,21])))))/2.0)) * (data[:,9]))) + (((((np.tanh((((data[:,21]) / 2.0)))) / 2.0)) / 2.0)))/2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((((0.0)) + (data[:,13]))/2.0)) +\n",
    "                0.250000*np.tanh((((((((data[:,2]) / 2.0)) * 2.0)) + (data[:,7]))/2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,14]) * 2.0)) + (np.tanh((data[:,14]))))/2.0)) +\n",
    "                0.250000*np.tanh(np.tanh((((((((((-1.0*((((np.tanh((data[:,9]))) / 2.0))))) / 2.0)) / 2.0)) + (((data[:,3]) * (data[:,13]))))/2.0)))) +\n",
    "                0.250000*np.tanh((-1.0*((((((((-1.0*(((((((-1.0*((data[:,18])))) - ((((0.0)) / 2.0)))) / 2.0))))) + (np.tanh(((((-1.0*(((-1.0*((data[:,22]))))))) / 2.0)))))/2.0)) / 2.0))))))\n",
    "    \n",
    "    def GP_class_13(self,data):\n",
    "        return(0.250000*np.tanh(((((np.tanh((np.tanh((data[:,2]))))) - ((10.0)))) - (np.tanh((((((data[:,7]) - ((((((6.0)) - ((4.87243366241455078)))) - ((9.0)))))) - ((14.80352973937988281)))))))) +\n",
    "                0.250000*np.tanh(((np.tanh((((((3.0)) + (data[:,1]))/2.0)))) - ((7.0)))) +\n",
    "                0.250000*np.tanh(((((np.tanh((np.tanh((np.tanh((data[:,6]))))))) * 2.0)) - ((6.10337877273559570)))) +\n",
    "                0.250000*np.tanh(((((((data[:,9]) + (data[:,14]))) + (data[:,14]))) + (data[:,14]))) +\n",
    "                0.250000*np.tanh(((((((np.tanh(((((-1.0*(((((((data[:,2]) + ((10.0)))/2.0)) / 2.0))))) - ((13.28130435943603516)))))) + ((10.0)))) - ((13.28130435943603516)))) + ((-1.0*((data[:,5])))))) +\n",
    "                0.250000*np.tanh(((((((((((data[:,20]) + (((((((((data[:,20]) * 2.0)) * 2.0)) * 2.0)) + (data[:,13]))))/2.0)) + (((data[:,9]) + (((data[:,9]) + (((data[:,6]) + (data[:,9]))))))))/2.0)) + (data[:,20]))) + (data[:,15]))) +\n",
    "                0.250000*np.tanh(((((((((data[:,14]) / 2.0)) + ((((data[:,9]) + (((data[:,15]) + (((data[:,5]) + ((((((data[:,9]) + (((data[:,5]) + (data[:,14]))))) + (data[:,9]))/2.0)))))))/2.0)))) * 2.0)) + (data[:,14]))) +\n",
    "                0.250000*np.tanh((((data[:,13]) + (data[:,7]))/2.0)) +\n",
    "                0.250000*np.tanh(((data[:,9]) + ((((data[:,3]) + ((((data[:,21]) + (data[:,3]))/2.0)))/2.0)))) +\n",
    "                0.250000*np.tanh((((data[:,2]) + (((((((((((((((data[:,20]) + (data[:,1]))) + (((data[:,2]) + (data[:,14]))))) + (data[:,2]))) + (np.tanh((data[:,2]))))/2.0)) + (((data[:,14]) + (data[:,2]))))) + (data[:,14]))/2.0)))/2.0)))\n",
    "    \n",
    "    def GP_class_14(self,data):\n",
    "        return(0.250000*np.tanh((((((((((((5.54024744033813477)) - ((((((9.0)) * 2.0)) * 2.0)))) - (data[:,0]))) - ((((7.0)) + ((4.74105215072631836)))))) - (((((7.0)) + (((data[:,5]) * 2.0)))/2.0)))) - ((9.0)))) +\n",
    "                0.250000*np.tanh(((((((((9.0)) - ((14.27298927307128906)))) - (data[:,0]))) + (np.tanh(((((12.77708148956298828)) - ((14.80560111999511719)))))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((0.0)) + ((-1.0*((((data[:,22]) + (((((((((13.30077362060546875)) - (np.tanh((data[:,4]))))) + (((data[:,22]) / 2.0)))/2.0)) / 2.0))))))))/2.0)) - (((np.tanh((((data[:,7]) - (data[:,7]))))) / 2.0)))) +\n",
    "                0.250000*np.tanh(((((((data[:,6]) + (data[:,14]))/2.0)) + (((np.tanh((((((data[:,14]) + (data[:,14]))) + (((data[:,6]) - (((data[:,5]) + (((np.tanh((data[:,21]))) + ((((data[:,14]) + ((((data[:,14]) + (data[:,14]))/2.0)))/2.0)))))))))))) + (data[:,5]))))/2.0)) +\n",
    "                0.250000*np.tanh((((((((((((((((((data[:,2]) + (data[:,16]))) + ((((((data[:,2]) / 2.0)) + (data[:,9]))/2.0)))/2.0)) + (np.tanh((data[:,10]))))/2.0)) + (data[:,9]))) + (data[:,9]))/2.0)) + (data[:,21]))) + (data[:,3]))) +\n",
    "                0.250000*np.tanh((((data[:,13]) + (((((((((((data[:,3]) / 2.0)) / 2.0)) / 2.0)) * (data[:,3]))) / 2.0)))/2.0)) +\n",
    "                0.250000*np.tanh(((data[:,14]) + (((((((data[:,14]) / 2.0)) + (data[:,14]))) * 2.0)))) +\n",
    "                0.250000*np.tanh(data[:,9]) +\n",
    "                0.250000*np.tanh(((data[:,1]) / 2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,2]) + ((((((data[:,13]) + (data[:,14]))) + (data[:,13]))/2.0)))) + (np.tanh((data[:,2]))))/2.0)))\n",
    "    \n",
    "    def GP_class_15(self,data):\n",
    "        return(0.250000*np.tanh((((((((4.0)) + ((((8.0)) / 2.0)))) - ((9.56193733215332031)))) - (((((np.tanh(((13.93556308746337891)))) - (data[:,18]))) + ((13.93556308746337891)))))) +\n",
    "                0.250000*np.tanh(((data[:,4]) - ((((12.76094818115234375)) - (data[:,8]))))) +\n",
    "                0.250000*np.tanh((((-1.0*(((12.35446166992187500))))) - (((((12.35446166992187500)) + ((((((12.35446166992187500)) - ((-1.0*(((0.0))))))) - (data[:,0]))))/2.0)))) +\n",
    "                0.250000*np.tanh(((data[:,21]) - ((14.46367263793945312)))) +\n",
    "                0.250000*np.tanh(((((data[:,2]) + ((((data[:,9]) + ((-1.0*(((-1.0*(((-1.0*((((data[:,7]) * (((data[:,21]) * 2.0))))))))))))))/2.0)))) + (data[:,9]))) +\n",
    "                0.250000*np.tanh(((((((((((data[:,7]) + (data[:,3]))/2.0)) + (data[:,20]))/2.0)) - ((((2.33354020118713379)) / 2.0)))) - ((((2.0)) + ((8.78930377960205078)))))) +\n",
    "                0.250000*np.tanh(((((((data[:,14]) + (((((((data[:,14]) + (((data[:,15]) + (data[:,14]))))) + (((data[:,15]) + (data[:,14]))))) + (((data[:,14]) / 2.0)))))) + (data[:,14]))) + (data[:,14]))) +\n",
    "                0.250000*np.tanh(((((((((data[:,13]) + (data[:,13]))) + (((data[:,13]) + (data[:,12]))))) + (data[:,9]))) + ((((((data[:,9]) + (((data[:,13]) + ((((data[:,9]) + (((((data[:,13]) * 2.0)) / 2.0)))/2.0)))))/2.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((data[:,9]) + ((((((data[:,9]) + (data[:,9]))/2.0)) / 2.0)))/2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,14]) + (data[:,8]))) + (data[:,14]))/2.0)))\n",
    "    \n",
    "    def GP_class_16(self,data):\n",
    "        return(0.250000*np.tanh(((((((((((((9.37592792510986328)) - ((13.36316204071044922)))) + ((11.89122962951660156)))/2.0)) - ((((9.0)) - (((((((data[:,13]) / 2.0)) / 2.0)) + ((((-1.0*((((data[:,4]) / 2.0))))) * 2.0)))))))) - ((12.24639320373535156)))) - ((11.89122581481933594)))) +\n",
    "                0.250000*np.tanh(((((np.tanh(((4.51821422576904297)))) - ((13.23712635040283203)))) - ((((((13.23712635040283203)) + (((data[:,22]) - ((((11.40539550781250000)) - (((((9.0)) + ((((((((data[:,7]) + (((data[:,17]) / 2.0)))/2.0)) * 2.0)) / 2.0)))/2.0)))))))) - (data[:,5]))))) +\n",
    "                0.250000*np.tanh(((data[:,14]) - ((((4.0)) + (((((13.41770648956298828)) + ((12.42538261413574219)))/2.0)))))) +\n",
    "                0.250000*np.tanh((((5.0)) - ((9.27778816223144531)))) +\n",
    "                0.250000*np.tanh(((((data[:,16]) - (((((((data[:,1]) - (((np.tanh((((((((9.29507255554199219)) - (((((((14.34461498260498047)) * 2.0)) + (((((7.0)) + ((9.10683441162109375)))/2.0)))/2.0)))) + ((4.21145153045654297)))/2.0)))) * 2.0)))) - ((9.10683441162109375)))) * 2.0)))) - ((((14.34461498260498047)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((((((((data[:,17]) / 2.0)) + (((data[:,13]) + (data[:,9]))))/2.0)) + (((data[:,17]) + (data[:,9]))))) + (data[:,0]))) +\n",
    "                0.250000*np.tanh(((data[:,13]) + (((data[:,14]) - (data[:,21]))))) +\n",
    "                0.250000*np.tanh((((((data[:,14]) + (data[:,5]))/2.0)) + (((((((data[:,9]) / 2.0)) + (data[:,14]))) / 2.0)))) +\n",
    "                0.250000*np.tanh((((((data[:,17]) + (data[:,9]))) + (((((data[:,17]) / 2.0)) + ((((((((((data[:,9]) + (data[:,9]))) - ((3.0)))) + (data[:,7]))) + (data[:,9]))/2.0)))))/2.0)) +\n",
    "                0.250000*np.tanh(np.tanh(((((((((((((((data[:,2]) + (((((((((((data[:,22]) + (data[:,21]))/2.0)) + (data[:,2]))/2.0)) * 2.0)) + ((((((data[:,21]) * 2.0)) + (data[:,21]))/2.0)))))) + (data[:,2]))/2.0)) + (data[:,17]))/2.0)) + (np.tanh((data[:,8]))))/2.0)) + (data[:,2]))))))\n",
    "    \n",
    "    def GP_class_17(self,data):\n",
    "        return(0.250000*np.tanh(((((data[:,14]) - ((((data[:,5]) + (((((14.43326377868652344)) + ((6.0)))/2.0)))/2.0)))) - (((((((10.0)) + ((14.84462165832519531)))/2.0)) - ((((7.0)) + (data[:,13]))))))) +\n",
    "                0.250000*np.tanh((((((((((data[:,14]) + (((((((((data[:,11]) - ((9.71331787109375000)))) / 2.0)) + ((9.0)))) - ((3.0)))))/2.0)) - ((10.0)))) - ((((10.0)) + ((((9.0)) - ((((((10.0)) - ((9.0)))) / 2.0)))))))) - ((10.0)))) +\n",
    "                0.250000*np.tanh((((((((((8.0)) - ((12.78277492523193359)))) - (data[:,10]))) - (np.tanh(((((((7.0)) - ((14.95321178436279297)))) - ((8.0)))))))) - ((14.95321178436279297)))) +\n",
    "                0.250000*np.tanh((((7.45682907104492188)) - ((14.98023796081542969)))) +\n",
    "                0.250000*np.tanh(((((((((((7.0)) + (((((np.tanh((((((((8.0)) * (data[:,8]))) + (data[:,11]))/2.0)))) / 2.0)) - ((8.0)))))/2.0)) - (data[:,20]))) - ((((8.0)) * 2.0)))) + ((8.0)))) +\n",
    "                0.250000*np.tanh(((data[:,8]) + (((data[:,4]) + (((np.tanh((data[:,4]))) + (((data[:,13]) + (data[:,13]))))))))) +\n",
    "                0.250000*np.tanh(data[:,14]) +\n",
    "                0.250000*np.tanh(((((((((((data[:,14]) + (np.tanh((((data[:,3]) * (data[:,13]))))))) + (data[:,14]))) + (data[:,0]))) + (data[:,8]))) / 2.0)) +\n",
    "                0.250000*np.tanh((((((data[:,9]) + (np.tanh(((((((data[:,19]) * (((((((data[:,1]) + (((((((data[:,21]) + (data[:,9]))/2.0)) + (data[:,6]))/2.0)))/2.0)) + (data[:,17]))/2.0)))) + (((data[:,15]) / 2.0)))/2.0)))))/2.0)) * 2.0)) +\n",
    "                0.250000*np.tanh(((data[:,1]) + (((((data[:,3]) + (data[:,15]))) + (np.tanh(((((data[:,20]) + (((data[:,1]) * 2.0)))/2.0)))))))))\n",
    "    \n",
    "    def GP_class_18(self,data):\n",
    "        return(0.250000*np.tanh((((((((((12.59485149383544922)) - ((12.59485149383544922)))) - ((12.59485149383544922)))) - ((((11.47756862640380859)) / 2.0)))) - ((12.59485149383544922)))) +\n",
    "                0.250000*np.tanh((((((-1.0*(((11.26121807098388672))))) - (((((((((11.33140659332275391)) - ((-1.0*(((9.76293182373046875))))))) - (((((11.33140659332275391)) + ((8.0)))/2.0)))) + ((9.76293182373046875)))/2.0)))) - (data[:,11]))) +\n",
    "                0.250000*np.tanh(((((((((((3.40250444412231445)) - (np.tanh(((14.86789989471435547)))))) - ((14.86789989471435547)))) + ((((((data[:,5]) + ((-1.0*(((((14.86789989471435547)) * 2.0))))))/2.0)) - ((14.86789989471435547)))))/2.0)) - (((((14.86789989471435547)) + (((((7.0)) + ((-1.0*((data[:,16])))))/2.0)))/2.0)))) +\n",
    "                0.250000*np.tanh(((data[:,18]) - ((11.84332561492919922)))) +\n",
    "                0.250000*np.tanh(((((np.tanh(((((8.96548557281494141)) * (data[:,12]))))) - ((-1.0*((((data[:,2]) * (((((data[:,4]) - ((-1.0*((data[:,9])))))) - ((9.0))))))))))) - ((8.96548557281494141)))) +\n",
    "                0.250000*np.tanh(((((((10.0)) - (data[:,12]))) + (((((((((data[:,13]) - ((12.43707370758056641)))) - ((((12.43707370758056641)) - (((data[:,12]) / 2.0)))))) - ((((12.43707370758056641)) - ((((data[:,13]) + ((12.43707370758056641)))/2.0)))))) - ((12.43707370758056641)))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((np.tanh((((np.tanh((data[:,14]))) + (data[:,13]))))) * 2.0)) + (data[:,14]))) + (data[:,13]))) +\n",
    "                0.250000*np.tanh(((np.tanh((data[:,14]))) + (data[:,14]))) +\n",
    "                0.250000*np.tanh(((((data[:,9]) + (((((data[:,13]) + (data[:,4]))) + (data[:,13]))))) / 2.0)) +\n",
    "                0.250000*np.tanh(((data[:,15]) - ((((data[:,3]) + ((5.0)))/2.0)))))\n",
    "    \n",
    "    def GP_class_19(self,data):\n",
    "        return(0.250000*np.tanh((((((data[:,13]) + (data[:,13]))/2.0)) + ((((((data[:,8]) + ((((data[:,14]) + (data[:,14]))/2.0)))/2.0)) * 2.0)))) +\n",
    "                0.250000*np.tanh((((data[:,3]) + (((data[:,8]) + (np.tanh(((((((-1.0*((((((9.05535793304443359)) + ((((data[:,14]) + (((((((data[:,1]) - (((data[:,12]) * 2.0)))) * ((-1.0*((data[:,17])))))) / 2.0)))/2.0)))/2.0))))) + (data[:,2]))) * 2.0)))))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((data[:,3]) + (((((data[:,14]) + (data[:,14]))) * 2.0)))) + ((((data[:,14]) + (np.tanh((((data[:,14]) + (np.tanh((data[:,14]))))))))/2.0)))) * 2.0)) + ((((data[:,14]) + (data[:,2]))/2.0)))) +\n",
    "                0.250000*np.tanh(((((data[:,8]) + (((data[:,4]) + (((data[:,13]) + (data[:,10]))))))) + (((((data[:,13]) + (((((data[:,13]) / 2.0)) + (data[:,9]))))) + (np.tanh(((((data[:,8]) + (data[:,8]))/2.0)))))))) +\n",
    "                0.250000*np.tanh((((((data[:,19]) + (((((data[:,10]) + ((((data[:,11]) + (data[:,19]))/2.0)))) + (data[:,10]))))/2.0)) + (data[:,2]))) +\n",
    "                0.250000*np.tanh((((((data[:,0]) + (((((((((data[:,0]) + (((((data[:,0]) - (data[:,11]))) / 2.0)))/2.0)) * 2.0)) + ((((((np.tanh((data[:,13]))) + (((data[:,0]) / 2.0)))/2.0)) / 2.0)))/2.0)))/2.0)) * 2.0)) +\n",
    "                0.250000*np.tanh(((((-1.0*((data[:,15])))) + (((data[:,14]) + (data[:,14]))))/2.0)) +\n",
    "                0.250000*np.tanh(((((((((data[:,0]) + (data[:,15]))/2.0)) + (((data[:,15]) * (data[:,15]))))/2.0)) - (data[:,11]))) +\n",
    "                0.250000*np.tanh(data[:,13]) +\n",
    "                0.250000*np.tanh(((((((((data[:,18]) + ((((data[:,4]) + (data[:,18]))/2.0)))) / 2.0)) + ((((data[:,18]) + (data[:,4]))/2.0)))) * (data[:,4])))    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time for the actual submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from kaggle.competitions import nflrush\n",
    "env = nflrush.make_env()\n",
    "iter_test = env.iter_test()\n",
    "gp = GP()\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    basetable = create_features(test_df, deploy=True)\n",
    "    basetable.drop(['GameId','PlayId'], axis=1, inplace=True)\n",
    "    scaled_basetable = scaler.transform(basetable)\n",
    "    \n",
    "    y_pred_nn = model.predict(scaled_basetable)\n",
    "\n",
    "    y_pred_gp = np.zeros((test_df.shape[0],199))\n",
    "    ans = gp.GrabPredictions(scaled_basetable)\n",
    "    y_pred_gp[:,96:96+20] = ans\n",
    "    \n",
    "    y_pred = (.6*y_pred_nn+.4*y_pred_gp)\n",
    "    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1).tolist()[0]\n",
    "    \n",
    "    preds_df = pd.DataFrame(data=[y_pred], columns=sample_prediction_df.columns)\n",
    "    env.predict(preds_df)\n",
    "    \n",
    "env.write_submission_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
