{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle\n",
    "## Competition NFL Big Data Bowl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Carregando os pacotes\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Statistic lib\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, norm\n",
    "\n",
    "# Sklearn lib\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Models\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.svm import SVR\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Keras\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Utils\n",
    "import pandasql as ps\n",
    "import re \n",
    "import math, string, os\n",
    "import datetime\n",
    "import math, copy, time, os\n",
    "from IPython.display import Image\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# Options\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_seq_items = 8000\n",
    "pd.options.display.max_rows = 8000\n",
    "pd.set_option('display.max_columns', None)\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "f5fdc987f79035336b408413b3b3111d1b48fd2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is ready !!\n"
     ]
    }
   ],
   "source": [
    "# Carregando os dados de treino\n",
    "train = pd.read_csv('../data/train.csv', low_memory=False)\n",
    "#train = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', low_memory=False)\n",
    "print (\"Data is ready !!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = train[['GameId','PlayId','Yards']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao para realizar feature engineering no dataset (treino ou teste)\n",
    "def feature_engineering(df, deploy=False): \n",
    "    \n",
    "    def new_X(x_coordinate, play_direction):\n",
    "        if play_direction == 'left':\n",
    "            return 120.0 - x_coordinate\n",
    "        else:\n",
    "            return x_coordinate\n",
    "\n",
    "    def new_line(rush_team, field_position, yardline):\n",
    "        if rush_team == field_position:\n",
    "            # offense starting at X = 0 plus the 10 yard endzone plus the line of scrimmage\n",
    "            return 10.0 + yardline\n",
    "        else:\n",
    "            # half the field plus the yards between midfield and the line of scrimmage\n",
    "            return 60.0 + (50 - yardline)\n",
    "\n",
    "    def new_orientation(angle, play_direction):\n",
    "        if play_direction == 'left':\n",
    "            new_angle = 360.0 - angle\n",
    "            if new_angle == 360.0:\n",
    "                new_angle = 0.0\n",
    "            return new_angle\n",
    "        else:\n",
    "            return angle\n",
    "\n",
    "    def euclidean_distance(x1,y1,x2,y2):\n",
    "        x_diff = (x1-x2)**2\n",
    "        y_diff = (y1-y2)**2\n",
    "\n",
    "        return np.sqrt(x_diff + y_diff)\n",
    "\n",
    "    def back_direction(orientation):\n",
    "        if orientation > 180.0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def update_yardline(df):\n",
    "        new_yardline = df[df['NflId'] == df['NflIdRusher']]\n",
    "        new_yardline['YardLine'] = new_yardline[['PossessionTeam','FieldPosition','YardLine']].apply(lambda x: new_line(x[0],x[1],x[2]), axis=1)\n",
    "        new_yardline = new_yardline[['GameId','PlayId','YardLine']]\n",
    "\n",
    "        return new_yardline\n",
    "\n",
    "    def update_orientation(df, yardline):\n",
    "        df['X'] = df[['X','PlayDirection']].apply(lambda x: new_X(x[0],x[1]), axis=1)\n",
    "        df['Orientation'] = df[['Orientation','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n",
    "        df['Dir'] = df[['Dir','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n",
    "\n",
    "        df = df.drop('YardLine', axis=1)\n",
    "        df = pd.merge(df, yardline, on=['GameId','PlayId'], how='inner')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def back_features(df):\n",
    "        carriers = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','NflIdRusher','X','Y','Orientation','Dir','YardLine']]\n",
    "        carriers['back_from_scrimmage'] = carriers['YardLine'] - carriers['X']\n",
    "        carriers['back_oriented_down_field'] = carriers['Orientation'].apply(lambda x: back_direction(x))\n",
    "        carriers['back_moving_down_field'] = carriers['Dir'].apply(lambda x: back_direction(x))\n",
    "        carriers = carriers.rename(columns={'X':'back_X',\n",
    "                                            'Y':'back_Y'})\n",
    "        carriers = carriers[['GameId','PlayId','NflIdRusher','back_X','back_Y','back_from_scrimmage','back_oriented_down_field','back_moving_down_field']]\n",
    "\n",
    "        return carriers\n",
    "\n",
    "    def features_relative_to_back(df, carriers):\n",
    "        player_distance = df[['GameId','PlayId','NflId','X','Y']]\n",
    "        player_distance = pd.merge(player_distance, carriers, on=['GameId','PlayId'], how='inner')\n",
    "        player_distance = player_distance[player_distance['NflId'] != player_distance['NflIdRusher']]\n",
    "        player_distance['dist_to_back'] = player_distance[['X','Y','back_X','back_Y']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n",
    "\n",
    "        player_distance = player_distance.groupby(['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field'])\\\n",
    "                                         .agg({'dist_to_back':['min','max','mean','std']})\\\n",
    "                                         .reset_index()\n",
    "        player_distance.columns = ['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field',\n",
    "                                   'min_dist','max_dist','mean_dist','std_dist']\n",
    "\n",
    "        return player_distance\n",
    "\n",
    "    def defense_features(df):\n",
    "        rusher = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','Team','X','Y']]\n",
    "        rusher.columns = ['GameId','PlayId','RusherTeam','RusherX','RusherY']\n",
    "\n",
    "        defense = pd.merge(df,rusher,on=['GameId','PlayId'],how='inner')\n",
    "        defense = defense[defense['Team'] != defense['RusherTeam']][['GameId','PlayId','X','Y','RusherX','RusherY']]\n",
    "        defense['def_dist_to_back'] = defense[['X','Y','RusherX','RusherY']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n",
    "\n",
    "        defense = defense.groupby(['GameId','PlayId'])\\\n",
    "                         .agg({'def_dist_to_back':['min','max','mean','std']})\\\n",
    "                         .reset_index()\n",
    "        defense.columns = ['GameId','PlayId','def_min_dist','def_max_dist','def_mean_dist','def_std_dist']\n",
    "\n",
    "        return defense\n",
    "\n",
    "    def static_features(df):\n",
    "        static_features = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','X','Y','S','A','Dis','Orientation','Dir',\n",
    "                                                            'YardLine','Quarter','Down','Distance','DefendersInTheBox']].drop_duplicates()\n",
    "        static_features['DefendersInTheBox'] = static_features['DefendersInTheBox'].fillna(np.mean(static_features['DefendersInTheBox']))\n",
    "\n",
    "        return static_features\n",
    "\n",
    "\n",
    "    def combine_features(relative_to_back, defense, static, deploy=deploy):\n",
    "        df = pd.merge(relative_to_back,defense,on=['GameId','PlayId'],how='inner')\n",
    "        df = pd.merge(df,static,on=['GameId','PlayId'],how='inner')\n",
    "\n",
    "        if not deploy:\n",
    "            df = pd.merge(df, outcomes, on=['GameId','PlayId'], how='inner')\n",
    "\n",
    "        return df\n",
    "    \n",
    "    yardline = update_yardline(df)\n",
    "    df = update_orientation(df, yardline)\n",
    "    back_feats = back_features(df)\n",
    "    rel_back = features_relative_to_back(df, back_feats)\n",
    "    def_feats = defense_features(df)\n",
    "    static_feats = static_features(df)\n",
    "    basetable = combine_features(rel_back, def_feats, static_feats, deploy=deploy)\n",
    "    \n",
    "    return basetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.25 µs\n"
     ]
    }
   ],
   "source": [
    "# Criando um novo dataset aplicando Feature Engineering\n",
    "%time\n",
    "train_df = feature_engineering(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GameId</th>\n",
       "      <th>PlayId</th>\n",
       "      <th>back_from_scrimmage</th>\n",
       "      <th>back_oriented_down_field</th>\n",
       "      <th>back_moving_down_field</th>\n",
       "      <th>min_dist</th>\n",
       "      <th>max_dist</th>\n",
       "      <th>mean_dist</th>\n",
       "      <th>std_dist</th>\n",
       "      <th>def_min_dist</th>\n",
       "      <th>def_max_dist</th>\n",
       "      <th>def_mean_dist</th>\n",
       "      <th>def_std_dist</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>S</th>\n",
       "      <th>A</th>\n",
       "      <th>Dis</th>\n",
       "      <th>Orientation</th>\n",
       "      <th>Dir</th>\n",
       "      <th>YardLine</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Down</th>\n",
       "      <th>Distance</th>\n",
       "      <th>DefendersInTheBox</th>\n",
       "      <th>Yards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907000118</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.449724</td>\n",
       "      <td>22.415872</td>\n",
       "      <td>8.046559</td>\n",
       "      <td>4.873845</td>\n",
       "      <td>4.593310</td>\n",
       "      <td>22.415872</td>\n",
       "      <td>9.752491</td>\n",
       "      <td>5.327299</td>\n",
       "      <td>41.25</td>\n",
       "      <td>30.53</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.38</td>\n",
       "      <td>198.02</td>\n",
       "      <td>114.26</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907000139</td>\n",
       "      <td>4.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.792023</td>\n",
       "      <td>23.025872</td>\n",
       "      <td>8.614623</td>\n",
       "      <td>5.598683</td>\n",
       "      <td>4.287773</td>\n",
       "      <td>23.025872</td>\n",
       "      <td>10.297028</td>\n",
       "      <td>5.833217</td>\n",
       "      <td>48.93</td>\n",
       "      <td>27.16</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.34</td>\n",
       "      <td>149.30</td>\n",
       "      <td>47.80</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907000189</td>\n",
       "      <td>3.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.646390</td>\n",
       "      <td>20.726285</td>\n",
       "      <td>8.482583</td>\n",
       "      <td>4.642121</td>\n",
       "      <td>4.221670</td>\n",
       "      <td>20.726285</td>\n",
       "      <td>9.903689</td>\n",
       "      <td>5.073290</td>\n",
       "      <td>71.34</td>\n",
       "      <td>19.11</td>\n",
       "      <td>5.77</td>\n",
       "      <td>2.42</td>\n",
       "      <td>0.60</td>\n",
       "      <td>219.18</td>\n",
       "      <td>138.04</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907000345</td>\n",
       "      <td>3.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.918096</td>\n",
       "      <td>9.791231</td>\n",
       "      <td>5.549379</td>\n",
       "      <td>1.983128</td>\n",
       "      <td>4.528002</td>\n",
       "      <td>9.791231</td>\n",
       "      <td>6.309354</td>\n",
       "      <td>1.834174</td>\n",
       "      <td>104.47</td>\n",
       "      <td>25.36</td>\n",
       "      <td>4.45</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.46</td>\n",
       "      <td>173.78</td>\n",
       "      <td>84.56</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907000395</td>\n",
       "      <td>5.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.502892</td>\n",
       "      <td>21.214806</td>\n",
       "      <td>9.168819</td>\n",
       "      <td>5.611232</td>\n",
       "      <td>4.288088</td>\n",
       "      <td>21.214806</td>\n",
       "      <td>11.056456</td>\n",
       "      <td>5.900009</td>\n",
       "      <td>29.99</td>\n",
       "      <td>27.12</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.44</td>\n",
       "      <td>34.27</td>\n",
       "      <td>157.92</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       GameId          PlayId  back_from_scrimmage  back_oriented_down_field  \\\n",
       "0  2017090700  20170907000118                 3.75                         1   \n",
       "1  2017090700  20170907000139                 4.07                         0   \n",
       "2  2017090700  20170907000189                 3.66                         1   \n",
       "3  2017090700  20170907000345                 3.53                         0   \n",
       "4  2017090700  20170907000395                 5.01                         0   \n",
       "\n",
       "   back_moving_down_field  min_dist   max_dist  mean_dist  std_dist  \\\n",
       "0                       0  1.449724  22.415872   8.046559  4.873845   \n",
       "1                       0  0.792023  23.025872   8.614623  5.598683   \n",
       "2                       0  1.646390  20.726285   8.482583  4.642121   \n",
       "3                       0  0.918096   9.791231   5.549379  1.983128   \n",
       "4                       0  0.502892  21.214806   9.168819  5.611232   \n",
       "\n",
       "   def_min_dist  def_max_dist  def_mean_dist  def_std_dist       X      Y  \\\n",
       "0      4.593310     22.415872       9.752491      5.327299   41.25  30.53   \n",
       "1      4.287773     23.025872      10.297028      5.833217   48.93  27.16   \n",
       "2      4.221670     20.726285       9.903689      5.073290   71.34  19.11   \n",
       "3      4.528002      9.791231       6.309354      1.834174  104.47  25.36   \n",
       "4      4.288088     21.214806      11.056456      5.900009   29.99  27.12   \n",
       "\n",
       "      S     A   Dis  Orientation     Dir  YardLine  Quarter  Down  Distance  \\\n",
       "0  3.63  3.35  0.38       198.02  114.26      45.0        1     3         2   \n",
       "1  3.06  2.41  0.34       149.30   47.80      53.0        1     1        10   \n",
       "2  5.77  2.42  0.60       219.18  138.04      75.0        1     1        10   \n",
       "3  4.45  3.20  0.46       173.78   84.56     108.0        1     2         2   \n",
       "4  3.90  2.53  0.44        34.27  157.92      35.0        1     1        10   \n",
       "\n",
       "   DefendersInTheBox  Yards  \n",
       "0                6.0      8  \n",
       "1                6.0      3  \n",
       "2                7.0      5  \n",
       "3                9.0      2  \n",
       "4                7.0      7  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23171, 26)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação e Validação dos Modelos de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fazendo uma limpeza na memoria\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação\n",
    "Continuous Ranked Probability Score (CRPS) is derived based on the predicted scalar value.\n",
    "The CRPS is computed as follows:\n",
    "$$\n",
    "C=\\frac{1}{199N}\\sum_{m=1}^N\\sum_{n=-99}^{99}(P(y\\geq n)-H(n-Y_m))^2\n",
    "$$\n",
    "$H(x)=1$ if $x\\geq 0$ else $0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a funcao de validacao, conforme formula do Ranked Probability Score\n",
    "def funcao_crps(y_train, y_pred):\n",
    "    y_true = np.clip(np.cumsum(y_train, axis=1), 0, 1)\n",
    "    y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "    tr_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_train.shape[0])\n",
    "    tr_s = np.round(tr_s, 6)\n",
    "    return 'CRPS: ',tr_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao para o fit dos modelos e realizar as previsoes para comparacao\n",
    "def model_scores(models, X_train, y_train, X_test, y_test, params, experimento):\n",
    "    model_results = pd.DataFrame()\n",
    "    model_data = {}\n",
    "    for model in tqdm_notebook(models):    \n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        model_name        = model.__class__.__name__\n",
    "        test_predictions  = model.predict(X_test)\n",
    "        train_predictions = model.predict(X_train)\n",
    "\n",
    "        test_score  = round(mean_squared_error(y_test, test_predictions),4)\n",
    "        train_score = round(mean_squared_error(y_train, train_predictions),4)\n",
    "        test_mae    = round(mean_absolute_error(y_test, test_predictions),4)\n",
    "        train_mae   = round(mean_absolute_error(y_train, train_predictions),4)\n",
    "\n",
    "        model_data['Experimento']  = [experimento]\n",
    "        model_data['Nome_Modelo']  = [model_name]\n",
    "        model_data['Modelo']       = [model]\n",
    "        model_data['Parametros']   = [str(params)]\n",
    "        model_data['Qtde_Feature'] = [X_train.shape[1]]\n",
    "        model_data['Score_Treino'] = [train_score]\n",
    "        model_data['MAE']          = [test_mae]\n",
    "        model_data['Score_Teste']  = [test_score]\n",
    "\n",
    "        print('{} MSE: {}'.format(model_name,test_score))\n",
    "        print('{} MAE: {}'.format(model_name,test_mae))\n",
    "\n",
    "        model_results = model_results.append(pd.DataFrame.from_dict(model_data, orient = 'columns'))\n",
    "    \n",
    "    model_results.sort_values('Score_Teste', ascending = True, inplace = True)\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blend models para fazer predicoes mais robustas\n",
    "def blended_predictions(X):\n",
    "    return ((light_p * lightgbm.predict(X)) + \\\n",
    "            (xgboost_p * xgboost.predict(X)) + \\\n",
    "            (ridge_p * ridge.predict(X)) + \\\n",
    "            (svr_p * svr.predict(X)) + \\\n",
    "            (gbr_p * gbr.predict(X)) + \\\n",
    "            (rf_p * rf.predict(X)))\n",
    "\n",
    "# Funcao para calcular as previsoes usando Blended dos modelos\n",
    "def model_blended_scores(params, experimento):\n",
    "    model_results = pd.DataFrame()\n",
    "    model_data = {}\n",
    "\n",
    "    train_blend_score = round(mean_squared_error(y_train, blended_predictions(X_train)),4)\n",
    "    test_blend_score  = round(mean_squared_error(y_val, blended_predictions(X_val)),4)\n",
    "\n",
    "    train_blend_mae   = round(mean_absolute_error(y_train, blended_predictions(X_train)),4)\n",
    "    test_blend_mae    = round(mean_absolute_error(y_val, blended_predictions(X_val)),4)\n",
    "\n",
    "    model_data['Experimento']  = [experimento]\n",
    "    model_data['Nome_Modelo']  = 'Blended'\n",
    "    model_data['Modelo']       = 'Blended'\n",
    "    model_data['Parametros']   = [str(params)]\n",
    "    model_data['Qtde_Feature'] = [X_train.shape[1]]\n",
    "    model_data['Score_Treino'] = [train_blend_score]\n",
    "    model_data['MAE']          = [test_blend_mae]\n",
    "    model_data['Score_Teste']  = [test_blend_score]\n",
    "\n",
    "    print('Blended MAE: {}'.format(test_blend_mae))\n",
    "    print('Blended Score Teste: {}'.format(test_blend_score))\n",
    "\n",
    "    model_results = model_results.append(pd.DataFrame.from_dict(model_data, orient = 'columns'))\n",
    "    model_results.sort_values('Score_Teste', ascending = True, inplace = True)\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split de dados e label\n",
    "X = train_df.drop(['GameId','PlayId','Yards'], axis=1)\n",
    "y = train_df['Yards']\n",
    "\n",
    "#X = train_df.copy()\n",
    "#yards = X.Yards\n",
    "\n",
    "#y = np.zeros((y_train_.shape[0], 199))\n",
    "#for idx, target in enumerate(list(y_train_)):\n",
    "#    y[idx][99 + target] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23171, 23), (23171,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizacao das features \n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Preenchendo valores missing\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X = imp.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split our data into train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19695, 23) (3476, 23)\n",
      "(19695,) (3476,)\n"
     ]
    }
   ],
   "source": [
    "# Verificando o shape apos o split entre feature e target\n",
    "print(X_train.shape, X_val.shape)\n",
    "print(y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nessa parte usarei varios modelos para comparação. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light Gradient Boosting Regressor\n",
    "lightgbm = LGBMRegressor(objective='regression', \n",
    "                         num_leaves=6,\n",
    "                         learning_rate=0.0005, \n",
    "                         n_estimators=1000,\n",
    "                         max_bin=200, \n",
    "                         bagging_fraction=0.8,\n",
    "                         bagging_freq=4, \n",
    "                         bagging_seed=8,\n",
    "                         feature_fraction=0.2,\n",
    "                         feature_fraction_seed=8,\n",
    "                         min_sum_hessian_in_leaf = 11,\n",
    "                         verbose=-1,\n",
    "                         random_state=42)\n",
    "\n",
    "# XGBoost Regressor\n",
    "xgboost = XGBRegressor(learning_rate=0.0005,\n",
    "                       n_estimators=1000,\n",
    "                       max_depth=4,\n",
    "                       min_child_weight=0,\n",
    "                       gamma=0.6,\n",
    "                       subsample=0.7,\n",
    "                       colsample_bytree=0.7,\n",
    "                       objective='reg:squarederror',\n",
    "                       nthread=-1,\n",
    "                       scale_pos_weight=1,\n",
    "                       seed=27,\n",
    "                       reg_alpha=0.0005,\n",
    "                       random_state=42)\n",
    "\n",
    "# Ridge Regressor\n",
    "ridge_alphas = [1e-15, 1e-10, 1e-8, 9e-4, 7e-4, 5e-4, 3e-4, 1e-4, 1e-3, 5e-2, 1e-2, 0.1, 0.3, 1, 3, 5, 10, 15, 18, 20, 30, 50, 75, 100]\n",
    "ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=ridge_alphas, cv=10))\n",
    "\n",
    "# Support Vector Regressor\n",
    "svr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003))\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "gbr = GradientBoostingRegressor(n_estimators=1000,\n",
    "                                learning_rate=0.0005,\n",
    "                                max_depth=4,\n",
    "                                max_features='sqrt',\n",
    "                                min_samples_leaf=15,\n",
    "                                min_samples_split=10,\n",
    "                                loss='huber',\n",
    "                                random_state=42)  \n",
    "\n",
    "# Random Forest Regressor\n",
    "rf = RandomForestRegressor(n_estimators=1000,\n",
    "                           max_depth=15,\n",
    "                           min_samples_split=5,\n",
    "                           min_samples_leaf=5,\n",
    "                           max_features=None,\n",
    "                           oob_score=True,\n",
    "                           random_state=42)\n",
    "\n",
    "# Stack up all the models above, optimized using lightgbm\n",
    "stack_gen = StackingCVRegressor(regressors=(xgboost, lightgbm, svr, ridge, gbr, rf),\n",
    "                                meta_regressor=lightgbm,\n",
    "                                use_features_in_secondary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentos = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimento = '01'\n",
    "\n",
    "# Parametros para os modelos\n",
    "n_estimators = 1000\n",
    "learning_rate = 0.0005\n",
    "params = str((n_estimators, learning_rate))\n",
    "\n",
    "# Parametros para o peso no blended dos modelos\n",
    "light_p   = 0.2\n",
    "xgboost_p = 0.33\n",
    "ridge_p   = 0.05\n",
    "svr_p     = 0.1\n",
    "gbr_p     = 0.1\n",
    "rf_p      = 0.45\n",
    "params_blended = str((light_p, xgboost_p, ridge_p, svr_p, gbr_p, rf_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541c88fa6fe24481829966a254a304b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMRegressor MSE: 43.2946\n",
      "LGBMRegressor MAE: 3.7927\n",
      "XGBRegressor MSE: 47.8946\n",
      "XGBRegressor MAE: 3.7103\n",
      "Pipeline MSE: 41.4624\n",
      "Pipeline MAE: 3.6209\n",
      "Pipeline MSE: 43.2116\n",
      "Pipeline MAE: 3.4484\n",
      "GradientBoostingRegressor MSE: 44.2078\n",
      "GradientBoostingRegressor MAE: 3.6043\n",
      "RandomForestRegressor MSE: 40.6447\n",
      "RandomForestRegressor MAE: 3.5559\n",
      "StackingCVRegressor MSE: 42.3198\n",
      "StackingCVRegressor MAE: 3.7076\n",
      "\n",
      "Blended MAE: 3.5681\n",
      "Blended Score Teste: 40.8281\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experimento</th>\n",
       "      <th>Nome_Modelo</th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Parametros</th>\n",
       "      <th>Qtde_Feature</th>\n",
       "      <th>Score_Treino</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Score_Teste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>(1000, 0.0005)</td>\n",
       "      <td>23</td>\n",
       "      <td>24.7146</td>\n",
       "      <td>3.5559</td>\n",
       "      <td>40.6447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>Blended</td>\n",
       "      <td>Blended</td>\n",
       "      <td>(0.2, 0.33, 0.05, 0.1, 0.1, 0.45)</td>\n",
       "      <td>23</td>\n",
       "      <td>31.5838</td>\n",
       "      <td>3.5681</td>\n",
       "      <td>40.8281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>Pipeline</td>\n",
       "      <td>(RobustScaler(copy=True, quantile_range=(25.0,...</td>\n",
       "      <td>(1000, 0.0005)</td>\n",
       "      <td>23</td>\n",
       "      <td>38.5240</td>\n",
       "      <td>3.6209</td>\n",
       "      <td>41.4624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>StackingCVRegressor</td>\n",
       "      <td>StackingCVRegressor(cv=5,\\n                   ...</td>\n",
       "      <td>(1000, 0.0005)</td>\n",
       "      <td>23</td>\n",
       "      <td>38.5402</td>\n",
       "      <td>3.7076</td>\n",
       "      <td>42.3198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>Pipeline</td>\n",
       "      <td>(RobustScaler(copy=True, quantile_range=(25.0,...</td>\n",
       "      <td>(1000, 0.0005)</td>\n",
       "      <td>23</td>\n",
       "      <td>40.2188</td>\n",
       "      <td>3.4484</td>\n",
       "      <td>43.2116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>LGBMRegressor(bagging_fraction=0.8, bagging_fr...</td>\n",
       "      <td>(1000, 0.0005)</td>\n",
       "      <td>23</td>\n",
       "      <td>40.2068</td>\n",
       "      <td>3.7927</td>\n",
       "      <td>43.2946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>(1000, 0.0005)</td>\n",
       "      <td>23</td>\n",
       "      <td>41.0467</td>\n",
       "      <td>3.6043</td>\n",
       "      <td>44.2078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
       "      <td>(1000, 0.0005)</td>\n",
       "      <td>23</td>\n",
       "      <td>44.3620</td>\n",
       "      <td>3.7103</td>\n",
       "      <td>47.8946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Experimento                Nome_Modelo  \\\n",
       "0          01      RandomForestRegressor   \n",
       "0          01                    Blended   \n",
       "0          01                   Pipeline   \n",
       "0          01        StackingCVRegressor   \n",
       "0          01                   Pipeline   \n",
       "0          01              LGBMRegressor   \n",
       "0          01  GradientBoostingRegressor   \n",
       "0          01               XGBRegressor   \n",
       "\n",
       "                                              Modelo  \\\n",
       "0  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "0                                            Blended   \n",
       "0  (RobustScaler(copy=True, quantile_range=(25.0,...   \n",
       "0  StackingCVRegressor(cv=5,\\n                   ...   \n",
       "0  (RobustScaler(copy=True, quantile_range=(25.0,...   \n",
       "0  LGBMRegressor(bagging_fraction=0.8, bagging_fr...   \n",
       "0  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "0  XGBRegressor(base_score=0.5, booster='gbtree',...   \n",
       "\n",
       "                          Parametros  Qtde_Feature  Score_Treino     MAE  \\\n",
       "0                     (1000, 0.0005)            23       24.7146  3.5559   \n",
       "0  (0.2, 0.33, 0.05, 0.1, 0.1, 0.45)            23       31.5838  3.5681   \n",
       "0                     (1000, 0.0005)            23       38.5240  3.6209   \n",
       "0                     (1000, 0.0005)            23       38.5402  3.7076   \n",
       "0                     (1000, 0.0005)            23       40.2188  3.4484   \n",
       "0                     (1000, 0.0005)            23       40.2068  3.7927   \n",
       "0                     (1000, 0.0005)            23       41.0467  3.6043   \n",
       "0                     (1000, 0.0005)            23       44.3620  3.7103   \n",
       "\n",
       "   Score_Teste  \n",
       "0      40.6447  \n",
       "0      40.8281  \n",
       "0      41.4624  \n",
       "0      42.3198  \n",
       "0      43.2116  \n",
       "0      43.2946  \n",
       "0      44.2078  \n",
       "0      47.8946  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executando toda a lista de modelos, com as respectivas previsoes\n",
    "test_models = [lightgbm, xgboost, ridge, svr, gbr, rf, stack_gen]\n",
    "\n",
    "model_results = model_scores(test_models, X_train, y_train, X_val, y_val, params, experimento)\n",
    "model_results_blended = model_blended_scores(params_blended, experimento)\n",
    "\n",
    "experimentos = experimentos.append(model_results)\n",
    "experimentos = experimentos.append(model_results_blended)\n",
    "experimentos.sort_values('Score_Teste', ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando NN Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric(Callback):\n",
    "    def __init__(self, model, callbacks, data):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.callbacks = callbacks\n",
    "        self.data = data\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_train_begin(logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_train_end(logs)\n",
    "\n",
    "    def on_epoch_end(self, batch, logs=None):\n",
    "        X_train, y_train = self.data[0][0], self.data[0][1]\n",
    "        y_pred = self.model.predict(X_train)\n",
    "\n",
    "        y_true = np.clip(np.cumsum(y_train, axis=1), 0, 1)\n",
    "        y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "        tr_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_train.shape[0])\n",
    "        tr_s = np.round(tr_s, 6)\n",
    "        logs['tr_CRPS'] = tr_s\n",
    "\n",
    "        X_valid, y_valid = self.data[1][0], self.data[1][1]\n",
    "        y_pred = self.model.predict(X_valid)\n",
    "\n",
    "        y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n",
    "        y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n",
    "        val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_valid.shape[0])\n",
    "        val_s = np.round(val_s, 6)\n",
    "        logs['val_CRPS'] = val_s\n",
    "        print('tr_CRPS', tr_s, 'val_CRPS', val_s)\n",
    "\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_epoch_end(batch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.4)) #dropout is a type of regularisation. Regularisation helps to control overfitting\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2)) #dropout is a type of regularisation. Regularisation helps to control overfitting\n",
    "model.add(Dense(199, activation='softmax'))\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_CRPS', \n",
    "                   mode='min',\n",
    "                   restore_best_weights=True, \n",
    "                   verbose=1, \n",
    "                   patience=66)\n",
    "es.set_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ = np.zeros((y.shape[0], 199))\n",
    "for idx, target in enumerate(list(y)):\n",
    "    y_train_[idx][99 + target] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split our data into train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_train_, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = Metric(model, [es], [(X_train,y_train), (X_val,y_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y_train_, callbacks=[metric], epochs=100, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao para desmembrar Yards de -99 a 99\n",
    "def desmembra_yards(y):\n",
    "    y_ = copy.deepcopy(y.to_frame())\n",
    "    y_.columns = ['Yards']\n",
    "    for i in list(range(-99,100)):  \n",
    "        y_['Yards' + str(i)] = y_['Yards'].apply(lambda x: 1 if i >= x else 0)\n",
    "    y_.drop('Yards',1,inplace = True)\n",
    "    return y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desmembra Yards\n",
    "y_new = desmembra_yards(y)\n",
    "y_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit do modelo final (Random Forest )\n",
    "final_model = rf.fit(X, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca previsoes do modelo com dados de validacao\n",
    "y_pred = final_model.predict(X)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validacao com base na formula do CRPS\n",
    "funcao_crps(y_new, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REALIZANDO A SUBMISSAO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
